{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Copy of assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W2JcwPiv2mv",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9OP1Pu5v2my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "SEED=1337\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9dYFvADv2m1",
        "colab_type": "code",
        "outputId": "bfb3dff7-52ce-4cd6-ac07-1a22102ddf2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "df = pd.read_csv('ner_short.csv', index_col=0)\n",
        "df.head(n=20)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>1.0</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>VB</td>\n",
              "      <td>protest</td>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>1.0</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>VB</td>\n",
              "      <td>protest</td>\n",
              "      <td>TO</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>1.0</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NN</td>\n",
              "      <td>war</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>VB</td>\n",
              "      <td>TO</td>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>1.0</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "      <td>NN</td>\n",
              "      <td>war</td>\n",
              "      <td>DT</td>\n",
              "      <td>VB</td>\n",
              "      <td>TO</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NNP</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "      <td>NN</td>\n",
              "      <td>DT</td>\n",
              "      <td>VB</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>1.0</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>1.0</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>VB</td>\n",
              "      <td>demand</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>VB</td>\n",
              "      <td>demand</td>\n",
              "      <td>CC</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>1.0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NN</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>VB</td>\n",
              "      <td>CC</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NN</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>DT</td>\n",
              "      <td>VB</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>JJ</td>\n",
              "      <td>British</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NN</td>\n",
              "      <td>DT</td>\n",
              "      <td>VB</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>1.0</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NNS</td>\n",
              "      <td>troops</td>\n",
              "      <td>JJ</td>\n",
              "      <td>British</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>IN</td>\n",
              "      <td>from</td>\n",
              "      <td>NNS</td>\n",
              "      <td>troops</td>\n",
              "      <td>JJ</td>\n",
              "      <td>IN</td>\n",
              "      <td>NN</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>British</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>DT</td>\n",
              "      <td>that</td>\n",
              "      <td>IN</td>\n",
              "      <td>from</td>\n",
              "      <td>NNS</td>\n",
              "      <td>JJ</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>1.0</td>\n",
              "      <td>troops</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   next-next-pos next-next-word next-pos  ... sentence_idx           word    tag\n",
              "0            NNS  demonstrators       IN  ...          1.0      Thousands      O\n",
              "1            VBP           have      NNS  ...          1.0             of      O\n",
              "2            VBN        marched      VBP  ...          1.0  demonstrators      O\n",
              "3             IN        through      VBN  ...          1.0           have      O\n",
              "4            NNP         London       IN  ...          1.0        marched      O\n",
              "5             TO             to      NNP  ...          1.0        through      O\n",
              "6             VB        protest       TO  ...          1.0         London  B-geo\n",
              "7             DT            the       VB  ...          1.0             to      O\n",
              "8             NN            war       DT  ...          1.0        protest      O\n",
              "9             IN             in       NN  ...          1.0            the      O\n",
              "10           NNP           Iraq       IN  ...          1.0            war      O\n",
              "11            CC            and      NNP  ...          1.0             in      O\n",
              "12            VB         demand       CC  ...          1.0           Iraq  B-geo\n",
              "13            DT            the       VB  ...          1.0            and      O\n",
              "14            NN     withdrawal       DT  ...          1.0         demand      O\n",
              "15            IN             of       NN  ...          1.0            the      O\n",
              "16            JJ        British       IN  ...          1.0     withdrawal      O\n",
              "17           NNS         troops       JJ  ...          1.0             of      O\n",
              "18            IN           from      NNS  ...          1.0        British  B-gpe\n",
              "19            DT           that       IN  ...          1.0         troops      O\n",
              "\n",
              "[20 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZPdQH4Dv2m4",
        "colab_type": "code",
        "outputId": "b15a3b3e-4ab3-426d-84cb-6ac137defd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenCg9QJv2m6",
        "colab_type": "code",
        "outputId": "17afc29d-e630-4103-9c86-8116019734f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5adG3Q0llll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ff9b8af3-9a9d-4099-acc5-3d60cf27a3e7"
      },
      "source": [
        "np.unique(df['tag'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per',\n",
              "       'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org',\n",
              "       'I-per', 'I-tim', 'O'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ9eDoYqv2m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqCLNIM5v2nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df.pos)\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHMaZ7LYv2nC",
        "colab_type": "code",
        "outputId": "b2c5ca0d-38ee-481c-a666-2bb42f1de4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_idx  next-next-pos next-next-word  ...           word tag  length\n",
              "0           1.0             18  demonstrators  ...      Thousands   O      48\n",
              "1           1.0             33           have  ...             of   O      48\n",
              "2           1.0             32        marched  ...  demonstrators   O      48\n",
              "3           1.0              9        through  ...           have   O      48\n",
              "4           1.0             16         London  ...        marched   O      48\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDb_2SBkv2nF",
        "colab_type": "code",
        "outputId": "3e99b36c-de83-4945-a860-3638c676d2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# splitting\n",
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(\n",
        "    df, y, stratify=y, test_size=0.25, random_state=SEED, shuffle=True\n",
        ")\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3eHrxUjv2nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some wrappers to work with word2vec\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from collections import defaultdict\n",
        "\n",
        "   \n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5, negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCGXyrfv2nL",
        "colab_type": "code",
        "outputId": "f799ddd0-9273-475f-be7c-7350fdc3f512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# here we exploit that word2vec is an unsupervised learning algorithm\n",
        "# so we can train it on the whole dataset (subject to discussion)\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(sentences_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 44.7 s, sys: 459 ms, total: 45.1 s\n",
            "Wall time: 25.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYfS0gVov2nO",
        "colab_type": "code",
        "outputId": "26251468-a2c3-4836-9e98-5c2679f5e941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "# baseline 1 \n",
        "# random labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', DummyClassifier(random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.05887736725599869\n",
            "test 0.060439542712750365\n",
            "CPU times: user 130 ms, sys: 14 ms, total: 144 ms\n",
            "Wall time: 144 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaatYxZFv2nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# baseline 2 \n",
        "# pos features + one hot encoding + logistic regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
        "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfB13lKXv2nT",
        "colab_type": "code",
        "outputId": "470beaf2-e533-476e-e7e3-527e865c8a07",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# baseline 3\n",
        "# use word2vec cbow embedding + baseline 2 + svm\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "\n",
        "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
        "                                    {'C': np.logspace(-4, 0, 5)}, \n",
        "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.0min finished\n",
            "/Users/denaas/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 0.95846030477073\n",
            "test 0.8122113864662406\n",
            "CPU times: user 1min 56s, sys: 5.51 s, total: 2min 1s\n",
            "Wall time: 7min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5FaURDz2zoZ",
        "colab_type": "text"
      },
      "source": [
        "###### Бьём бейзлайны"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqni3etaoqSt",
        "colab_type": "text"
      },
      "source": [
        "Во-первых, лемматизируем наши слова и будем обучать word2vec на леммах (уменьшится словарь, для задачи NER конкретная форма слова представляется не очень важной, а векторы будут точнее).\n",
        "\n",
        "Во-вторых, добавим признак капитализации (первая буква заглавная или нет?) всех слов в контексте. Если это слово или предшуствующее ему не \\__START1\\__ и не \\__START2\\__ (предположительно немногочисленными случаями, когда первое слово в предложении является NER, можно пренебречь, да и небольшой шум не сделает сильно хуже): NER по большей части будет начинаться с заглавной буквы, но не каждое слово с заглавной буквы будет обязательно NER, и поэтому мы добавляем этот признак и для слов в контексте, поскольку, ввероятно, должны быть определённые закономерности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjItDUU5s2TP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "647d6c89-811f-40fc-86fb-133d8bac4fac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "for prefix in ['prev-prev-', 'prev-', '', 'next-', 'next-next-']:\n",
        "    df[f'{prefix}lemma'] = df[f'{prefix}word'].apply(lambda wordform: lemmatizer.lemmatize(wordform.lower(), pos=get_wordnet_pos(nltk.pos_tag([wordform.lower()])[0][1])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei3n9mk8qOyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for prefix in ['prev-prev-', 'prev-', 'next-', 'next-next-']:\n",
        "    df[prefix + 'uppercase'] = df.apply(lambda row: 1 if row[f'{prefix}word'] not in ['__START1__', '__START2__'] and row[f'{prefix}word'][0].isupper() else 0, axis=1)\n",
        "df['uppercase'] = df.apply(lambda row: 1 if row['prev-word'] != '__START1__' and row['word'][0].isupper() else 0, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xOqOL6m3tf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "a7fdc147-fd43-4ce0-b123-9bce5c0210b4"
      },
      "source": [
        "df.head(n=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>prev-prev-uppercase</th>\n",
              "      <th>prev-uppercase</th>\n",
              "      <th>next-uppercase</th>\n",
              "      <th>next-next-uppercase</th>\n",
              "      <th>uppercase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>have</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>demonstrator</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>to</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>48</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>london</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>iraq</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>48</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>in</td>\n",
              "      <td>iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>10</td>\n",
              "      <td>British</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>british</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>troops</td>\n",
              "      <td>10</td>\n",
              "      <td>British</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>british</td>\n",
              "      <td>troop</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>from</td>\n",
              "      <td>18</td>\n",
              "      <td>troops</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>48</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>british</td>\n",
              "      <td>troop</td>\n",
              "      <td>from</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>that</td>\n",
              "      <td>9</td>\n",
              "      <td>from</td>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>troops</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>of</td>\n",
              "      <td>british</td>\n",
              "      <td>troop</td>\n",
              "      <td>from</td>\n",
              "      <td>that</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx  next-next-pos  ... next-next-uppercase  uppercase\n",
              "0            1.0             18  ...                   0          0\n",
              "1            1.0             33  ...                   0          0\n",
              "2            1.0             32  ...                   0          0\n",
              "3            1.0              9  ...                   0          0\n",
              "4            1.0             16  ...                   1          0\n",
              "5            1.0             28  ...                   0          0\n",
              "6            1.0             29  ...                   0          1\n",
              "7            1.0              7  ...                   0          0\n",
              "8            1.0             15  ...                   0          0\n",
              "9            1.0              9  ...                   0          0\n",
              "10           1.0             16  ...                   1          0\n",
              "11           1.0              5  ...                   0          0\n",
              "12           1.0             29  ...                   0          1\n",
              "13           1.0              7  ...                   0          0\n",
              "14           1.0             15  ...                   0          0\n",
              "15           1.0              9  ...                   0          0\n",
              "16           1.0             10  ...                   1          0\n",
              "17           1.0             18  ...                   0          0\n",
              "18           1.0              9  ...                   0          1\n",
              "19           1.0              7  ...                   0          0\n",
              "\n",
              "[20 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnNuv0iyUZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "78bf12fb-a83b-4023-a06d-bc855530ed63"
      },
      "source": [
        "%%time\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.lemma).split('.')]\n",
        "\n",
        "w2v_cbow_lemmas = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow_lemmas.fit(sentences_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 45.2 s, sys: 405 ms, total: 45.6 s\n",
            "Wall time: 25.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tJ6iHly502N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "880cc255-4a53-449d-baff-0b9736de6726"
      },
      "source": [
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(\n",
        "    df, y, stratify=y, test_size=0.25, random_state=SEED, shuffle=True\n",
        ")\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjCaXGItv2nX",
        "colab_type": "code",
        "outputId": "b6991b5e-3f7b-453e-ad55-060388fc6c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "%%time\n",
        "# baselines 1-2\n",
        "# use RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "columns = [f'{prefix}{feature}'\n",
        "    for prefix in ['prev-prev-', 'prev-', '', 'next-', 'next-next-']\n",
        "    for feature in ['pos', 'uppercase']\n",
        "]\n",
        "\n",
        "encoder_pos = OneHotEncoder()\n",
        "encoder_pos.fit(df[columns])\n",
        "X_train = encoder_pos.transform(df_train[columns])\n",
        "X_test = encoder_pos.transform(df_test[columns])\n",
        "\n",
        "# параметры подобраны с помощью сетки, просто обучать всё сразу очень долго,\n",
        "# поэтому они подбирались последовательным пепебором раскомменчиванием в param_grid\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = model_selection.GridSearchCV(\n",
        "    estimator=RandomForestClassifier(\n",
        "        random_state=SEED, max_features=None, verbose=1, criterion='entropy',\n",
        "        min_samples_leaf=1, min_samples_split=2, n_estimators=500\n",
        "    ),\n",
        "    param_grid={\n",
        "        # 'criterion': ['gini', 'entropy'],\n",
        "        # 'min_samples_split': [2, 3, 4],\n",
        "        # 'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
        "     },\n",
        "     scoring='f1_macro', cv=3, n_jobs=-1, verbose=1, refit=True\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "# print(model.best_params_)\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  6.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  4.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 0.7804723072356119\n",
            "test 0.6426730786726875\n",
            "CPU times: user 4min 4s, sys: 349 ms, total: 4min 4s\n",
            "Wall time: 10min 6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJMcac844Sz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CatBoost\n",
        "\n",
        "# !pip install catboost\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from catboost import CatBoostClassifier, Pool, cv\n",
        "\n",
        "# NUM_OF_FEATS = 5\n",
        "# columns = ['pos', 'next-pos', 'next-next-pos', 'prev-pos', 'prev-prev-pos']\n",
        "# model = CatBoostClassifier(\n",
        "#     custom_loss=[metrics.f1_score(average='macro')],\n",
        "#     random_seed=SEED,\n",
        "#     logging_level='Silent'\n",
        "# )\n",
        "\n",
        "# # cv_params = model.get_params()\n",
        "# # cv_params.update({\n",
        "# #     random_seed=SEED\n",
        "# # })\n",
        "\n",
        "# # cv_data = cv(\n",
        "# #     Pool(X_train, y_train, cat_features=range(NUM_OF_FEATS)), cv_params, plot=True\n",
        "# # )\n",
        "\n",
        "# model.fit(\n",
        "#     df_train[columns], y_train,\n",
        "#     cat_features=range(NUM_OF_FEATS),\n",
        "#     eval_set=(df_test[columns], y_test),\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "# print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdsvTGbW8Soq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "729a1275-bcfc-4005-e65a-36ba98b1f403"
      },
      "source": [
        "# LGBM\n",
        "# import lightgbm as lgb\n",
        "\n",
        "# columns = ['pos', 'next-pos', 'next-next-pos', 'prev-pos', 'prev-prev-pos']\n",
        "# lgb_train = lgb.Dataset(df_train[columns], y_train)\n",
        "# lgb_eval = lgb.Dataset(df_test[columns], y_test, reference=lgb_train)\n",
        "\n",
        "# params = {\n",
        "#     'boosting_type': 'gbdt',\n",
        "#     'objective': 'multiclass',\n",
        "#     'num_class': len(np.unique(y)),\n",
        "#     'metric': 'multi_logloss',\n",
        "#     'num_leaves': 127,\n",
        "#     'learning_rate': 0.005,\n",
        "#     'feature_fraction': 0.6,\n",
        "#     'bagging_fraction': 0.6,\n",
        "#     'bagging_freq': 1,\n",
        "#     'verbose': 50,\n",
        "#     'seed': SEED\n",
        "# }\n",
        "\n",
        "# print('Starting training...')\n",
        "# # train\n",
        "# gbm = lgb.train(\n",
        "#     params,\n",
        "#     lgb_train,\n",
        "#     num_boost_round=5000,\n",
        "#     valid_sets=lgb_eval,\n",
        "#     early_stopping_rounds=100\n",
        "# )\n",
        "\n",
        "# print('Saving model...')\n",
        "# # save model to file\n",
        "# gbm.save_model('model.txt')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "[1]\tvalid_0's multi_logloss: 0.736673\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.732001\n",
            "[3]\tvalid_0's multi_logloss: 0.72757\n",
            "[4]\tvalid_0's multi_logloss: 0.722838\n",
            "[5]\tvalid_0's multi_logloss: 0.717367\n",
            "[6]\tvalid_0's multi_logloss: 0.712229\n",
            "[7]\tvalid_0's multi_logloss: 0.708249\n",
            "[8]\tvalid_0's multi_logloss: 0.703345\n",
            "[9]\tvalid_0's multi_logloss: 0.697759\n",
            "[10]\tvalid_0's multi_logloss: 0.692245\n",
            "[11]\tvalid_0's multi_logloss: 0.68868\n",
            "[12]\tvalid_0's multi_logloss: 0.684151\n",
            "[13]\tvalid_0's multi_logloss: 0.680346\n",
            "[14]\tvalid_0's multi_logloss: 0.674944\n",
            "[15]\tvalid_0's multi_logloss: 0.670183\n",
            "[16]\tvalid_0's multi_logloss: 0.666086\n",
            "[17]\tvalid_0's multi_logloss: 0.662804\n",
            "[18]\tvalid_0's multi_logloss: 0.65925\n",
            "[19]\tvalid_0's multi_logloss: 0.655896\n",
            "[20]\tvalid_0's multi_logloss: 0.651731\n",
            "[21]\tvalid_0's multi_logloss: 0.647756\n",
            "[22]\tvalid_0's multi_logloss: 0.644395\n",
            "[23]\tvalid_0's multi_logloss: 0.640758\n",
            "[24]\tvalid_0's multi_logloss: 0.636545\n",
            "[25]\tvalid_0's multi_logloss: 0.633216\n",
            "[26]\tvalid_0's multi_logloss: 0.63037\n",
            "[27]\tvalid_0's multi_logloss: 0.627536\n",
            "[28]\tvalid_0's multi_logloss: 0.624373\n",
            "[29]\tvalid_0's multi_logloss: 0.620451\n",
            "[30]\tvalid_0's multi_logloss: 0.617641\n",
            "[31]\tvalid_0's multi_logloss: 0.615023\n",
            "[32]\tvalid_0's multi_logloss: 0.612679\n",
            "[33]\tvalid_0's multi_logloss: 0.609122\n",
            "[34]\tvalid_0's multi_logloss: 0.606424\n",
            "[35]\tvalid_0's multi_logloss: 0.603997\n",
            "[36]\tvalid_0's multi_logloss: 0.601706\n",
            "[37]\tvalid_0's multi_logloss: 0.599064\n",
            "[38]\tvalid_0's multi_logloss: 0.595528\n",
            "[39]\tvalid_0's multi_logloss: 0.5921\n",
            "[40]\tvalid_0's multi_logloss: 0.589392\n",
            "[41]\tvalid_0's multi_logloss: 0.586906\n",
            "[42]\tvalid_0's multi_logloss: 0.583823\n",
            "[43]\tvalid_0's multi_logloss: 0.580998\n",
            "[44]\tvalid_0's multi_logloss: 0.579076\n",
            "[45]\tvalid_0's multi_logloss: 0.577009\n",
            "[46]\tvalid_0's multi_logloss: 0.574769\n",
            "[47]\tvalid_0's multi_logloss: 0.572483\n",
            "[48]\tvalid_0's multi_logloss: 0.569889\n",
            "[49]\tvalid_0's multi_logloss: 0.567229\n",
            "[50]\tvalid_0's multi_logloss: 0.565007\n",
            "[51]\tvalid_0's multi_logloss: 0.56305\n",
            "[52]\tvalid_0's multi_logloss: 0.560415\n",
            "[53]\tvalid_0's multi_logloss: 0.557597\n",
            "[54]\tvalid_0's multi_logloss: 0.55522\n",
            "[55]\tvalid_0's multi_logloss: 0.552616\n",
            "[56]\tvalid_0's multi_logloss: 0.550695\n",
            "[57]\tvalid_0's multi_logloss: 0.549013\n",
            "[58]\tvalid_0's multi_logloss: 0.546436\n",
            "[59]\tvalid_0's multi_logloss: 0.544828\n",
            "[60]\tvalid_0's multi_logloss: 0.542558\n",
            "[61]\tvalid_0's multi_logloss: 0.54026\n",
            "[62]\tvalid_0's multi_logloss: 0.53798\n",
            "[63]\tvalid_0's multi_logloss: 0.535844\n",
            "[64]\tvalid_0's multi_logloss: 0.533821\n",
            "[65]\tvalid_0's multi_logloss: 0.532336\n",
            "[66]\tvalid_0's multi_logloss: 0.530038\n",
            "[67]\tvalid_0's multi_logloss: 0.527712\n",
            "[68]\tvalid_0's multi_logloss: 0.526404\n",
            "[69]\tvalid_0's multi_logloss: 0.524195\n",
            "[70]\tvalid_0's multi_logloss: 0.522176\n",
            "[71]\tvalid_0's multi_logloss: 0.520115\n",
            "[72]\tvalid_0's multi_logloss: 0.518234\n",
            "[73]\tvalid_0's multi_logloss: 0.516962\n",
            "[74]\tvalid_0's multi_logloss: 0.51499\n",
            "[75]\tvalid_0's multi_logloss: 0.512952\n",
            "[76]\tvalid_0's multi_logloss: 0.511492\n",
            "[77]\tvalid_0's multi_logloss: 0.509674\n",
            "[78]\tvalid_0's multi_logloss: 0.507893\n",
            "[79]\tvalid_0's multi_logloss: 0.506395\n",
            "[80]\tvalid_0's multi_logloss: 0.504533\n",
            "[81]\tvalid_0's multi_logloss: 0.502709\n",
            "[82]\tvalid_0's multi_logloss: 0.500767\n",
            "[83]\tvalid_0's multi_logloss: 0.49945\n",
            "[84]\tvalid_0's multi_logloss: 0.497756\n",
            "[85]\tvalid_0's multi_logloss: 0.496547\n",
            "[86]\tvalid_0's multi_logloss: 0.494742\n",
            "[87]\tvalid_0's multi_logloss: 0.493403\n",
            "[88]\tvalid_0's multi_logloss: 0.491621\n",
            "[89]\tvalid_0's multi_logloss: 0.489792\n",
            "[90]\tvalid_0's multi_logloss: 0.488223\n",
            "[91]\tvalid_0's multi_logloss: 0.4872\n",
            "[92]\tvalid_0's multi_logloss: 0.486108\n",
            "[93]\tvalid_0's multi_logloss: 0.484936\n",
            "[94]\tvalid_0's multi_logloss: 0.483751\n",
            "[95]\tvalid_0's multi_logloss: 0.482008\n",
            "[96]\tvalid_0's multi_logloss: 0.48079\n",
            "[97]\tvalid_0's multi_logloss: 0.479721\n",
            "[98]\tvalid_0's multi_logloss: 0.478084\n",
            "[99]\tvalid_0's multi_logloss: 0.476379\n",
            "[100]\tvalid_0's multi_logloss: 0.475177\n",
            "[101]\tvalid_0's multi_logloss: 0.473499\n",
            "[102]\tvalid_0's multi_logloss: 0.471878\n",
            "[103]\tvalid_0's multi_logloss: 0.470722\n",
            "[104]\tvalid_0's multi_logloss: 0.469261\n",
            "[105]\tvalid_0's multi_logloss: 0.467745\n",
            "[106]\tvalid_0's multi_logloss: 0.466833\n",
            "[107]\tvalid_0's multi_logloss: 0.465354\n",
            "[108]\tvalid_0's multi_logloss: 0.46396\n",
            "[109]\tvalid_0's multi_logloss: 0.462412\n",
            "[110]\tvalid_0's multi_logloss: 0.460891\n",
            "[111]\tvalid_0's multi_logloss: 0.45991\n",
            "[112]\tvalid_0's multi_logloss: 0.458918\n",
            "[113]\tvalid_0's multi_logloss: 0.457529\n",
            "[114]\tvalid_0's multi_logloss: 0.456136\n",
            "[115]\tvalid_0's multi_logloss: 0.454678\n",
            "[116]\tvalid_0's multi_logloss: 0.453802\n",
            "[117]\tvalid_0's multi_logloss: 0.45231\n",
            "[118]\tvalid_0's multi_logloss: 0.451177\n",
            "[119]\tvalid_0's multi_logloss: 0.449852\n",
            "[120]\tvalid_0's multi_logloss: 0.448952\n",
            "[121]\tvalid_0's multi_logloss: 0.447561\n",
            "[122]\tvalid_0's multi_logloss: 0.446269\n",
            "[123]\tvalid_0's multi_logloss: 0.445282\n",
            "[124]\tvalid_0's multi_logloss: 0.444453\n",
            "[125]\tvalid_0's multi_logloss: 0.443514\n",
            "[126]\tvalid_0's multi_logloss: 0.442226\n",
            "[127]\tvalid_0's multi_logloss: 0.440839\n",
            "[128]\tvalid_0's multi_logloss: 0.439534\n",
            "[129]\tvalid_0's multi_logloss: 0.438381\n",
            "[130]\tvalid_0's multi_logloss: 0.437442\n",
            "[131]\tvalid_0's multi_logloss: 0.436563\n",
            "[132]\tvalid_0's multi_logloss: 0.435666\n",
            "[133]\tvalid_0's multi_logloss: 0.434783\n",
            "[134]\tvalid_0's multi_logloss: 0.433871\n",
            "[135]\tvalid_0's multi_logloss: 0.432665\n",
            "[136]\tvalid_0's multi_logloss: 0.431344\n",
            "[137]\tvalid_0's multi_logloss: 0.430485\n",
            "[138]\tvalid_0's multi_logloss: 0.429247\n",
            "[139]\tvalid_0's multi_logloss: 0.428008\n",
            "[140]\tvalid_0's multi_logloss: 0.427223\n",
            "[141]\tvalid_0's multi_logloss: 0.426378\n",
            "[142]\tvalid_0's multi_logloss: 0.425112\n",
            "[143]\tvalid_0's multi_logloss: 0.424237\n",
            "[144]\tvalid_0's multi_logloss: 0.423479\n",
            "[145]\tvalid_0's multi_logloss: 0.422254\n",
            "[146]\tvalid_0's multi_logloss: 0.421352\n",
            "[147]\tvalid_0's multi_logloss: 0.420152\n",
            "[148]\tvalid_0's multi_logloss: 0.419009\n",
            "[149]\tvalid_0's multi_logloss: 0.418254\n",
            "[150]\tvalid_0's multi_logloss: 0.417281\n",
            "[151]\tvalid_0's multi_logloss: 0.41622\n",
            "[152]\tvalid_0's multi_logloss: 0.415131\n",
            "[153]\tvalid_0's multi_logloss: 0.414046\n",
            "[154]\tvalid_0's multi_logloss: 0.412999\n",
            "[155]\tvalid_0's multi_logloss: 0.411945\n",
            "[156]\tvalid_0's multi_logloss: 0.410866\n",
            "[157]\tvalid_0's multi_logloss: 0.40985\n",
            "[158]\tvalid_0's multi_logloss: 0.408749\n",
            "[159]\tvalid_0's multi_logloss: 0.408082\n",
            "[160]\tvalid_0's multi_logloss: 0.407382\n",
            "[161]\tvalid_0's multi_logloss: 0.40626\n",
            "[162]\tvalid_0's multi_logloss: 0.405444\n",
            "[163]\tvalid_0's multi_logloss: 0.404644\n",
            "[164]\tvalid_0's multi_logloss: 0.403652\n",
            "[165]\tvalid_0's multi_logloss: 0.402998\n",
            "[166]\tvalid_0's multi_logloss: 0.402019\n",
            "[167]\tvalid_0's multi_logloss: 0.401273\n",
            "[168]\tvalid_0's multi_logloss: 0.400237\n",
            "[169]\tvalid_0's multi_logloss: 0.399522\n",
            "[170]\tvalid_0's multi_logloss: 0.39854\n",
            "[171]\tvalid_0's multi_logloss: 0.397519\n",
            "[172]\tvalid_0's multi_logloss: 0.396937\n",
            "[173]\tvalid_0's multi_logloss: 0.395964\n",
            "[174]\tvalid_0's multi_logloss: 0.394966\n",
            "[175]\tvalid_0's multi_logloss: 0.394248\n",
            "[176]\tvalid_0's multi_logloss: 0.393334\n",
            "[177]\tvalid_0's multi_logloss: 0.392414\n",
            "[178]\tvalid_0's multi_logloss: 0.391852\n",
            "[179]\tvalid_0's multi_logloss: 0.390963\n",
            "[180]\tvalid_0's multi_logloss: 0.390036\n",
            "[181]\tvalid_0's multi_logloss: 0.389203\n",
            "[182]\tvalid_0's multi_logloss: 0.388314\n",
            "[183]\tvalid_0's multi_logloss: 0.387721\n",
            "[184]\tvalid_0's multi_logloss: 0.386883\n",
            "[185]\tvalid_0's multi_logloss: 0.385952\n",
            "[186]\tvalid_0's multi_logloss: 0.385283\n",
            "[187]\tvalid_0's multi_logloss: 0.384471\n",
            "[188]\tvalid_0's multi_logloss: 0.383884\n",
            "[189]\tvalid_0's multi_logloss: 0.383328\n",
            "[190]\tvalid_0's multi_logloss: 0.3824\n",
            "[191]\tvalid_0's multi_logloss: 0.381563\n",
            "[192]\tvalid_0's multi_logloss: 0.380704\n",
            "[193]\tvalid_0's multi_logloss: 0.380061\n",
            "[194]\tvalid_0's multi_logloss: 0.37914\n",
            "[195]\tvalid_0's multi_logloss: 0.378284\n",
            "[196]\tvalid_0's multi_logloss: 0.37763\n",
            "[197]\tvalid_0's multi_logloss: 0.377096\n",
            "[198]\tvalid_0's multi_logloss: 0.376257\n",
            "[199]\tvalid_0's multi_logloss: 0.375419\n",
            "[200]\tvalid_0's multi_logloss: 0.374542\n",
            "[201]\tvalid_0's multi_logloss: 0.373969\n",
            "[202]\tvalid_0's multi_logloss: 0.373142\n",
            "[203]\tvalid_0's multi_logloss: 0.372659\n",
            "[204]\tvalid_0's multi_logloss: 0.371863\n",
            "[205]\tvalid_0's multi_logloss: 0.371326\n",
            "[206]\tvalid_0's multi_logloss: 0.370526\n",
            "[207]\tvalid_0's multi_logloss: 0.3697\n",
            "[208]\tvalid_0's multi_logloss: 0.368944\n",
            "[209]\tvalid_0's multi_logloss: 0.368397\n",
            "[210]\tvalid_0's multi_logloss: 0.367852\n",
            "[211]\tvalid_0's multi_logloss: 0.367092\n",
            "[212]\tvalid_0's multi_logloss: 0.366326\n",
            "[213]\tvalid_0's multi_logloss: 0.365563\n",
            "[214]\tvalid_0's multi_logloss: 0.365018\n",
            "[215]\tvalid_0's multi_logloss: 0.364264\n",
            "[216]\tvalid_0's multi_logloss: 0.363697\n",
            "[217]\tvalid_0's multi_logloss: 0.363202\n",
            "[218]\tvalid_0's multi_logloss: 0.36247\n",
            "[219]\tvalid_0's multi_logloss: 0.361763\n",
            "[220]\tvalid_0's multi_logloss: 0.361057\n",
            "[221]\tvalid_0's multi_logloss: 0.360292\n",
            "[222]\tvalid_0's multi_logloss: 0.359599\n",
            "[223]\tvalid_0's multi_logloss: 0.358867\n",
            "[224]\tvalid_0's multi_logloss: 0.358363\n",
            "[225]\tvalid_0's multi_logloss: 0.357575\n",
            "[226]\tvalid_0's multi_logloss: 0.356809\n",
            "[227]\tvalid_0's multi_logloss: 0.356137\n",
            "[228]\tvalid_0's multi_logloss: 0.35543\n",
            "[229]\tvalid_0's multi_logloss: 0.355002\n",
            "[230]\tvalid_0's multi_logloss: 0.35429\n",
            "[231]\tvalid_0's multi_logloss: 0.353598\n",
            "[232]\tvalid_0's multi_logloss: 0.352922\n",
            "[233]\tvalid_0's multi_logloss: 0.352237\n",
            "[234]\tvalid_0's multi_logloss: 0.351502\n",
            "[235]\tvalid_0's multi_logloss: 0.350818\n",
            "[236]\tvalid_0's multi_logloss: 0.350343\n",
            "[237]\tvalid_0's multi_logloss: 0.349884\n",
            "[238]\tvalid_0's multi_logloss: 0.349224\n",
            "[239]\tvalid_0's multi_logloss: 0.348535\n",
            "[240]\tvalid_0's multi_logloss: 0.348063\n",
            "[241]\tvalid_0's multi_logloss: 0.347408\n",
            "[242]\tvalid_0's multi_logloss: 0.346735\n",
            "[243]\tvalid_0's multi_logloss: 0.346034\n",
            "[244]\tvalid_0's multi_logloss: 0.345579\n",
            "[245]\tvalid_0's multi_logloss: 0.345129\n",
            "[246]\tvalid_0's multi_logloss: 0.344438\n",
            "[247]\tvalid_0's multi_logloss: 0.344024\n",
            "[248]\tvalid_0's multi_logloss: 0.343613\n",
            "[249]\tvalid_0's multi_logloss: 0.343167\n",
            "[250]\tvalid_0's multi_logloss: 0.342491\n",
            "[251]\tvalid_0's multi_logloss: 0.342047\n",
            "[252]\tvalid_0's multi_logloss: 0.341619\n",
            "[253]\tvalid_0's multi_logloss: 0.341145\n",
            "[254]\tvalid_0's multi_logloss: 0.340545\n",
            "[255]\tvalid_0's multi_logloss: 0.339913\n",
            "[256]\tvalid_0's multi_logloss: 0.339501\n",
            "[257]\tvalid_0's multi_logloss: 0.339083\n",
            "[258]\tvalid_0's multi_logloss: 0.338424\n",
            "[259]\tvalid_0's multi_logloss: 0.337982\n",
            "[260]\tvalid_0's multi_logloss: 0.337554\n",
            "[261]\tvalid_0's multi_logloss: 0.336982\n",
            "[262]\tvalid_0's multi_logloss: 0.33653\n",
            "[263]\tvalid_0's multi_logloss: 0.335901\n",
            "[264]\tvalid_0's multi_logloss: 0.335247\n",
            "[265]\tvalid_0's multi_logloss: 0.334624\n",
            "[266]\tvalid_0's multi_logloss: 0.334012\n",
            "[267]\tvalid_0's multi_logloss: 0.33336\n",
            "[268]\tvalid_0's multi_logloss: 0.333004\n",
            "[269]\tvalid_0's multi_logloss: 0.332455\n",
            "[270]\tvalid_0's multi_logloss: 0.331929\n",
            "[271]\tvalid_0's multi_logloss: 0.331367\n",
            "[272]\tvalid_0's multi_logloss: 0.330754\n",
            "[273]\tvalid_0's multi_logloss: 0.330197\n",
            "[274]\tvalid_0's multi_logloss: 0.329627\n",
            "[275]\tvalid_0's multi_logloss: 0.329046\n",
            "[276]\tvalid_0's multi_logloss: 0.328476\n",
            "[277]\tvalid_0's multi_logloss: 0.327926\n",
            "[278]\tvalid_0's multi_logloss: 0.327359\n",
            "[279]\tvalid_0's multi_logloss: 0.326799\n",
            "[280]\tvalid_0's multi_logloss: 0.326263\n",
            "[281]\tvalid_0's multi_logloss: 0.325661\n",
            "[282]\tvalid_0's multi_logloss: 0.325314\n",
            "[283]\tvalid_0's multi_logloss: 0.32477\n",
            "[284]\tvalid_0's multi_logloss: 0.324233\n",
            "[285]\tvalid_0's multi_logloss: 0.323692\n",
            "[286]\tvalid_0's multi_logloss: 0.32314\n",
            "[287]\tvalid_0's multi_logloss: 0.32259\n",
            "[288]\tvalid_0's multi_logloss: 0.322072\n",
            "[289]\tvalid_0's multi_logloss: 0.321489\n",
            "[290]\tvalid_0's multi_logloss: 0.320954\n",
            "[291]\tvalid_0's multi_logloss: 0.320622\n",
            "[292]\tvalid_0's multi_logloss: 0.32021\n",
            "[293]\tvalid_0's multi_logloss: 0.319662\n",
            "[294]\tvalid_0's multi_logloss: 0.319314\n",
            "[295]\tvalid_0's multi_logloss: 0.31898\n",
            "[296]\tvalid_0's multi_logloss: 0.318449\n",
            "[297]\tvalid_0's multi_logloss: 0.318091\n",
            "[298]\tvalid_0's multi_logloss: 0.317579\n",
            "[299]\tvalid_0's multi_logloss: 0.317053\n",
            "[300]\tvalid_0's multi_logloss: 0.316552\n",
            "[301]\tvalid_0's multi_logloss: 0.316085\n",
            "[302]\tvalid_0's multi_logloss: 0.315601\n",
            "[303]\tvalid_0's multi_logloss: 0.315256\n",
            "[304]\tvalid_0's multi_logloss: 0.31477\n",
            "[305]\tvalid_0's multi_logloss: 0.31426\n",
            "[306]\tvalid_0's multi_logloss: 0.313928\n",
            "[307]\tvalid_0's multi_logloss: 0.313433\n",
            "[308]\tvalid_0's multi_logloss: 0.313088\n",
            "[309]\tvalid_0's multi_logloss: 0.312798\n",
            "[310]\tvalid_0's multi_logloss: 0.312439\n",
            "[311]\tvalid_0's multi_logloss: 0.311972\n",
            "[312]\tvalid_0's multi_logloss: 0.311448\n",
            "[313]\tvalid_0's multi_logloss: 0.310947\n",
            "[314]\tvalid_0's multi_logloss: 0.310663\n",
            "[315]\tvalid_0's multi_logloss: 0.310324\n",
            "[316]\tvalid_0's multi_logloss: 0.30981\n",
            "[317]\tvalid_0's multi_logloss: 0.309351\n",
            "[318]\tvalid_0's multi_logloss: 0.309044\n",
            "[319]\tvalid_0's multi_logloss: 0.308714\n",
            "[320]\tvalid_0's multi_logloss: 0.308369\n",
            "[321]\tvalid_0's multi_logloss: 0.307902\n",
            "[322]\tvalid_0's multi_logloss: 0.30743\n",
            "[323]\tvalid_0's multi_logloss: 0.306958\n",
            "[324]\tvalid_0's multi_logloss: 0.306464\n",
            "[325]\tvalid_0's multi_logloss: 0.306011\n",
            "[326]\tvalid_0's multi_logloss: 0.305534\n",
            "[327]\tvalid_0's multi_logloss: 0.305225\n",
            "[328]\tvalid_0's multi_logloss: 0.304757\n",
            "[329]\tvalid_0's multi_logloss: 0.304421\n",
            "[330]\tvalid_0's multi_logloss: 0.303967\n",
            "[331]\tvalid_0's multi_logloss: 0.303534\n",
            "[332]\tvalid_0's multi_logloss: 0.30309\n",
            "[333]\tvalid_0's multi_logloss: 0.302783\n",
            "[334]\tvalid_0's multi_logloss: 0.302493\n",
            "[335]\tvalid_0's multi_logloss: 0.302239\n",
            "[336]\tvalid_0's multi_logloss: 0.301811\n",
            "[337]\tvalid_0's multi_logloss: 0.301532\n",
            "[338]\tvalid_0's multi_logloss: 0.301108\n",
            "[339]\tvalid_0's multi_logloss: 0.300797\n",
            "[340]\tvalid_0's multi_logloss: 0.300373\n",
            "[341]\tvalid_0's multi_logloss: 0.299912\n",
            "[342]\tvalid_0's multi_logloss: 0.299474\n",
            "[343]\tvalid_0's multi_logloss: 0.299165\n",
            "[344]\tvalid_0's multi_logloss: 0.29875\n",
            "[345]\tvalid_0's multi_logloss: 0.29832\n",
            "[346]\tvalid_0's multi_logloss: 0.297875\n",
            "[347]\tvalid_0's multi_logloss: 0.297613\n",
            "[348]\tvalid_0's multi_logloss: 0.297339\n",
            "[349]\tvalid_0's multi_logloss: 0.296909\n",
            "[350]\tvalid_0's multi_logloss: 0.296505\n",
            "[351]\tvalid_0's multi_logloss: 0.296235\n",
            "[352]\tvalid_0's multi_logloss: 0.295813\n",
            "[353]\tvalid_0's multi_logloss: 0.295513\n",
            "[354]\tvalid_0's multi_logloss: 0.295251\n",
            "[355]\tvalid_0's multi_logloss: 0.294831\n",
            "[356]\tvalid_0's multi_logloss: 0.294588\n",
            "[357]\tvalid_0's multi_logloss: 0.294293\n",
            "[358]\tvalid_0's multi_logloss: 0.294031\n",
            "[359]\tvalid_0's multi_logloss: 0.293603\n",
            "[360]\tvalid_0's multi_logloss: 0.293195\n",
            "[361]\tvalid_0's multi_logloss: 0.292786\n",
            "[362]\tvalid_0's multi_logloss: 0.292387\n",
            "[363]\tvalid_0's multi_logloss: 0.292011\n",
            "[364]\tvalid_0's multi_logloss: 0.291738\n",
            "[365]\tvalid_0's multi_logloss: 0.291328\n",
            "[366]\tvalid_0's multi_logloss: 0.291063\n",
            "[367]\tvalid_0's multi_logloss: 0.290805\n",
            "[368]\tvalid_0's multi_logloss: 0.290552\n",
            "[369]\tvalid_0's multi_logloss: 0.290278\n",
            "[370]\tvalid_0's multi_logloss: 0.289923\n",
            "[371]\tvalid_0's multi_logloss: 0.28965\n",
            "[372]\tvalid_0's multi_logloss: 0.289257\n",
            "[373]\tvalid_0's multi_logloss: 0.289\n",
            "[374]\tvalid_0's multi_logloss: 0.288609\n",
            "[375]\tvalid_0's multi_logloss: 0.28821\n",
            "[376]\tvalid_0's multi_logloss: 0.287927\n",
            "[377]\tvalid_0's multi_logloss: 0.28757\n",
            "[378]\tvalid_0's multi_logloss: 0.287342\n",
            "[379]\tvalid_0's multi_logloss: 0.286971\n",
            "[380]\tvalid_0's multi_logloss: 0.286623\n",
            "[381]\tvalid_0's multi_logloss: 0.286253\n",
            "[382]\tvalid_0's multi_logloss: 0.28598\n",
            "[383]\tvalid_0's multi_logloss: 0.285698\n",
            "[384]\tvalid_0's multi_logloss: 0.285475\n",
            "[385]\tvalid_0's multi_logloss: 0.285222\n",
            "[386]\tvalid_0's multi_logloss: 0.284847\n",
            "[387]\tvalid_0's multi_logloss: 0.284582\n",
            "[388]\tvalid_0's multi_logloss: 0.284192\n",
            "[389]\tvalid_0's multi_logloss: 0.283818\n",
            "[390]\tvalid_0's multi_logloss: 0.283458\n",
            "[391]\tvalid_0's multi_logloss: 0.283226\n",
            "[392]\tvalid_0's multi_logloss: 0.283\n",
            "[393]\tvalid_0's multi_logloss: 0.282602\n",
            "[394]\tvalid_0's multi_logloss: 0.282239\n",
            "[395]\tvalid_0's multi_logloss: 0.282\n",
            "[396]\tvalid_0's multi_logloss: 0.28178\n",
            "[397]\tvalid_0's multi_logloss: 0.281422\n",
            "[398]\tvalid_0's multi_logloss: 0.281164\n",
            "[399]\tvalid_0's multi_logloss: 0.280932\n",
            "[400]\tvalid_0's multi_logloss: 0.280569\n",
            "[401]\tvalid_0's multi_logloss: 0.280343\n",
            "[402]\tvalid_0's multi_logloss: 0.279996\n",
            "[403]\tvalid_0's multi_logloss: 0.279655\n",
            "[404]\tvalid_0's multi_logloss: 0.279321\n",
            "[405]\tvalid_0's multi_logloss: 0.279103\n",
            "[406]\tvalid_0's multi_logloss: 0.278893\n",
            "[407]\tvalid_0's multi_logloss: 0.278542\n",
            "[408]\tvalid_0's multi_logloss: 0.278315\n",
            "[409]\tvalid_0's multi_logloss: 0.277994\n",
            "[410]\tvalid_0's multi_logloss: 0.277767\n",
            "[411]\tvalid_0's multi_logloss: 0.277556\n",
            "[412]\tvalid_0's multi_logloss: 0.277225\n",
            "[413]\tvalid_0's multi_logloss: 0.277014\n",
            "[414]\tvalid_0's multi_logloss: 0.27669\n",
            "[415]\tvalid_0's multi_logloss: 0.276499\n",
            "[416]\tvalid_0's multi_logloss: 0.276149\n",
            "[417]\tvalid_0's multi_logloss: 0.275928\n",
            "[418]\tvalid_0's multi_logloss: 0.275598\n",
            "[419]\tvalid_0's multi_logloss: 0.27538\n",
            "[420]\tvalid_0's multi_logloss: 0.275035\n",
            "[421]\tvalid_0's multi_logloss: 0.27482\n",
            "[422]\tvalid_0's multi_logloss: 0.274507\n",
            "[423]\tvalid_0's multi_logloss: 0.274285\n",
            "[424]\tvalid_0's multi_logloss: 0.273984\n",
            "[425]\tvalid_0's multi_logloss: 0.273669\n",
            "[426]\tvalid_0's multi_logloss: 0.273335\n",
            "[427]\tvalid_0's multi_logloss: 0.273015\n",
            "[428]\tvalid_0's multi_logloss: 0.272702\n",
            "[429]\tvalid_0's multi_logloss: 0.272391\n",
            "[430]\tvalid_0's multi_logloss: 0.272082\n",
            "[431]\tvalid_0's multi_logloss: 0.271859\n",
            "[432]\tvalid_0's multi_logloss: 0.271656\n",
            "[433]\tvalid_0's multi_logloss: 0.271432\n",
            "[434]\tvalid_0's multi_logloss: 0.27125\n",
            "[435]\tvalid_0's multi_logloss: 0.270911\n",
            "[436]\tvalid_0's multi_logloss: 0.270719\n",
            "[437]\tvalid_0's multi_logloss: 0.270407\n",
            "[438]\tvalid_0's multi_logloss: 0.270106\n",
            "[439]\tvalid_0's multi_logloss: 0.26982\n",
            "[440]\tvalid_0's multi_logloss: 0.269643\n",
            "[441]\tvalid_0's multi_logloss: 0.269336\n",
            "[442]\tvalid_0's multi_logloss: 0.269024\n",
            "[443]\tvalid_0's multi_logloss: 0.268858\n",
            "[444]\tvalid_0's multi_logloss: 0.268546\n",
            "[445]\tvalid_0's multi_logloss: 0.268369\n",
            "[446]\tvalid_0's multi_logloss: 0.268045\n",
            "[447]\tvalid_0's multi_logloss: 0.267766\n",
            "[448]\tvalid_0's multi_logloss: 0.267467\n",
            "[449]\tvalid_0's multi_logloss: 0.267169\n",
            "[450]\tvalid_0's multi_logloss: 0.266964\n",
            "[451]\tvalid_0's multi_logloss: 0.266773\n",
            "[452]\tvalid_0's multi_logloss: 0.26649\n",
            "[453]\tvalid_0's multi_logloss: 0.266215\n",
            "[454]\tvalid_0's multi_logloss: 0.26592\n",
            "[455]\tvalid_0's multi_logloss: 0.265747\n",
            "[456]\tvalid_0's multi_logloss: 0.265446\n",
            "[457]\tvalid_0's multi_logloss: 0.26524\n",
            "[458]\tvalid_0's multi_logloss: 0.264936\n",
            "[459]\tvalid_0's multi_logloss: 0.264643\n",
            "[460]\tvalid_0's multi_logloss: 0.26434\n",
            "[461]\tvalid_0's multi_logloss: 0.264054\n",
            "[462]\tvalid_0's multi_logloss: 0.263794\n",
            "[463]\tvalid_0's multi_logloss: 0.263609\n",
            "[464]\tvalid_0's multi_logloss: 0.263324\n",
            "[465]\tvalid_0's multi_logloss: 0.26316\n",
            "[466]\tvalid_0's multi_logloss: 0.262979\n",
            "[467]\tvalid_0's multi_logloss: 0.26281\n",
            "[468]\tvalid_0's multi_logloss: 0.262526\n",
            "[469]\tvalid_0's multi_logloss: 0.262262\n",
            "[470]\tvalid_0's multi_logloss: 0.261985\n",
            "[471]\tvalid_0's multi_logloss: 0.261828\n",
            "[472]\tvalid_0's multi_logloss: 0.261627\n",
            "[473]\tvalid_0's multi_logloss: 0.261355\n",
            "[474]\tvalid_0's multi_logloss: 0.261086\n",
            "[475]\tvalid_0's multi_logloss: 0.260911\n",
            "[476]\tvalid_0's multi_logloss: 0.260645\n",
            "[477]\tvalid_0's multi_logloss: 0.2604\n",
            "[478]\tvalid_0's multi_logloss: 0.26012\n",
            "[479]\tvalid_0's multi_logloss: 0.259844\n",
            "[480]\tvalid_0's multi_logloss: 0.259571\n",
            "[481]\tvalid_0's multi_logloss: 0.259408\n",
            "[482]\tvalid_0's multi_logloss: 0.259242\n",
            "[483]\tvalid_0's multi_logloss: 0.259069\n",
            "[484]\tvalid_0's multi_logloss: 0.258824\n",
            "[485]\tvalid_0's multi_logloss: 0.258676\n",
            "[486]\tvalid_0's multi_logloss: 0.258519\n",
            "[487]\tvalid_0's multi_logloss: 0.258341\n",
            "[488]\tvalid_0's multi_logloss: 0.258164\n",
            "[489]\tvalid_0's multi_logloss: 0.257907\n",
            "[490]\tvalid_0's multi_logloss: 0.25774\n",
            "[491]\tvalid_0's multi_logloss: 0.257482\n",
            "[492]\tvalid_0's multi_logloss: 0.257223\n",
            "[493]\tvalid_0's multi_logloss: 0.257043\n",
            "[494]\tvalid_0's multi_logloss: 0.256782\n",
            "[495]\tvalid_0's multi_logloss: 0.256613\n",
            "[496]\tvalid_0's multi_logloss: 0.25635\n",
            "[497]\tvalid_0's multi_logloss: 0.256112\n",
            "[498]\tvalid_0's multi_logloss: 0.25586\n",
            "[499]\tvalid_0's multi_logloss: 0.255602\n",
            "[500]\tvalid_0's multi_logloss: 0.255444\n",
            "[501]\tvalid_0's multi_logloss: 0.255262\n",
            "[502]\tvalid_0's multi_logloss: 0.255107\n",
            "[503]\tvalid_0's multi_logloss: 0.254948\n",
            "[504]\tvalid_0's multi_logloss: 0.254709\n",
            "[505]\tvalid_0's multi_logloss: 0.254472\n",
            "[506]\tvalid_0's multi_logloss: 0.254222\n",
            "[507]\tvalid_0's multi_logloss: 0.254067\n",
            "[508]\tvalid_0's multi_logloss: 0.253815\n",
            "[509]\tvalid_0's multi_logloss: 0.253662\n",
            "[510]\tvalid_0's multi_logloss: 0.253488\n",
            "[511]\tvalid_0's multi_logloss: 0.253334\n",
            "[512]\tvalid_0's multi_logloss: 0.253102\n",
            "[513]\tvalid_0's multi_logloss: 0.252858\n",
            "[514]\tvalid_0's multi_logloss: 0.252704\n",
            "[515]\tvalid_0's multi_logloss: 0.252471\n",
            "[516]\tvalid_0's multi_logloss: 0.252254\n",
            "[517]\tvalid_0's multi_logloss: 0.252085\n",
            "[518]\tvalid_0's multi_logloss: 0.251923\n",
            "[519]\tvalid_0's multi_logloss: 0.251687\n",
            "[520]\tvalid_0's multi_logloss: 0.251453\n",
            "[521]\tvalid_0's multi_logloss: 0.251293\n",
            "[522]\tvalid_0's multi_logloss: 0.251133\n",
            "[523]\tvalid_0's multi_logloss: 0.250987\n",
            "[524]\tvalid_0's multi_logloss: 0.250832\n",
            "[525]\tvalid_0's multi_logloss: 0.250666\n",
            "[526]\tvalid_0's multi_logloss: 0.250427\n",
            "[527]\tvalid_0's multi_logloss: 0.250206\n",
            "[528]\tvalid_0's multi_logloss: 0.249998\n",
            "[529]\tvalid_0's multi_logloss: 0.249851\n",
            "[530]\tvalid_0's multi_logloss: 0.249618\n",
            "[531]\tvalid_0's multi_logloss: 0.249397\n",
            "[532]\tvalid_0's multi_logloss: 0.24917\n",
            "[533]\tvalid_0's multi_logloss: 0.24896\n",
            "[534]\tvalid_0's multi_logloss: 0.248827\n",
            "[535]\tvalid_0's multi_logloss: 0.248601\n",
            "[536]\tvalid_0's multi_logloss: 0.248447\n",
            "[537]\tvalid_0's multi_logloss: 0.24822\n",
            "[538]\tvalid_0's multi_logloss: 0.247998\n",
            "[539]\tvalid_0's multi_logloss: 0.247875\n",
            "[540]\tvalid_0's multi_logloss: 0.247662\n",
            "[541]\tvalid_0's multi_logloss: 0.247424\n",
            "[542]\tvalid_0's multi_logloss: 0.24729\n",
            "[543]\tvalid_0's multi_logloss: 0.247146\n",
            "[544]\tvalid_0's multi_logloss: 0.246932\n",
            "[545]\tvalid_0's multi_logloss: 0.246711\n",
            "[546]\tvalid_0's multi_logloss: 0.246582\n",
            "[547]\tvalid_0's multi_logloss: 0.246362\n",
            "[548]\tvalid_0's multi_logloss: 0.246228\n",
            "[549]\tvalid_0's multi_logloss: 0.246025\n",
            "[550]\tvalid_0's multi_logloss: 0.245799\n",
            "[551]\tvalid_0's multi_logloss: 0.245596\n",
            "[552]\tvalid_0's multi_logloss: 0.245463\n",
            "[553]\tvalid_0's multi_logloss: 0.245326\n",
            "[554]\tvalid_0's multi_logloss: 0.245204\n",
            "[555]\tvalid_0's multi_logloss: 0.24507\n",
            "[556]\tvalid_0's multi_logloss: 0.244856\n",
            "[557]\tvalid_0's multi_logloss: 0.244653\n",
            "[558]\tvalid_0's multi_logloss: 0.244432\n",
            "[559]\tvalid_0's multi_logloss: 0.244314\n",
            "[560]\tvalid_0's multi_logloss: 0.244112\n",
            "[561]\tvalid_0's multi_logloss: 0.243911\n",
            "[562]\tvalid_0's multi_logloss: 0.243702\n",
            "[563]\tvalid_0's multi_logloss: 0.243505\n",
            "[564]\tvalid_0's multi_logloss: 0.243286\n",
            "[565]\tvalid_0's multi_logloss: 0.243072\n",
            "[566]\tvalid_0's multi_logloss: 0.242883\n",
            "[567]\tvalid_0's multi_logloss: 0.242683\n",
            "[568]\tvalid_0's multi_logloss: 0.242481\n",
            "[569]\tvalid_0's multi_logloss: 0.242285\n",
            "[570]\tvalid_0's multi_logloss: 0.242086\n",
            "[571]\tvalid_0's multi_logloss: 0.241899\n",
            "[572]\tvalid_0's multi_logloss: 0.241697\n",
            "[573]\tvalid_0's multi_logloss: 0.241495\n",
            "[574]\tvalid_0's multi_logloss: 0.24129\n",
            "[575]\tvalid_0's multi_logloss: 0.241161\n",
            "[576]\tvalid_0's multi_logloss: 0.240946\n",
            "[577]\tvalid_0's multi_logloss: 0.240757\n",
            "[578]\tvalid_0's multi_logloss: 0.240627\n",
            "[579]\tvalid_0's multi_logloss: 0.240424\n",
            "[580]\tvalid_0's multi_logloss: 0.240294\n",
            "[581]\tvalid_0's multi_logloss: 0.240103\n",
            "[582]\tvalid_0's multi_logloss: 0.239895\n",
            "[583]\tvalid_0's multi_logloss: 0.239695\n",
            "[584]\tvalid_0's multi_logloss: 0.239491\n",
            "[585]\tvalid_0's multi_logloss: 0.239313\n",
            "[586]\tvalid_0's multi_logloss: 0.239127\n",
            "[587]\tvalid_0's multi_logloss: 0.239013\n",
            "[588]\tvalid_0's multi_logloss: 0.238886\n",
            "[589]\tvalid_0's multi_logloss: 0.238695\n",
            "[590]\tvalid_0's multi_logloss: 0.238508\n",
            "[591]\tvalid_0's multi_logloss: 0.238321\n",
            "[592]\tvalid_0's multi_logloss: 0.238211\n",
            "[593]\tvalid_0's multi_logloss: 0.238091\n",
            "[594]\tvalid_0's multi_logloss: 0.237893\n",
            "[595]\tvalid_0's multi_logloss: 0.23777\n",
            "[596]\tvalid_0's multi_logloss: 0.23758\n",
            "[597]\tvalid_0's multi_logloss: 0.237461\n",
            "[598]\tvalid_0's multi_logloss: 0.237343\n",
            "[599]\tvalid_0's multi_logloss: 0.237156\n",
            "[600]\tvalid_0's multi_logloss: 0.23698\n",
            "[601]\tvalid_0's multi_logloss: 0.236857\n",
            "[602]\tvalid_0's multi_logloss: 0.236687\n",
            "[603]\tvalid_0's multi_logloss: 0.236508\n",
            "[604]\tvalid_0's multi_logloss: 0.236383\n",
            "[605]\tvalid_0's multi_logloss: 0.236263\n",
            "[606]\tvalid_0's multi_logloss: 0.23614\n",
            "[607]\tvalid_0's multi_logloss: 0.235966\n",
            "[608]\tvalid_0's multi_logloss: 0.235791\n",
            "[609]\tvalid_0's multi_logloss: 0.235612\n",
            "[610]\tvalid_0's multi_logloss: 0.235435\n",
            "[611]\tvalid_0's multi_logloss: 0.235328\n",
            "[612]\tvalid_0's multi_logloss: 0.235155\n",
            "[613]\tvalid_0's multi_logloss: 0.234969\n",
            "[614]\tvalid_0's multi_logloss: 0.234847\n",
            "[615]\tvalid_0's multi_logloss: 0.234675\n",
            "[616]\tvalid_0's multi_logloss: 0.23449\n",
            "[617]\tvalid_0's multi_logloss: 0.23431\n",
            "[618]\tvalid_0's multi_logloss: 0.23414\n",
            "[619]\tvalid_0's multi_logloss: 0.234036\n",
            "[620]\tvalid_0's multi_logloss: 0.233869\n",
            "[621]\tvalid_0's multi_logloss: 0.2337\n",
            "[622]\tvalid_0's multi_logloss: 0.233516\n",
            "[623]\tvalid_0's multi_logloss: 0.233398\n",
            "[624]\tvalid_0's multi_logloss: 0.233273\n",
            "[625]\tvalid_0's multi_logloss: 0.233099\n",
            "[626]\tvalid_0's multi_logloss: 0.232984\n",
            "[627]\tvalid_0's multi_logloss: 0.232865\n",
            "[628]\tvalid_0's multi_logloss: 0.232702\n",
            "[629]\tvalid_0's multi_logloss: 0.232537\n",
            "[630]\tvalid_0's multi_logloss: 0.23238\n",
            "[631]\tvalid_0's multi_logloss: 0.232216\n",
            "[632]\tvalid_0's multi_logloss: 0.232048\n",
            "[633]\tvalid_0's multi_logloss: 0.231871\n",
            "[634]\tvalid_0's multi_logloss: 0.231764\n",
            "[635]\tvalid_0's multi_logloss: 0.231602\n",
            "[636]\tvalid_0's multi_logloss: 0.231499\n",
            "[637]\tvalid_0's multi_logloss: 0.231338\n",
            "[638]\tvalid_0's multi_logloss: 0.231175\n",
            "[639]\tvalid_0's multi_logloss: 0.231022\n",
            "[640]\tvalid_0's multi_logloss: 0.230925\n",
            "[641]\tvalid_0's multi_logloss: 0.230815\n",
            "[642]\tvalid_0's multi_logloss: 0.23071\n",
            "[643]\tvalid_0's multi_logloss: 0.230553\n",
            "[644]\tvalid_0's multi_logloss: 0.230387\n",
            "[645]\tvalid_0's multi_logloss: 0.230291\n",
            "[646]\tvalid_0's multi_logloss: 0.230128\n",
            "[647]\tvalid_0's multi_logloss: 0.229967\n",
            "[648]\tvalid_0's multi_logloss: 0.229805\n",
            "[649]\tvalid_0's multi_logloss: 0.229687\n",
            "[650]\tvalid_0's multi_logloss: 0.229583\n",
            "[651]\tvalid_0's multi_logloss: 0.229423\n",
            "[652]\tvalid_0's multi_logloss: 0.229318\n",
            "[653]\tvalid_0's multi_logloss: 0.229208\n",
            "[654]\tvalid_0's multi_logloss: 0.229052\n",
            "[655]\tvalid_0's multi_logloss: 0.228905\n",
            "[656]\tvalid_0's multi_logloss: 0.228799\n",
            "[657]\tvalid_0's multi_logloss: 0.228689\n",
            "[658]\tvalid_0's multi_logloss: 0.228526\n",
            "[659]\tvalid_0's multi_logloss: 0.228372\n",
            "[660]\tvalid_0's multi_logloss: 0.228214\n",
            "[661]\tvalid_0's multi_logloss: 0.228105\n",
            "[662]\tvalid_0's multi_logloss: 0.227956\n",
            "[663]\tvalid_0's multi_logloss: 0.227802\n",
            "[664]\tvalid_0's multi_logloss: 0.227696\n",
            "[665]\tvalid_0's multi_logloss: 0.227604\n",
            "[666]\tvalid_0's multi_logloss: 0.227501\n",
            "[667]\tvalid_0's multi_logloss: 0.227404\n",
            "[668]\tvalid_0's multi_logloss: 0.227306\n",
            "[669]\tvalid_0's multi_logloss: 0.22721\n",
            "[670]\tvalid_0's multi_logloss: 0.227066\n",
            "[671]\tvalid_0's multi_logloss: 0.226961\n",
            "[672]\tvalid_0's multi_logloss: 0.226851\n",
            "[673]\tvalid_0's multi_logloss: 0.226754\n",
            "[674]\tvalid_0's multi_logloss: 0.226616\n",
            "[675]\tvalid_0's multi_logloss: 0.226466\n",
            "[676]\tvalid_0's multi_logloss: 0.226318\n",
            "[677]\tvalid_0's multi_logloss: 0.226183\n",
            "[678]\tvalid_0's multi_logloss: 0.226036\n",
            "[679]\tvalid_0's multi_logloss: 0.225903\n",
            "[680]\tvalid_0's multi_logloss: 0.225796\n",
            "[681]\tvalid_0's multi_logloss: 0.225642\n",
            "[682]\tvalid_0's multi_logloss: 0.225495\n",
            "[683]\tvalid_0's multi_logloss: 0.225355\n",
            "[684]\tvalid_0's multi_logloss: 0.225266\n",
            "[685]\tvalid_0's multi_logloss: 0.225164\n",
            "[686]\tvalid_0's multi_logloss: 0.225021\n",
            "[687]\tvalid_0's multi_logloss: 0.22492\n",
            "[688]\tvalid_0's multi_logloss: 0.224776\n",
            "[689]\tvalid_0's multi_logloss: 0.224625\n",
            "[690]\tvalid_0's multi_logloss: 0.22452\n",
            "[691]\tvalid_0's multi_logloss: 0.224379\n",
            "[692]\tvalid_0's multi_logloss: 0.22428\n",
            "[693]\tvalid_0's multi_logloss: 0.224202\n",
            "[694]\tvalid_0's multi_logloss: 0.224095\n",
            "[695]\tvalid_0's multi_logloss: 0.22395\n",
            "[696]\tvalid_0's multi_logloss: 0.223875\n",
            "[697]\tvalid_0's multi_logloss: 0.223738\n",
            "[698]\tvalid_0's multi_logloss: 0.223589\n",
            "[699]\tvalid_0's multi_logloss: 0.223493\n",
            "[700]\tvalid_0's multi_logloss: 0.223398\n",
            "[701]\tvalid_0's multi_logloss: 0.223259\n",
            "[702]\tvalid_0's multi_logloss: 0.223108\n",
            "[703]\tvalid_0's multi_logloss: 0.222974\n",
            "[704]\tvalid_0's multi_logloss: 0.22284\n",
            "[705]\tvalid_0's multi_logloss: 0.222749\n",
            "[706]\tvalid_0's multi_logloss: 0.222613\n",
            "[707]\tvalid_0's multi_logloss: 0.222512\n",
            "[708]\tvalid_0's multi_logloss: 0.22238\n",
            "[709]\tvalid_0's multi_logloss: 0.222251\n",
            "[710]\tvalid_0's multi_logloss: 0.222118\n",
            "[711]\tvalid_0's multi_logloss: 0.22198\n",
            "[712]\tvalid_0's multi_logloss: 0.221849\n",
            "[713]\tvalid_0's multi_logloss: 0.221714\n",
            "[714]\tvalid_0's multi_logloss: 0.221584\n",
            "[715]\tvalid_0's multi_logloss: 0.221498\n",
            "[716]\tvalid_0's multi_logloss: 0.221416\n",
            "[717]\tvalid_0's multi_logloss: 0.221323\n",
            "[718]\tvalid_0's multi_logloss: 0.221188\n",
            "[719]\tvalid_0's multi_logloss: 0.221055\n",
            "[720]\tvalid_0's multi_logloss: 0.220967\n",
            "[721]\tvalid_0's multi_logloss: 0.220845\n",
            "[722]\tvalid_0's multi_logloss: 0.220765\n",
            "[723]\tvalid_0's multi_logloss: 0.220627\n",
            "[724]\tvalid_0's multi_logloss: 0.220501\n",
            "[725]\tvalid_0's multi_logloss: 0.220375\n",
            "[726]\tvalid_0's multi_logloss: 0.22024\n",
            "[727]\tvalid_0's multi_logloss: 0.220149\n",
            "[728]\tvalid_0's multi_logloss: 0.220036\n",
            "[729]\tvalid_0's multi_logloss: 0.219908\n",
            "[730]\tvalid_0's multi_logloss: 0.219786\n",
            "[731]\tvalid_0's multi_logloss: 0.219659\n",
            "[732]\tvalid_0's multi_logloss: 0.219534\n",
            "[733]\tvalid_0's multi_logloss: 0.21941\n",
            "[734]\tvalid_0's multi_logloss: 0.219272\n",
            "[735]\tvalid_0's multi_logloss: 0.219185\n",
            "[736]\tvalid_0's multi_logloss: 0.219047\n",
            "[737]\tvalid_0's multi_logloss: 0.218962\n",
            "[738]\tvalid_0's multi_logloss: 0.218837\n",
            "[739]\tvalid_0's multi_logloss: 0.218753\n",
            "[740]\tvalid_0's multi_logloss: 0.218667\n",
            "[741]\tvalid_0's multi_logloss: 0.218578\n",
            "[742]\tvalid_0's multi_logloss: 0.218484\n",
            "[743]\tvalid_0's multi_logloss: 0.218361\n",
            "[744]\tvalid_0's multi_logloss: 0.21824\n",
            "[745]\tvalid_0's multi_logloss: 0.218119\n",
            "[746]\tvalid_0's multi_logloss: 0.218006\n",
            "[747]\tvalid_0's multi_logloss: 0.217931\n",
            "[748]\tvalid_0's multi_logloss: 0.217804\n",
            "[749]\tvalid_0's multi_logloss: 0.217673\n",
            "[750]\tvalid_0's multi_logloss: 0.217555\n",
            "[751]\tvalid_0's multi_logloss: 0.217434\n",
            "[752]\tvalid_0's multi_logloss: 0.217307\n",
            "[753]\tvalid_0's multi_logloss: 0.217179\n",
            "[754]\tvalid_0's multi_logloss: 0.217051\n",
            "[755]\tvalid_0's multi_logloss: 0.216974\n",
            "[756]\tvalid_0's multi_logloss: 0.216887\n",
            "[757]\tvalid_0's multi_logloss: 0.216809\n",
            "[758]\tvalid_0's multi_logloss: 0.216691\n",
            "[759]\tvalid_0's multi_logloss: 0.216565\n",
            "[760]\tvalid_0's multi_logloss: 0.216482\n",
            "[761]\tvalid_0's multi_logloss: 0.216358\n",
            "[762]\tvalid_0's multi_logloss: 0.216277\n",
            "[763]\tvalid_0's multi_logloss: 0.216162\n",
            "[764]\tvalid_0's multi_logloss: 0.216044\n",
            "[765]\tvalid_0's multi_logloss: 0.215965\n",
            "[766]\tvalid_0's multi_logloss: 0.215849\n",
            "[767]\tvalid_0's multi_logloss: 0.215769\n",
            "[768]\tvalid_0's multi_logloss: 0.215637\n",
            "[769]\tvalid_0's multi_logloss: 0.215522\n",
            "[770]\tvalid_0's multi_logloss: 0.215405\n",
            "[771]\tvalid_0's multi_logloss: 0.215329\n",
            "[772]\tvalid_0's multi_logloss: 0.215216\n",
            "[773]\tvalid_0's multi_logloss: 0.215107\n",
            "[774]\tvalid_0's multi_logloss: 0.214992\n",
            "[775]\tvalid_0's multi_logloss: 0.214882\n",
            "[776]\tvalid_0's multi_logloss: 0.21477\n",
            "[777]\tvalid_0's multi_logloss: 0.21469\n",
            "[778]\tvalid_0's multi_logloss: 0.214577\n",
            "[779]\tvalid_0's multi_logloss: 0.214459\n",
            "[780]\tvalid_0's multi_logloss: 0.21438\n",
            "[781]\tvalid_0's multi_logloss: 0.21427\n",
            "[782]\tvalid_0's multi_logloss: 0.214153\n",
            "[783]\tvalid_0's multi_logloss: 0.214039\n",
            "[784]\tvalid_0's multi_logloss: 0.213962\n",
            "[785]\tvalid_0's multi_logloss: 0.213886\n",
            "[786]\tvalid_0's multi_logloss: 0.213817\n",
            "[787]\tvalid_0's multi_logloss: 0.213748\n",
            "[788]\tvalid_0's multi_logloss: 0.213637\n",
            "[789]\tvalid_0's multi_logloss: 0.213552\n",
            "[790]\tvalid_0's multi_logloss: 0.21348\n",
            "[791]\tvalid_0's multi_logloss: 0.213362\n",
            "[792]\tvalid_0's multi_logloss: 0.213245\n",
            "[793]\tvalid_0's multi_logloss: 0.213134\n",
            "[794]\tvalid_0's multi_logloss: 0.21306\n",
            "[795]\tvalid_0's multi_logloss: 0.212988\n",
            "[796]\tvalid_0's multi_logloss: 0.212917\n",
            "[797]\tvalid_0's multi_logloss: 0.212795\n",
            "[798]\tvalid_0's multi_logloss: 0.212686\n",
            "[799]\tvalid_0's multi_logloss: 0.21258\n",
            "[800]\tvalid_0's multi_logloss: 0.212513\n",
            "[801]\tvalid_0's multi_logloss: 0.21244\n",
            "[802]\tvalid_0's multi_logloss: 0.212363\n",
            "[803]\tvalid_0's multi_logloss: 0.212253\n",
            "[804]\tvalid_0's multi_logloss: 0.212185\n",
            "[805]\tvalid_0's multi_logloss: 0.212085\n",
            "[806]\tvalid_0's multi_logloss: 0.211977\n",
            "[807]\tvalid_0's multi_logloss: 0.211867\n",
            "[808]\tvalid_0's multi_logloss: 0.211767\n",
            "[809]\tvalid_0's multi_logloss: 0.211689\n",
            "[810]\tvalid_0's multi_logloss: 0.211621\n",
            "[811]\tvalid_0's multi_logloss: 0.211514\n",
            "[812]\tvalid_0's multi_logloss: 0.211409\n",
            "[813]\tvalid_0's multi_logloss: 0.211336\n",
            "[814]\tvalid_0's multi_logloss: 0.211243\n",
            "[815]\tvalid_0's multi_logloss: 0.211131\n",
            "[816]\tvalid_0's multi_logloss: 0.211027\n",
            "[817]\tvalid_0's multi_logloss: 0.210917\n",
            "[818]\tvalid_0's multi_logloss: 0.210813\n",
            "[819]\tvalid_0's multi_logloss: 0.210707\n",
            "[820]\tvalid_0's multi_logloss: 0.210607\n",
            "[821]\tvalid_0's multi_logloss: 0.210502\n",
            "[822]\tvalid_0's multi_logloss: 0.210441\n",
            "[823]\tvalid_0's multi_logloss: 0.210354\n",
            "[824]\tvalid_0's multi_logloss: 0.210257\n",
            "[825]\tvalid_0's multi_logloss: 0.210146\n",
            "[826]\tvalid_0's multi_logloss: 0.21008\n",
            "[827]\tvalid_0's multi_logloss: 0.210011\n",
            "[828]\tvalid_0's multi_logloss: 0.209907\n",
            "[829]\tvalid_0's multi_logloss: 0.209839\n",
            "[830]\tvalid_0's multi_logloss: 0.20977\n",
            "[831]\tvalid_0's multi_logloss: 0.209689\n",
            "[832]\tvalid_0's multi_logloss: 0.209587\n",
            "[833]\tvalid_0's multi_logloss: 0.20948\n",
            "[834]\tvalid_0's multi_logloss: 0.209372\n",
            "[835]\tvalid_0's multi_logloss: 0.209268\n",
            "[836]\tvalid_0's multi_logloss: 0.20917\n",
            "[837]\tvalid_0's multi_logloss: 0.209074\n",
            "[838]\tvalid_0's multi_logloss: 0.20898\n",
            "[839]\tvalid_0's multi_logloss: 0.20891\n",
            "[840]\tvalid_0's multi_logloss: 0.208835\n",
            "[841]\tvalid_0's multi_logloss: 0.208765\n",
            "[842]\tvalid_0's multi_logloss: 0.208674\n",
            "[843]\tvalid_0's multi_logloss: 0.208588\n",
            "[844]\tvalid_0's multi_logloss: 0.208522\n",
            "[845]\tvalid_0's multi_logloss: 0.208421\n",
            "[846]\tvalid_0's multi_logloss: 0.208329\n",
            "[847]\tvalid_0's multi_logloss: 0.208234\n",
            "[848]\tvalid_0's multi_logloss: 0.208169\n",
            "[849]\tvalid_0's multi_logloss: 0.208116\n",
            "[850]\tvalid_0's multi_logloss: 0.208049\n",
            "[851]\tvalid_0's multi_logloss: 0.207984\n",
            "[852]\tvalid_0's multi_logloss: 0.207918\n",
            "[853]\tvalid_0's multi_logloss: 0.207821\n",
            "[854]\tvalid_0's multi_logloss: 0.207733\n",
            "[855]\tvalid_0's multi_logloss: 0.207675\n",
            "[856]\tvalid_0's multi_logloss: 0.207575\n",
            "[857]\tvalid_0's multi_logloss: 0.207508\n",
            "[858]\tvalid_0's multi_logloss: 0.207405\n",
            "[859]\tvalid_0's multi_logloss: 0.207314\n",
            "[860]\tvalid_0's multi_logloss: 0.207228\n",
            "[861]\tvalid_0's multi_logloss: 0.207164\n",
            "[862]\tvalid_0's multi_logloss: 0.207099\n",
            "[863]\tvalid_0's multi_logloss: 0.207001\n",
            "[864]\tvalid_0's multi_logloss: 0.206943\n",
            "[865]\tvalid_0's multi_logloss: 0.206848\n",
            "[866]\tvalid_0's multi_logloss: 0.206753\n",
            "[867]\tvalid_0's multi_logloss: 0.20669\n",
            "[868]\tvalid_0's multi_logloss: 0.206608\n",
            "[869]\tvalid_0's multi_logloss: 0.206538\n",
            "[870]\tvalid_0's multi_logloss: 0.206444\n",
            "[871]\tvalid_0's multi_logloss: 0.206355\n",
            "[872]\tvalid_0's multi_logloss: 0.206293\n",
            "[873]\tvalid_0's multi_logloss: 0.206202\n",
            "[874]\tvalid_0's multi_logloss: 0.206111\n",
            "[875]\tvalid_0's multi_logloss: 0.206029\n",
            "[876]\tvalid_0's multi_logloss: 0.205965\n",
            "[877]\tvalid_0's multi_logloss: 0.205881\n",
            "[878]\tvalid_0's multi_logloss: 0.205788\n",
            "[879]\tvalid_0's multi_logloss: 0.205731\n",
            "[880]\tvalid_0's multi_logloss: 0.205645\n",
            "[881]\tvalid_0's multi_logloss: 0.205563\n",
            "[882]\tvalid_0's multi_logloss: 0.205501\n",
            "[883]\tvalid_0's multi_logloss: 0.205409\n",
            "[884]\tvalid_0's multi_logloss: 0.205322\n",
            "[885]\tvalid_0's multi_logloss: 0.205234\n",
            "[886]\tvalid_0's multi_logloss: 0.205152\n",
            "[887]\tvalid_0's multi_logloss: 0.205091\n",
            "[888]\tvalid_0's multi_logloss: 0.205008\n",
            "[889]\tvalid_0's multi_logloss: 0.204946\n",
            "[890]\tvalid_0's multi_logloss: 0.204856\n",
            "[891]\tvalid_0's multi_logloss: 0.204761\n",
            "[892]\tvalid_0's multi_logloss: 0.204668\n",
            "[893]\tvalid_0's multi_logloss: 0.204606\n",
            "[894]\tvalid_0's multi_logloss: 0.204545\n",
            "[895]\tvalid_0's multi_logloss: 0.204487\n",
            "[896]\tvalid_0's multi_logloss: 0.204401\n",
            "[897]\tvalid_0's multi_logloss: 0.204342\n",
            "[898]\tvalid_0's multi_logloss: 0.204246\n",
            "[899]\tvalid_0's multi_logloss: 0.204148\n",
            "[900]\tvalid_0's multi_logloss: 0.20409\n",
            "[901]\tvalid_0's multi_logloss: 0.204004\n",
            "[902]\tvalid_0's multi_logloss: 0.203941\n",
            "[903]\tvalid_0's multi_logloss: 0.203857\n",
            "[904]\tvalid_0's multi_logloss: 0.203775\n",
            "[905]\tvalid_0's multi_logloss: 0.203684\n",
            "[906]\tvalid_0's multi_logloss: 0.203598\n",
            "[907]\tvalid_0's multi_logloss: 0.20354\n",
            "[908]\tvalid_0's multi_logloss: 0.203463\n",
            "[909]\tvalid_0's multi_logloss: 0.203385\n",
            "[910]\tvalid_0's multi_logloss: 0.2033\n",
            "[911]\tvalid_0's multi_logloss: 0.203216\n",
            "[912]\tvalid_0's multi_logloss: 0.203162\n",
            "[913]\tvalid_0's multi_logloss: 0.203077\n",
            "[914]\tvalid_0's multi_logloss: 0.203015\n",
            "[915]\tvalid_0's multi_logloss: 0.202928\n",
            "[916]\tvalid_0's multi_logloss: 0.20288\n",
            "[917]\tvalid_0's multi_logloss: 0.202797\n",
            "[918]\tvalid_0's multi_logloss: 0.202715\n",
            "[919]\tvalid_0's multi_logloss: 0.202656\n",
            "[920]\tvalid_0's multi_logloss: 0.202592\n",
            "[921]\tvalid_0's multi_logloss: 0.202513\n",
            "[922]\tvalid_0's multi_logloss: 0.202451\n",
            "[923]\tvalid_0's multi_logloss: 0.202377\n",
            "[924]\tvalid_0's multi_logloss: 0.202293\n",
            "[925]\tvalid_0's multi_logloss: 0.202233\n",
            "[926]\tvalid_0's multi_logloss: 0.202179\n",
            "[927]\tvalid_0's multi_logloss: 0.202126\n",
            "[928]\tvalid_0's multi_logloss: 0.202073\n",
            "[929]\tvalid_0's multi_logloss: 0.20202\n",
            "[930]\tvalid_0's multi_logloss: 0.201937\n",
            "[931]\tvalid_0's multi_logloss: 0.201853\n",
            "[932]\tvalid_0's multi_logloss: 0.201778\n",
            "[933]\tvalid_0's multi_logloss: 0.201724\n",
            "[934]\tvalid_0's multi_logloss: 0.201646\n",
            "[935]\tvalid_0's multi_logloss: 0.201568\n",
            "[936]\tvalid_0's multi_logloss: 0.201519\n",
            "[937]\tvalid_0's multi_logloss: 0.201434\n",
            "[938]\tvalid_0's multi_logloss: 0.201373\n",
            "[939]\tvalid_0's multi_logloss: 0.201296\n",
            "[940]\tvalid_0's multi_logloss: 0.201242\n",
            "[941]\tvalid_0's multi_logloss: 0.201187\n",
            "[942]\tvalid_0's multi_logloss: 0.201101\n",
            "[943]\tvalid_0's multi_logloss: 0.201027\n",
            "[944]\tvalid_0's multi_logloss: 0.20098\n",
            "[945]\tvalid_0's multi_logloss: 0.200922\n",
            "[946]\tvalid_0's multi_logloss: 0.200836\n",
            "[947]\tvalid_0's multi_logloss: 0.200755\n",
            "[948]\tvalid_0's multi_logloss: 0.200704\n",
            "[949]\tvalid_0's multi_logloss: 0.200642\n",
            "[950]\tvalid_0's multi_logloss: 0.200558\n",
            "[951]\tvalid_0's multi_logloss: 0.200488\n",
            "[952]\tvalid_0's multi_logloss: 0.200409\n",
            "[953]\tvalid_0's multi_logloss: 0.200334\n",
            "[954]\tvalid_0's multi_logloss: 0.20026\n",
            "[955]\tvalid_0's multi_logloss: 0.200185\n",
            "[956]\tvalid_0's multi_logloss: 0.200112\n",
            "[957]\tvalid_0's multi_logloss: 0.200058\n",
            "[958]\tvalid_0's multi_logloss: 0.200002\n",
            "[959]\tvalid_0's multi_logloss: 0.19994\n",
            "[960]\tvalid_0's multi_logloss: 0.199882\n",
            "[961]\tvalid_0's multi_logloss: 0.199838\n",
            "[962]\tvalid_0's multi_logloss: 0.199784\n",
            "[963]\tvalid_0's multi_logloss: 0.199735\n",
            "[964]\tvalid_0's multi_logloss: 0.199659\n",
            "[965]\tvalid_0's multi_logloss: 0.199593\n",
            "[966]\tvalid_0's multi_logloss: 0.199524\n",
            "[967]\tvalid_0's multi_logloss: 0.199454\n",
            "[968]\tvalid_0's multi_logloss: 0.199373\n",
            "[969]\tvalid_0's multi_logloss: 0.199298\n",
            "[970]\tvalid_0's multi_logloss: 0.19923\n",
            "[971]\tvalid_0's multi_logloss: 0.199158\n",
            "[972]\tvalid_0's multi_logloss: 0.19911\n",
            "[973]\tvalid_0's multi_logloss: 0.199065\n",
            "[974]\tvalid_0's multi_logloss: 0.19899\n",
            "[975]\tvalid_0's multi_logloss: 0.19892\n",
            "[976]\tvalid_0's multi_logloss: 0.198856\n",
            "[977]\tvalid_0's multi_logloss: 0.198812\n",
            "[978]\tvalid_0's multi_logloss: 0.198741\n",
            "[979]\tvalid_0's multi_logloss: 0.198684\n",
            "[980]\tvalid_0's multi_logloss: 0.198613\n",
            "[981]\tvalid_0's multi_logloss: 0.198541\n",
            "[982]\tvalid_0's multi_logloss: 0.198491\n",
            "[983]\tvalid_0's multi_logloss: 0.198432\n",
            "[984]\tvalid_0's multi_logloss: 0.198381\n",
            "[985]\tvalid_0's multi_logloss: 0.198312\n",
            "[986]\tvalid_0's multi_logloss: 0.198251\n",
            "[987]\tvalid_0's multi_logloss: 0.198195\n",
            "[988]\tvalid_0's multi_logloss: 0.198139\n",
            "[989]\tvalid_0's multi_logloss: 0.19808\n",
            "[990]\tvalid_0's multi_logloss: 0.198011\n",
            "[991]\tvalid_0's multi_logloss: 0.197945\n",
            "[992]\tvalid_0's multi_logloss: 0.197876\n",
            "[993]\tvalid_0's multi_logloss: 0.19781\n",
            "[994]\tvalid_0's multi_logloss: 0.197743\n",
            "[995]\tvalid_0's multi_logloss: 0.197687\n",
            "[996]\tvalid_0's multi_logloss: 0.197632\n",
            "[997]\tvalid_0's multi_logloss: 0.197588\n",
            "[998]\tvalid_0's multi_logloss: 0.197518\n",
            "[999]\tvalid_0's multi_logloss: 0.197453\n",
            "[1000]\tvalid_0's multi_logloss: 0.197388\n",
            "[1001]\tvalid_0's multi_logloss: 0.197341\n",
            "[1002]\tvalid_0's multi_logloss: 0.197275\n",
            "[1003]\tvalid_0's multi_logloss: 0.197207\n",
            "[1004]\tvalid_0's multi_logloss: 0.19716\n",
            "[1005]\tvalid_0's multi_logloss: 0.197111\n",
            "[1006]\tvalid_0's multi_logloss: 0.197038\n",
            "[1007]\tvalid_0's multi_logloss: 0.196975\n",
            "[1008]\tvalid_0's multi_logloss: 0.196937\n",
            "[1009]\tvalid_0's multi_logloss: 0.19687\n",
            "[1010]\tvalid_0's multi_logloss: 0.196826\n",
            "[1011]\tvalid_0's multi_logloss: 0.196764\n",
            "[1012]\tvalid_0's multi_logloss: 0.196711\n",
            "[1013]\tvalid_0's multi_logloss: 0.196642\n",
            "[1014]\tvalid_0's multi_logloss: 0.196573\n",
            "[1015]\tvalid_0's multi_logloss: 0.1965\n",
            "[1016]\tvalid_0's multi_logloss: 0.196436\n",
            "[1017]\tvalid_0's multi_logloss: 0.196373\n",
            "[1018]\tvalid_0's multi_logloss: 0.196314\n",
            "[1019]\tvalid_0's multi_logloss: 0.196247\n",
            "[1020]\tvalid_0's multi_logloss: 0.19619\n",
            "[1021]\tvalid_0's multi_logloss: 0.196143\n",
            "[1022]\tvalid_0's multi_logloss: 0.196085\n",
            "[1023]\tvalid_0's multi_logloss: 0.196017\n",
            "[1024]\tvalid_0's multi_logloss: 0.195956\n",
            "[1025]\tvalid_0's multi_logloss: 0.19589\n",
            "[1026]\tvalid_0's multi_logloss: 0.195825\n",
            "[1027]\tvalid_0's multi_logloss: 0.195762\n",
            "[1028]\tvalid_0's multi_logloss: 0.1957\n",
            "[1029]\tvalid_0's multi_logloss: 0.195626\n",
            "[1030]\tvalid_0's multi_logloss: 0.195579\n",
            "[1031]\tvalid_0's multi_logloss: 0.195522\n",
            "[1032]\tvalid_0's multi_logloss: 0.195456\n",
            "[1033]\tvalid_0's multi_logloss: 0.195389\n",
            "[1034]\tvalid_0's multi_logloss: 0.195339\n",
            "[1035]\tvalid_0's multi_logloss: 0.195274\n",
            "[1036]\tvalid_0's multi_logloss: 0.195227\n",
            "[1037]\tvalid_0's multi_logloss: 0.195161\n",
            "[1038]\tvalid_0's multi_logloss: 0.195116\n",
            "[1039]\tvalid_0's multi_logloss: 0.195059\n",
            "[1040]\tvalid_0's multi_logloss: 0.195015\n",
            "[1041]\tvalid_0's multi_logloss: 0.194947\n",
            "[1042]\tvalid_0's multi_logloss: 0.194883\n",
            "[1043]\tvalid_0's multi_logloss: 0.194829\n",
            "[1044]\tvalid_0's multi_logloss: 0.194766\n",
            "[1045]\tvalid_0's multi_logloss: 0.194709\n",
            "[1046]\tvalid_0's multi_logloss: 0.194647\n",
            "[1047]\tvalid_0's multi_logloss: 0.194617\n",
            "[1048]\tvalid_0's multi_logloss: 0.194563\n",
            "[1049]\tvalid_0's multi_logloss: 0.194501\n",
            "[1050]\tvalid_0's multi_logloss: 0.194446\n",
            "[1051]\tvalid_0's multi_logloss: 0.194409\n",
            "[1052]\tvalid_0's multi_logloss: 0.194341\n",
            "[1053]\tvalid_0's multi_logloss: 0.194281\n",
            "[1054]\tvalid_0's multi_logloss: 0.194221\n",
            "[1055]\tvalid_0's multi_logloss: 0.194181\n",
            "[1056]\tvalid_0's multi_logloss: 0.194124\n",
            "[1057]\tvalid_0's multi_logloss: 0.194078\n",
            "[1058]\tvalid_0's multi_logloss: 0.194018\n",
            "[1059]\tvalid_0's multi_logloss: 0.193972\n",
            "[1060]\tvalid_0's multi_logloss: 0.193906\n",
            "[1061]\tvalid_0's multi_logloss: 0.19385\n",
            "[1062]\tvalid_0's multi_logloss: 0.193793\n",
            "[1063]\tvalid_0's multi_logloss: 0.193726\n",
            "[1064]\tvalid_0's multi_logloss: 0.193667\n",
            "[1065]\tvalid_0's multi_logloss: 0.193608\n",
            "[1066]\tvalid_0's multi_logloss: 0.193558\n",
            "[1067]\tvalid_0's multi_logloss: 0.193508\n",
            "[1068]\tvalid_0's multi_logloss: 0.193461\n",
            "[1069]\tvalid_0's multi_logloss: 0.193408\n",
            "[1070]\tvalid_0's multi_logloss: 0.193358\n",
            "[1071]\tvalid_0's multi_logloss: 0.1933\n",
            "[1072]\tvalid_0's multi_logloss: 0.193252\n",
            "[1073]\tvalid_0's multi_logloss: 0.193204\n",
            "[1074]\tvalid_0's multi_logloss: 0.193155\n",
            "[1075]\tvalid_0's multi_logloss: 0.193098\n",
            "[1076]\tvalid_0's multi_logloss: 0.193043\n",
            "[1077]\tvalid_0's multi_logloss: 0.192988\n",
            "[1078]\tvalid_0's multi_logloss: 0.192943\n",
            "[1079]\tvalid_0's multi_logloss: 0.192901\n",
            "[1080]\tvalid_0's multi_logloss: 0.19285\n",
            "[1081]\tvalid_0's multi_logloss: 0.19281\n",
            "[1082]\tvalid_0's multi_logloss: 0.192749\n",
            "[1083]\tvalid_0's multi_logloss: 0.192714\n",
            "[1084]\tvalid_0's multi_logloss: 0.192664\n",
            "[1085]\tvalid_0's multi_logloss: 0.192607\n",
            "[1086]\tvalid_0's multi_logloss: 0.192558\n",
            "[1087]\tvalid_0's multi_logloss: 0.192501\n",
            "[1088]\tvalid_0's multi_logloss: 0.192459\n",
            "[1089]\tvalid_0's multi_logloss: 0.192416\n",
            "[1090]\tvalid_0's multi_logloss: 0.192384\n",
            "[1091]\tvalid_0's multi_logloss: 0.192345\n",
            "[1092]\tvalid_0's multi_logloss: 0.192306\n",
            "[1093]\tvalid_0's multi_logloss: 0.192272\n",
            "[1094]\tvalid_0's multi_logloss: 0.19223\n",
            "[1095]\tvalid_0's multi_logloss: 0.192192\n",
            "[1096]\tvalid_0's multi_logloss: 0.19214\n",
            "[1097]\tvalid_0's multi_logloss: 0.192083\n",
            "[1098]\tvalid_0's multi_logloss: 0.192026\n",
            "[1099]\tvalid_0's multi_logloss: 0.191978\n",
            "[1100]\tvalid_0's multi_logloss: 0.191948\n",
            "[1101]\tvalid_0's multi_logloss: 0.191899\n",
            "[1102]\tvalid_0's multi_logloss: 0.191859\n",
            "[1103]\tvalid_0's multi_logloss: 0.191807\n",
            "[1104]\tvalid_0's multi_logloss: 0.191755\n",
            "[1105]\tvalid_0's multi_logloss: 0.191702\n",
            "[1106]\tvalid_0's multi_logloss: 0.191668\n",
            "[1107]\tvalid_0's multi_logloss: 0.191611\n",
            "[1108]\tvalid_0's multi_logloss: 0.191555\n",
            "[1109]\tvalid_0's multi_logloss: 0.191507\n",
            "[1110]\tvalid_0's multi_logloss: 0.191461\n",
            "[1111]\tvalid_0's multi_logloss: 0.191411\n",
            "[1112]\tvalid_0's multi_logloss: 0.191375\n",
            "[1113]\tvalid_0's multi_logloss: 0.191317\n",
            "[1114]\tvalid_0's multi_logloss: 0.191276\n",
            "[1115]\tvalid_0's multi_logloss: 0.191233\n",
            "[1116]\tvalid_0's multi_logloss: 0.191187\n",
            "[1117]\tvalid_0's multi_logloss: 0.191141\n",
            "[1118]\tvalid_0's multi_logloss: 0.191101\n",
            "[1119]\tvalid_0's multi_logloss: 0.191053\n",
            "[1120]\tvalid_0's multi_logloss: 0.191019\n",
            "[1121]\tvalid_0's multi_logloss: 0.190974\n",
            "[1122]\tvalid_0's multi_logloss: 0.190933\n",
            "[1123]\tvalid_0's multi_logloss: 0.190882\n",
            "[1124]\tvalid_0's multi_logloss: 0.190827\n",
            "[1125]\tvalid_0's multi_logloss: 0.190792\n",
            "[1126]\tvalid_0's multi_logloss: 0.190759\n",
            "[1127]\tvalid_0's multi_logloss: 0.190709\n",
            "[1128]\tvalid_0's multi_logloss: 0.190672\n",
            "[1129]\tvalid_0's multi_logloss: 0.190625\n",
            "[1130]\tvalid_0's multi_logloss: 0.19058\n",
            "[1131]\tvalid_0's multi_logloss: 0.190526\n",
            "[1132]\tvalid_0's multi_logloss: 0.190487\n",
            "[1133]\tvalid_0's multi_logloss: 0.190443\n",
            "[1134]\tvalid_0's multi_logloss: 0.190394\n",
            "[1135]\tvalid_0's multi_logloss: 0.190345\n",
            "[1136]\tvalid_0's multi_logloss: 0.190296\n",
            "[1137]\tvalid_0's multi_logloss: 0.190258\n",
            "[1138]\tvalid_0's multi_logloss: 0.19021\n",
            "[1139]\tvalid_0's multi_logloss: 0.190153\n",
            "[1140]\tvalid_0's multi_logloss: 0.190109\n",
            "[1141]\tvalid_0's multi_logloss: 0.190064\n",
            "[1142]\tvalid_0's multi_logloss: 0.190007\n",
            "[1143]\tvalid_0's multi_logloss: 0.189962\n",
            "[1144]\tvalid_0's multi_logloss: 0.189913\n",
            "[1145]\tvalid_0's multi_logloss: 0.189878\n",
            "[1146]\tvalid_0's multi_logloss: 0.18984\n",
            "[1147]\tvalid_0's multi_logloss: 0.18979\n",
            "[1148]\tvalid_0's multi_logloss: 0.189759\n",
            "[1149]\tvalid_0's multi_logloss: 0.18972\n",
            "[1150]\tvalid_0's multi_logloss: 0.189671\n",
            "[1151]\tvalid_0's multi_logloss: 0.189639\n",
            "[1152]\tvalid_0's multi_logloss: 0.189597\n",
            "[1153]\tvalid_0's multi_logloss: 0.189555\n",
            "[1154]\tvalid_0's multi_logloss: 0.189505\n",
            "[1155]\tvalid_0's multi_logloss: 0.189469\n",
            "[1156]\tvalid_0's multi_logloss: 0.18943\n",
            "[1157]\tvalid_0's multi_logloss: 0.189375\n",
            "[1158]\tvalid_0's multi_logloss: 0.189333\n",
            "[1159]\tvalid_0's multi_logloss: 0.189302\n",
            "[1160]\tvalid_0's multi_logloss: 0.189248\n",
            "[1161]\tvalid_0's multi_logloss: 0.189198\n",
            "[1162]\tvalid_0's multi_logloss: 0.18916\n",
            "[1163]\tvalid_0's multi_logloss: 0.189117\n",
            "[1164]\tvalid_0's multi_logloss: 0.189085\n",
            "[1165]\tvalid_0's multi_logloss: 0.189049\n",
            "[1166]\tvalid_0's multi_logloss: 0.188995\n",
            "[1167]\tvalid_0's multi_logloss: 0.188943\n",
            "[1168]\tvalid_0's multi_logloss: 0.188904\n",
            "[1169]\tvalid_0's multi_logloss: 0.188874\n",
            "[1170]\tvalid_0's multi_logloss: 0.188841\n",
            "[1171]\tvalid_0's multi_logloss: 0.188802\n",
            "[1172]\tvalid_0's multi_logloss: 0.188758\n",
            "[1173]\tvalid_0's multi_logloss: 0.188715\n",
            "[1174]\tvalid_0's multi_logloss: 0.188673\n",
            "[1175]\tvalid_0's multi_logloss: 0.188627\n",
            "[1176]\tvalid_0's multi_logloss: 0.188595\n",
            "[1177]\tvalid_0's multi_logloss: 0.188546\n",
            "[1178]\tvalid_0's multi_logloss: 0.188499\n",
            "[1179]\tvalid_0's multi_logloss: 0.188454\n",
            "[1180]\tvalid_0's multi_logloss: 0.188409\n",
            "[1181]\tvalid_0's multi_logloss: 0.188374\n",
            "[1182]\tvalid_0's multi_logloss: 0.188341\n",
            "[1183]\tvalid_0's multi_logloss: 0.188293\n",
            "[1184]\tvalid_0's multi_logloss: 0.18825\n",
            "[1185]\tvalid_0's multi_logloss: 0.188214\n",
            "[1186]\tvalid_0's multi_logloss: 0.188174\n",
            "[1187]\tvalid_0's multi_logloss: 0.188123\n",
            "[1188]\tvalid_0's multi_logloss: 0.188075\n",
            "[1189]\tvalid_0's multi_logloss: 0.188036\n",
            "[1190]\tvalid_0's multi_logloss: 0.188001\n",
            "[1191]\tvalid_0's multi_logloss: 0.187967\n",
            "[1192]\tvalid_0's multi_logloss: 0.187923\n",
            "[1193]\tvalid_0's multi_logloss: 0.187886\n",
            "[1194]\tvalid_0's multi_logloss: 0.187839\n",
            "[1195]\tvalid_0's multi_logloss: 0.187809\n",
            "[1196]\tvalid_0's multi_logloss: 0.187765\n",
            "[1197]\tvalid_0's multi_logloss: 0.187728\n",
            "[1198]\tvalid_0's multi_logloss: 0.187688\n",
            "[1199]\tvalid_0's multi_logloss: 0.187641\n",
            "[1200]\tvalid_0's multi_logloss: 0.187592\n",
            "[1201]\tvalid_0's multi_logloss: 0.187559\n",
            "[1202]\tvalid_0's multi_logloss: 0.187516\n",
            "[1203]\tvalid_0's multi_logloss: 0.187478\n",
            "[1204]\tvalid_0's multi_logloss: 0.187438\n",
            "[1205]\tvalid_0's multi_logloss: 0.187396\n",
            "[1206]\tvalid_0's multi_logloss: 0.18735\n",
            "[1207]\tvalid_0's multi_logloss: 0.187309\n",
            "[1208]\tvalid_0's multi_logloss: 0.187266\n",
            "[1209]\tvalid_0's multi_logloss: 0.187221\n",
            "[1210]\tvalid_0's multi_logloss: 0.187196\n",
            "[1211]\tvalid_0's multi_logloss: 0.187156\n",
            "[1212]\tvalid_0's multi_logloss: 0.187118\n",
            "[1213]\tvalid_0's multi_logloss: 0.187067\n",
            "[1214]\tvalid_0's multi_logloss: 0.187016\n",
            "[1215]\tvalid_0's multi_logloss: 0.186984\n",
            "[1216]\tvalid_0's multi_logloss: 0.186951\n",
            "[1217]\tvalid_0's multi_logloss: 0.186907\n",
            "[1218]\tvalid_0's multi_logloss: 0.186874\n",
            "[1219]\tvalid_0's multi_logloss: 0.186841\n",
            "[1220]\tvalid_0's multi_logloss: 0.186798\n",
            "[1221]\tvalid_0's multi_logloss: 0.186766\n",
            "[1222]\tvalid_0's multi_logloss: 0.186732\n",
            "[1223]\tvalid_0's multi_logloss: 0.186694\n",
            "[1224]\tvalid_0's multi_logloss: 0.186668\n",
            "[1225]\tvalid_0's multi_logloss: 0.186638\n",
            "[1226]\tvalid_0's multi_logloss: 0.186604\n",
            "[1227]\tvalid_0's multi_logloss: 0.186566\n",
            "[1228]\tvalid_0's multi_logloss: 0.186529\n",
            "[1229]\tvalid_0's multi_logloss: 0.186484\n",
            "[1230]\tvalid_0's multi_logloss: 0.186449\n",
            "[1231]\tvalid_0's multi_logloss: 0.186414\n",
            "[1232]\tvalid_0's multi_logloss: 0.186365\n",
            "[1233]\tvalid_0's multi_logloss: 0.186326\n",
            "[1234]\tvalid_0's multi_logloss: 0.186285\n",
            "[1235]\tvalid_0's multi_logloss: 0.186244\n",
            "[1236]\tvalid_0's multi_logloss: 0.186198\n",
            "[1237]\tvalid_0's multi_logloss: 0.186162\n",
            "[1238]\tvalid_0's multi_logloss: 0.18613\n",
            "[1239]\tvalid_0's multi_logloss: 0.186091\n",
            "[1240]\tvalid_0's multi_logloss: 0.186043\n",
            "[1241]\tvalid_0's multi_logloss: 0.18601\n",
            "[1242]\tvalid_0's multi_logloss: 0.185978\n",
            "[1243]\tvalid_0's multi_logloss: 0.185942\n",
            "[1244]\tvalid_0's multi_logloss: 0.185919\n",
            "[1245]\tvalid_0's multi_logloss: 0.18588\n",
            "[1246]\tvalid_0's multi_logloss: 0.185844\n",
            "[1247]\tvalid_0's multi_logloss: 0.185805\n",
            "[1248]\tvalid_0's multi_logloss: 0.185771\n",
            "[1249]\tvalid_0's multi_logloss: 0.185731\n",
            "[1250]\tvalid_0's multi_logloss: 0.185691\n",
            "[1251]\tvalid_0's multi_logloss: 0.185657\n",
            "[1252]\tvalid_0's multi_logloss: 0.185623\n",
            "[1253]\tvalid_0's multi_logloss: 0.185586\n",
            "[1254]\tvalid_0's multi_logloss: 0.185551\n",
            "[1255]\tvalid_0's multi_logloss: 0.185519\n",
            "[1256]\tvalid_0's multi_logloss: 0.185486\n",
            "[1257]\tvalid_0's multi_logloss: 0.185445\n",
            "[1258]\tvalid_0's multi_logloss: 0.185404\n",
            "[1259]\tvalid_0's multi_logloss: 0.185368\n",
            "[1260]\tvalid_0's multi_logloss: 0.185331\n",
            "[1261]\tvalid_0's multi_logloss: 0.185294\n",
            "[1262]\tvalid_0's multi_logloss: 0.185258\n",
            "[1263]\tvalid_0's multi_logloss: 0.185229\n",
            "[1264]\tvalid_0's multi_logloss: 0.185188\n",
            "[1265]\tvalid_0's multi_logloss: 0.185153\n",
            "[1266]\tvalid_0's multi_logloss: 0.185105\n",
            "[1267]\tvalid_0's multi_logloss: 0.185066\n",
            "[1268]\tvalid_0's multi_logloss: 0.185028\n",
            "[1269]\tvalid_0's multi_logloss: 0.184992\n",
            "[1270]\tvalid_0's multi_logloss: 0.184961\n",
            "[1271]\tvalid_0's multi_logloss: 0.184919\n",
            "[1272]\tvalid_0's multi_logloss: 0.184889\n",
            "[1273]\tvalid_0's multi_logloss: 0.184852\n",
            "[1274]\tvalid_0's multi_logloss: 0.184815\n",
            "[1275]\tvalid_0's multi_logloss: 0.184776\n",
            "[1276]\tvalid_0's multi_logloss: 0.184738\n",
            "[1277]\tvalid_0's multi_logloss: 0.184696\n",
            "[1278]\tvalid_0's multi_logloss: 0.184657\n",
            "[1279]\tvalid_0's multi_logloss: 0.184636\n",
            "[1280]\tvalid_0's multi_logloss: 0.184606\n",
            "[1281]\tvalid_0's multi_logloss: 0.184576\n",
            "[1282]\tvalid_0's multi_logloss: 0.184536\n",
            "[1283]\tvalid_0's multi_logloss: 0.184495\n",
            "[1284]\tvalid_0's multi_logloss: 0.184452\n",
            "[1285]\tvalid_0's multi_logloss: 0.184424\n",
            "[1286]\tvalid_0's multi_logloss: 0.18439\n",
            "[1287]\tvalid_0's multi_logloss: 0.184361\n",
            "[1288]\tvalid_0's multi_logloss: 0.184327\n",
            "[1289]\tvalid_0's multi_logloss: 0.184299\n",
            "[1290]\tvalid_0's multi_logloss: 0.184259\n",
            "[1291]\tvalid_0's multi_logloss: 0.184235\n",
            "[1292]\tvalid_0's multi_logloss: 0.184194\n",
            "[1293]\tvalid_0's multi_logloss: 0.184166\n",
            "[1294]\tvalid_0's multi_logloss: 0.184136\n",
            "[1295]\tvalid_0's multi_logloss: 0.184103\n",
            "[1296]\tvalid_0's multi_logloss: 0.184063\n",
            "[1297]\tvalid_0's multi_logloss: 0.184023\n",
            "[1298]\tvalid_0's multi_logloss: 0.183995\n",
            "[1299]\tvalid_0's multi_logloss: 0.183966\n",
            "[1300]\tvalid_0's multi_logloss: 0.183942\n",
            "[1301]\tvalid_0's multi_logloss: 0.183917\n",
            "[1302]\tvalid_0's multi_logloss: 0.183891\n",
            "[1303]\tvalid_0's multi_logloss: 0.183858\n",
            "[1304]\tvalid_0's multi_logloss: 0.183819\n",
            "[1305]\tvalid_0's multi_logloss: 0.183782\n",
            "[1306]\tvalid_0's multi_logloss: 0.183752\n",
            "[1307]\tvalid_0's multi_logloss: 0.183716\n",
            "[1308]\tvalid_0's multi_logloss: 0.183688\n",
            "[1309]\tvalid_0's multi_logloss: 0.183654\n",
            "[1310]\tvalid_0's multi_logloss: 0.183625\n",
            "[1311]\tvalid_0's multi_logloss: 0.183599\n",
            "[1312]\tvalid_0's multi_logloss: 0.183569\n",
            "[1313]\tvalid_0's multi_logloss: 0.183545\n",
            "[1314]\tvalid_0's multi_logloss: 0.183503\n",
            "[1315]\tvalid_0's multi_logloss: 0.183468\n",
            "[1316]\tvalid_0's multi_logloss: 0.183432\n",
            "[1317]\tvalid_0's multi_logloss: 0.183405\n",
            "[1318]\tvalid_0's multi_logloss: 0.183376\n",
            "[1319]\tvalid_0's multi_logloss: 0.183349\n",
            "[1320]\tvalid_0's multi_logloss: 0.183324\n",
            "[1321]\tvalid_0's multi_logloss: 0.183281\n",
            "[1322]\tvalid_0's multi_logloss: 0.183257\n",
            "[1323]\tvalid_0's multi_logloss: 0.183226\n",
            "[1324]\tvalid_0's multi_logloss: 0.183201\n",
            "[1325]\tvalid_0's multi_logloss: 0.183159\n",
            "[1326]\tvalid_0's multi_logloss: 0.183129\n",
            "[1327]\tvalid_0's multi_logloss: 0.183101\n",
            "[1328]\tvalid_0's multi_logloss: 0.183074\n",
            "[1329]\tvalid_0's multi_logloss: 0.183047\n",
            "[1330]\tvalid_0's multi_logloss: 0.183007\n",
            "[1331]\tvalid_0's multi_logloss: 0.182981\n",
            "[1332]\tvalid_0's multi_logloss: 0.182955\n",
            "[1333]\tvalid_0's multi_logloss: 0.182927\n",
            "[1334]\tvalid_0's multi_logloss: 0.182889\n",
            "[1335]\tvalid_0's multi_logloss: 0.182853\n",
            "[1336]\tvalid_0's multi_logloss: 0.18282\n",
            "[1337]\tvalid_0's multi_logloss: 0.182795\n",
            "[1338]\tvalid_0's multi_logloss: 0.182762\n",
            "[1339]\tvalid_0's multi_logloss: 0.182731\n",
            "[1340]\tvalid_0's multi_logloss: 0.182705\n",
            "[1341]\tvalid_0's multi_logloss: 0.182672\n",
            "[1342]\tvalid_0's multi_logloss: 0.182638\n",
            "[1343]\tvalid_0's multi_logloss: 0.182612\n",
            "[1344]\tvalid_0's multi_logloss: 0.182577\n",
            "[1345]\tvalid_0's multi_logloss: 0.182538\n",
            "[1346]\tvalid_0's multi_logloss: 0.182505\n",
            "[1347]\tvalid_0's multi_logloss: 0.182479\n",
            "[1348]\tvalid_0's multi_logloss: 0.182452\n",
            "[1349]\tvalid_0's multi_logloss: 0.182421\n",
            "[1350]\tvalid_0's multi_logloss: 0.182389\n",
            "[1351]\tvalid_0's multi_logloss: 0.182364\n",
            "[1352]\tvalid_0's multi_logloss: 0.182333\n",
            "[1353]\tvalid_0's multi_logloss: 0.182308\n",
            "[1354]\tvalid_0's multi_logloss: 0.182286\n",
            "[1355]\tvalid_0's multi_logloss: 0.182246\n",
            "[1356]\tvalid_0's multi_logloss: 0.182216\n",
            "[1357]\tvalid_0's multi_logloss: 0.182184\n",
            "[1358]\tvalid_0's multi_logloss: 0.182161\n",
            "[1359]\tvalid_0's multi_logloss: 0.182124\n",
            "[1360]\tvalid_0's multi_logloss: 0.182097\n",
            "[1361]\tvalid_0's multi_logloss: 0.182069\n",
            "[1362]\tvalid_0's multi_logloss: 0.182043\n",
            "[1363]\tvalid_0's multi_logloss: 0.182018\n",
            "[1364]\tvalid_0's multi_logloss: 0.181988\n",
            "[1365]\tvalid_0's multi_logloss: 0.181961\n",
            "[1366]\tvalid_0's multi_logloss: 0.181936\n",
            "[1367]\tvalid_0's multi_logloss: 0.18191\n",
            "[1368]\tvalid_0's multi_logloss: 0.181886\n",
            "[1369]\tvalid_0's multi_logloss: 0.181859\n",
            "[1370]\tvalid_0's multi_logloss: 0.181837\n",
            "[1371]\tvalid_0's multi_logloss: 0.181808\n",
            "[1372]\tvalid_0's multi_logloss: 0.181778\n",
            "[1373]\tvalid_0's multi_logloss: 0.181751\n",
            "[1374]\tvalid_0's multi_logloss: 0.181714\n",
            "[1375]\tvalid_0's multi_logloss: 0.181679\n",
            "[1376]\tvalid_0's multi_logloss: 0.181643\n",
            "[1377]\tvalid_0's multi_logloss: 0.18162\n",
            "[1378]\tvalid_0's multi_logloss: 0.181588\n",
            "[1379]\tvalid_0's multi_logloss: 0.181569\n",
            "[1380]\tvalid_0's multi_logloss: 0.181536\n",
            "[1381]\tvalid_0's multi_logloss: 0.181504\n",
            "[1382]\tvalid_0's multi_logloss: 0.181482\n",
            "[1383]\tvalid_0's multi_logloss: 0.181448\n",
            "[1384]\tvalid_0's multi_logloss: 0.181422\n",
            "[1385]\tvalid_0's multi_logloss: 0.18139\n",
            "[1386]\tvalid_0's multi_logloss: 0.181365\n",
            "[1387]\tvalid_0's multi_logloss: 0.181326\n",
            "[1388]\tvalid_0's multi_logloss: 0.181292\n",
            "[1389]\tvalid_0's multi_logloss: 0.181257\n",
            "[1390]\tvalid_0's multi_logloss: 0.181233\n",
            "[1391]\tvalid_0's multi_logloss: 0.181199\n",
            "[1392]\tvalid_0's multi_logloss: 0.18117\n",
            "[1393]\tvalid_0's multi_logloss: 0.181143\n",
            "[1394]\tvalid_0's multi_logloss: 0.18111\n",
            "[1395]\tvalid_0's multi_logloss: 0.181071\n",
            "[1396]\tvalid_0's multi_logloss: 0.181035\n",
            "[1397]\tvalid_0's multi_logloss: 0.181014\n",
            "[1398]\tvalid_0's multi_logloss: 0.18099\n",
            "[1399]\tvalid_0's multi_logloss: 0.18096\n",
            "[1400]\tvalid_0's multi_logloss: 0.180942\n",
            "[1401]\tvalid_0's multi_logloss: 0.180909\n",
            "[1402]\tvalid_0's multi_logloss: 0.180881\n",
            "[1403]\tvalid_0's multi_logloss: 0.18085\n",
            "[1404]\tvalid_0's multi_logloss: 0.180815\n",
            "[1405]\tvalid_0's multi_logloss: 0.180797\n",
            "[1406]\tvalid_0's multi_logloss: 0.18077\n",
            "[1407]\tvalid_0's multi_logloss: 0.180742\n",
            "[1408]\tvalid_0's multi_logloss: 0.180711\n",
            "[1409]\tvalid_0's multi_logloss: 0.180689\n",
            "[1410]\tvalid_0's multi_logloss: 0.180655\n",
            "[1411]\tvalid_0's multi_logloss: 0.180628\n",
            "[1412]\tvalid_0's multi_logloss: 0.180605\n",
            "[1413]\tvalid_0's multi_logloss: 0.180573\n",
            "[1414]\tvalid_0's multi_logloss: 0.180541\n",
            "[1415]\tvalid_0's multi_logloss: 0.180523\n",
            "[1416]\tvalid_0's multi_logloss: 0.180493\n",
            "[1417]\tvalid_0's multi_logloss: 0.180464\n",
            "[1418]\tvalid_0's multi_logloss: 0.180435\n",
            "[1419]\tvalid_0's multi_logloss: 0.180422\n",
            "[1420]\tvalid_0's multi_logloss: 0.180394\n",
            "[1421]\tvalid_0's multi_logloss: 0.180366\n",
            "[1422]\tvalid_0's multi_logloss: 0.180342\n",
            "[1423]\tvalid_0's multi_logloss: 0.180326\n",
            "[1424]\tvalid_0's multi_logloss: 0.180302\n",
            "[1425]\tvalid_0's multi_logloss: 0.180268\n",
            "[1426]\tvalid_0's multi_logloss: 0.180235\n",
            "[1427]\tvalid_0's multi_logloss: 0.18021\n",
            "[1428]\tvalid_0's multi_logloss: 0.180189\n",
            "[1429]\tvalid_0's multi_logloss: 0.18016\n",
            "[1430]\tvalid_0's multi_logloss: 0.180133\n",
            "[1431]\tvalid_0's multi_logloss: 0.180108\n",
            "[1432]\tvalid_0's multi_logloss: 0.180092\n",
            "[1433]\tvalid_0's multi_logloss: 0.180066\n",
            "[1434]\tvalid_0's multi_logloss: 0.18004\n",
            "[1435]\tvalid_0's multi_logloss: 0.180013\n",
            "[1436]\tvalid_0's multi_logloss: 0.179987\n",
            "[1437]\tvalid_0's multi_logloss: 0.179967\n",
            "[1438]\tvalid_0's multi_logloss: 0.17994\n",
            "[1439]\tvalid_0's multi_logloss: 0.179916\n",
            "[1440]\tvalid_0's multi_logloss: 0.179879\n",
            "[1441]\tvalid_0's multi_logloss: 0.179858\n",
            "[1442]\tvalid_0's multi_logloss: 0.179825\n",
            "[1443]\tvalid_0's multi_logloss: 0.1798\n",
            "[1444]\tvalid_0's multi_logloss: 0.179777\n",
            "[1445]\tvalid_0's multi_logloss: 0.179752\n",
            "[1446]\tvalid_0's multi_logloss: 0.179723\n",
            "[1447]\tvalid_0's multi_logloss: 0.179694\n",
            "[1448]\tvalid_0's multi_logloss: 0.179669\n",
            "[1449]\tvalid_0's multi_logloss: 0.179649\n",
            "[1450]\tvalid_0's multi_logloss: 0.179618\n",
            "[1451]\tvalid_0's multi_logloss: 0.17959\n",
            "[1452]\tvalid_0's multi_logloss: 0.179563\n",
            "[1453]\tvalid_0's multi_logloss: 0.179531\n",
            "[1454]\tvalid_0's multi_logloss: 0.179505\n",
            "[1455]\tvalid_0's multi_logloss: 0.179473\n",
            "[1456]\tvalid_0's multi_logloss: 0.17945\n",
            "[1457]\tvalid_0's multi_logloss: 0.179423\n",
            "[1458]\tvalid_0's multi_logloss: 0.179401\n",
            "[1459]\tvalid_0's multi_logloss: 0.179378\n",
            "[1460]\tvalid_0's multi_logloss: 0.179358\n",
            "[1461]\tvalid_0's multi_logloss: 0.179332\n",
            "[1462]\tvalid_0's multi_logloss: 0.179302\n",
            "[1463]\tvalid_0's multi_logloss: 0.179281\n",
            "[1464]\tvalid_0's multi_logloss: 0.179258\n",
            "[1465]\tvalid_0's multi_logloss: 0.179235\n",
            "[1466]\tvalid_0's multi_logloss: 0.179216\n",
            "[1467]\tvalid_0's multi_logloss: 0.179195\n",
            "[1468]\tvalid_0's multi_logloss: 0.179164\n",
            "[1469]\tvalid_0's multi_logloss: 0.179144\n",
            "[1470]\tvalid_0's multi_logloss: 0.17911\n",
            "[1471]\tvalid_0's multi_logloss: 0.179085\n",
            "[1472]\tvalid_0's multi_logloss: 0.179063\n",
            "[1473]\tvalid_0's multi_logloss: 0.179036\n",
            "[1474]\tvalid_0's multi_logloss: 0.179015\n",
            "[1475]\tvalid_0's multi_logloss: 0.17899\n",
            "[1476]\tvalid_0's multi_logloss: 0.178964\n",
            "[1477]\tvalid_0's multi_logloss: 0.178943\n",
            "[1478]\tvalid_0's multi_logloss: 0.178917\n",
            "[1479]\tvalid_0's multi_logloss: 0.178901\n",
            "[1480]\tvalid_0's multi_logloss: 0.178877\n",
            "[1481]\tvalid_0's multi_logloss: 0.17885\n",
            "[1482]\tvalid_0's multi_logloss: 0.178828\n",
            "[1483]\tvalid_0's multi_logloss: 0.178806\n",
            "[1484]\tvalid_0's multi_logloss: 0.178777\n",
            "[1485]\tvalid_0's multi_logloss: 0.178753\n",
            "[1486]\tvalid_0's multi_logloss: 0.178729\n",
            "[1487]\tvalid_0's multi_logloss: 0.178699\n",
            "[1488]\tvalid_0's multi_logloss: 0.17868\n",
            "[1489]\tvalid_0's multi_logloss: 0.178657\n",
            "[1490]\tvalid_0's multi_logloss: 0.178638\n",
            "[1491]\tvalid_0's multi_logloss: 0.17861\n",
            "[1492]\tvalid_0's multi_logloss: 0.178584\n",
            "[1493]\tvalid_0's multi_logloss: 0.178553\n",
            "[1494]\tvalid_0's multi_logloss: 0.178529\n",
            "[1495]\tvalid_0's multi_logloss: 0.1785\n",
            "[1496]\tvalid_0's multi_logloss: 0.178484\n",
            "[1497]\tvalid_0's multi_logloss: 0.178451\n",
            "[1498]\tvalid_0's multi_logloss: 0.178432\n",
            "[1499]\tvalid_0's multi_logloss: 0.178396\n",
            "[1500]\tvalid_0's multi_logloss: 0.178369\n",
            "[1501]\tvalid_0's multi_logloss: 0.178348\n",
            "[1502]\tvalid_0's multi_logloss: 0.178322\n",
            "[1503]\tvalid_0's multi_logloss: 0.178303\n",
            "[1504]\tvalid_0's multi_logloss: 0.178283\n",
            "[1505]\tvalid_0's multi_logloss: 0.178264\n",
            "[1506]\tvalid_0's multi_logloss: 0.178243\n",
            "[1507]\tvalid_0's multi_logloss: 0.178222\n",
            "[1508]\tvalid_0's multi_logloss: 0.178204\n",
            "[1509]\tvalid_0's multi_logloss: 0.178175\n",
            "[1510]\tvalid_0's multi_logloss: 0.178143\n",
            "[1511]\tvalid_0's multi_logloss: 0.178119\n",
            "[1512]\tvalid_0's multi_logloss: 0.178099\n",
            "[1513]\tvalid_0's multi_logloss: 0.17808\n",
            "[1514]\tvalid_0's multi_logloss: 0.178063\n",
            "[1515]\tvalid_0's multi_logloss: 0.17804\n",
            "[1516]\tvalid_0's multi_logloss: 0.178013\n",
            "[1517]\tvalid_0's multi_logloss: 0.177987\n",
            "[1518]\tvalid_0's multi_logloss: 0.177971\n",
            "[1519]\tvalid_0's multi_logloss: 0.177954\n",
            "[1520]\tvalid_0's multi_logloss: 0.177932\n",
            "[1521]\tvalid_0's multi_logloss: 0.177906\n",
            "[1522]\tvalid_0's multi_logloss: 0.177887\n",
            "[1523]\tvalid_0's multi_logloss: 0.177866\n",
            "[1524]\tvalid_0's multi_logloss: 0.177846\n",
            "[1525]\tvalid_0's multi_logloss: 0.177823\n",
            "[1526]\tvalid_0's multi_logloss: 0.1778\n",
            "[1527]\tvalid_0's multi_logloss: 0.177779\n",
            "[1528]\tvalid_0's multi_logloss: 0.17775\n",
            "[1529]\tvalid_0's multi_logloss: 0.177729\n",
            "[1530]\tvalid_0's multi_logloss: 0.177702\n",
            "[1531]\tvalid_0's multi_logloss: 0.177681\n",
            "[1532]\tvalid_0's multi_logloss: 0.177653\n",
            "[1533]\tvalid_0's multi_logloss: 0.177633\n",
            "[1534]\tvalid_0's multi_logloss: 0.177608\n",
            "[1535]\tvalid_0's multi_logloss: 0.177589\n",
            "[1536]\tvalid_0's multi_logloss: 0.177562\n",
            "[1537]\tvalid_0's multi_logloss: 0.177533\n",
            "[1538]\tvalid_0's multi_logloss: 0.177509\n",
            "[1539]\tvalid_0's multi_logloss: 0.17749\n",
            "[1540]\tvalid_0's multi_logloss: 0.177471\n",
            "[1541]\tvalid_0's multi_logloss: 0.177454\n",
            "[1542]\tvalid_0's multi_logloss: 0.177436\n",
            "[1543]\tvalid_0's multi_logloss: 0.177414\n",
            "[1544]\tvalid_0's multi_logloss: 0.177392\n",
            "[1545]\tvalid_0's multi_logloss: 0.177375\n",
            "[1546]\tvalid_0's multi_logloss: 0.17736\n",
            "[1547]\tvalid_0's multi_logloss: 0.177337\n",
            "[1548]\tvalid_0's multi_logloss: 0.177315\n",
            "[1549]\tvalid_0's multi_logloss: 0.17729\n",
            "[1550]\tvalid_0's multi_logloss: 0.177268\n",
            "[1551]\tvalid_0's multi_logloss: 0.177246\n",
            "[1552]\tvalid_0's multi_logloss: 0.177227\n",
            "[1553]\tvalid_0's multi_logloss: 0.177207\n",
            "[1554]\tvalid_0's multi_logloss: 0.177185\n",
            "[1555]\tvalid_0's multi_logloss: 0.177168\n",
            "[1556]\tvalid_0's multi_logloss: 0.177149\n",
            "[1557]\tvalid_0's multi_logloss: 0.177125\n",
            "[1558]\tvalid_0's multi_logloss: 0.177104\n",
            "[1559]\tvalid_0's multi_logloss: 0.177087\n",
            "[1560]\tvalid_0's multi_logloss: 0.177051\n",
            "[1561]\tvalid_0's multi_logloss: 0.177032\n",
            "[1562]\tvalid_0's multi_logloss: 0.17701\n",
            "[1563]\tvalid_0's multi_logloss: 0.17699\n",
            "[1564]\tvalid_0's multi_logloss: 0.176974\n",
            "[1565]\tvalid_0's multi_logloss: 0.176957\n",
            "[1566]\tvalid_0's multi_logloss: 0.176946\n",
            "[1567]\tvalid_0's multi_logloss: 0.176924\n",
            "[1568]\tvalid_0's multi_logloss: 0.176899\n",
            "[1569]\tvalid_0's multi_logloss: 0.176883\n",
            "[1570]\tvalid_0's multi_logloss: 0.17686\n",
            "[1571]\tvalid_0's multi_logloss: 0.17684\n",
            "[1572]\tvalid_0's multi_logloss: 0.176826\n",
            "[1573]\tvalid_0's multi_logloss: 0.176804\n",
            "[1574]\tvalid_0's multi_logloss: 0.176788\n",
            "[1575]\tvalid_0's multi_logloss: 0.176774\n",
            "[1576]\tvalid_0's multi_logloss: 0.17675\n",
            "[1577]\tvalid_0's multi_logloss: 0.176726\n",
            "[1578]\tvalid_0's multi_logloss: 0.176706\n",
            "[1579]\tvalid_0's multi_logloss: 0.176688\n",
            "[1580]\tvalid_0's multi_logloss: 0.176668\n",
            "[1581]\tvalid_0's multi_logloss: 0.176649\n",
            "[1582]\tvalid_0's multi_logloss: 0.176628\n",
            "[1583]\tvalid_0's multi_logloss: 0.176612\n",
            "[1584]\tvalid_0's multi_logloss: 0.176587\n",
            "[1585]\tvalid_0's multi_logloss: 0.176569\n",
            "[1586]\tvalid_0's multi_logloss: 0.176548\n",
            "[1587]\tvalid_0's multi_logloss: 0.17652\n",
            "[1588]\tvalid_0's multi_logloss: 0.176499\n",
            "[1589]\tvalid_0's multi_logloss: 0.176477\n",
            "[1590]\tvalid_0's multi_logloss: 0.176459\n",
            "[1591]\tvalid_0's multi_logloss: 0.176437\n",
            "[1592]\tvalid_0's multi_logloss: 0.176417\n",
            "[1593]\tvalid_0's multi_logloss: 0.176393\n",
            "[1594]\tvalid_0's multi_logloss: 0.176372\n",
            "[1595]\tvalid_0's multi_logloss: 0.176352\n",
            "[1596]\tvalid_0's multi_logloss: 0.176335\n",
            "[1597]\tvalid_0's multi_logloss: 0.176311\n",
            "[1598]\tvalid_0's multi_logloss: 0.176291\n",
            "[1599]\tvalid_0's multi_logloss: 0.176272\n",
            "[1600]\tvalid_0's multi_logloss: 0.17625\n",
            "[1601]\tvalid_0's multi_logloss: 0.176235\n",
            "[1602]\tvalid_0's multi_logloss: 0.176207\n",
            "[1603]\tvalid_0's multi_logloss: 0.176191\n",
            "[1604]\tvalid_0's multi_logloss: 0.176174\n",
            "[1605]\tvalid_0's multi_logloss: 0.176161\n",
            "[1606]\tvalid_0's multi_logloss: 0.176137\n",
            "[1607]\tvalid_0's multi_logloss: 0.176111\n",
            "[1608]\tvalid_0's multi_logloss: 0.176085\n",
            "[1609]\tvalid_0's multi_logloss: 0.176069\n",
            "[1610]\tvalid_0's multi_logloss: 0.176055\n",
            "[1611]\tvalid_0's multi_logloss: 0.176032\n",
            "[1612]\tvalid_0's multi_logloss: 0.17602\n",
            "[1613]\tvalid_0's multi_logloss: 0.176002\n",
            "[1614]\tvalid_0's multi_logloss: 0.175979\n",
            "[1615]\tvalid_0's multi_logloss: 0.175959\n",
            "[1616]\tvalid_0's multi_logloss: 0.175939\n",
            "[1617]\tvalid_0's multi_logloss: 0.175917\n",
            "[1618]\tvalid_0's multi_logloss: 0.175902\n",
            "[1619]\tvalid_0's multi_logloss: 0.175878\n",
            "[1620]\tvalid_0's multi_logloss: 0.175857\n",
            "[1621]\tvalid_0's multi_logloss: 0.175837\n",
            "[1622]\tvalid_0's multi_logloss: 0.175814\n",
            "[1623]\tvalid_0's multi_logloss: 0.175803\n",
            "[1624]\tvalid_0's multi_logloss: 0.175781\n",
            "[1625]\tvalid_0's multi_logloss: 0.175763\n",
            "[1626]\tvalid_0's multi_logloss: 0.175743\n",
            "[1627]\tvalid_0's multi_logloss: 0.175724\n",
            "[1628]\tvalid_0's multi_logloss: 0.175706\n",
            "[1629]\tvalid_0's multi_logloss: 0.17569\n",
            "[1630]\tvalid_0's multi_logloss: 0.175669\n",
            "[1631]\tvalid_0's multi_logloss: 0.175651\n",
            "[1632]\tvalid_0's multi_logloss: 0.175632\n",
            "[1633]\tvalid_0's multi_logloss: 0.175612\n",
            "[1634]\tvalid_0's multi_logloss: 0.175599\n",
            "[1635]\tvalid_0's multi_logloss: 0.17558\n",
            "[1636]\tvalid_0's multi_logloss: 0.175551\n",
            "[1637]\tvalid_0's multi_logloss: 0.175529\n",
            "[1638]\tvalid_0's multi_logloss: 0.175506\n",
            "[1639]\tvalid_0's multi_logloss: 0.175485\n",
            "[1640]\tvalid_0's multi_logloss: 0.175457\n",
            "[1641]\tvalid_0's multi_logloss: 0.175438\n",
            "[1642]\tvalid_0's multi_logloss: 0.175422\n",
            "[1643]\tvalid_0's multi_logloss: 0.175403\n",
            "[1644]\tvalid_0's multi_logloss: 0.175392\n",
            "[1645]\tvalid_0's multi_logloss: 0.175377\n",
            "[1646]\tvalid_0's multi_logloss: 0.175367\n",
            "[1647]\tvalid_0's multi_logloss: 0.175348\n",
            "[1648]\tvalid_0's multi_logloss: 0.175324\n",
            "[1649]\tvalid_0's multi_logloss: 0.175308\n",
            "[1650]\tvalid_0's multi_logloss: 0.175292\n",
            "[1651]\tvalid_0's multi_logloss: 0.175277\n",
            "[1652]\tvalid_0's multi_logloss: 0.175263\n",
            "[1653]\tvalid_0's multi_logloss: 0.175238\n",
            "[1654]\tvalid_0's multi_logloss: 0.175221\n",
            "[1655]\tvalid_0's multi_logloss: 0.175208\n",
            "[1656]\tvalid_0's multi_logloss: 0.175196\n",
            "[1657]\tvalid_0's multi_logloss: 0.175176\n",
            "[1658]\tvalid_0's multi_logloss: 0.17516\n",
            "[1659]\tvalid_0's multi_logloss: 0.17514\n",
            "[1660]\tvalid_0's multi_logloss: 0.175122\n",
            "[1661]\tvalid_0's multi_logloss: 0.175107\n",
            "[1662]\tvalid_0's multi_logloss: 0.175088\n",
            "[1663]\tvalid_0's multi_logloss: 0.175064\n",
            "[1664]\tvalid_0's multi_logloss: 0.175045\n",
            "[1665]\tvalid_0's multi_logloss: 0.175034\n",
            "[1666]\tvalid_0's multi_logloss: 0.175019\n",
            "[1667]\tvalid_0's multi_logloss: 0.175005\n",
            "[1668]\tvalid_0's multi_logloss: 0.174988\n",
            "[1669]\tvalid_0's multi_logloss: 0.174965\n",
            "[1670]\tvalid_0's multi_logloss: 0.174944\n",
            "[1671]\tvalid_0's multi_logloss: 0.174927\n",
            "[1672]\tvalid_0's multi_logloss: 0.174904\n",
            "[1673]\tvalid_0's multi_logloss: 0.174889\n",
            "[1674]\tvalid_0's multi_logloss: 0.174876\n",
            "[1675]\tvalid_0's multi_logloss: 0.174858\n",
            "[1676]\tvalid_0's multi_logloss: 0.174844\n",
            "[1677]\tvalid_0's multi_logloss: 0.174824\n",
            "[1678]\tvalid_0's multi_logloss: 0.174813\n",
            "[1679]\tvalid_0's multi_logloss: 0.174795\n",
            "[1680]\tvalid_0's multi_logloss: 0.174779\n",
            "[1681]\tvalid_0's multi_logloss: 0.174757\n",
            "[1682]\tvalid_0's multi_logloss: 0.174738\n",
            "[1683]\tvalid_0's multi_logloss: 0.174714\n",
            "[1684]\tvalid_0's multi_logloss: 0.174686\n",
            "[1685]\tvalid_0's multi_logloss: 0.174669\n",
            "[1686]\tvalid_0's multi_logloss: 0.174655\n",
            "[1687]\tvalid_0's multi_logloss: 0.174637\n",
            "[1688]\tvalid_0's multi_logloss: 0.174619\n",
            "[1689]\tvalid_0's multi_logloss: 0.174594\n",
            "[1690]\tvalid_0's multi_logloss: 0.174575\n",
            "[1691]\tvalid_0's multi_logloss: 0.174553\n",
            "[1692]\tvalid_0's multi_logloss: 0.174535\n",
            "[1693]\tvalid_0's multi_logloss: 0.174524\n",
            "[1694]\tvalid_0's multi_logloss: 0.174506\n",
            "[1695]\tvalid_0's multi_logloss: 0.174495\n",
            "[1696]\tvalid_0's multi_logloss: 0.174482\n",
            "[1697]\tvalid_0's multi_logloss: 0.174459\n",
            "[1698]\tvalid_0's multi_logloss: 0.174445\n",
            "[1699]\tvalid_0's multi_logloss: 0.174422\n",
            "[1700]\tvalid_0's multi_logloss: 0.174409\n",
            "[1701]\tvalid_0's multi_logloss: 0.174392\n",
            "[1702]\tvalid_0's multi_logloss: 0.174375\n",
            "[1703]\tvalid_0's multi_logloss: 0.174353\n",
            "[1704]\tvalid_0's multi_logloss: 0.174336\n",
            "[1705]\tvalid_0's multi_logloss: 0.17432\n",
            "[1706]\tvalid_0's multi_logloss: 0.174313\n",
            "[1707]\tvalid_0's multi_logloss: 0.174292\n",
            "[1708]\tvalid_0's multi_logloss: 0.174279\n",
            "[1709]\tvalid_0's multi_logloss: 0.174265\n",
            "[1710]\tvalid_0's multi_logloss: 0.174247\n",
            "[1711]\tvalid_0's multi_logloss: 0.174233\n",
            "[1712]\tvalid_0's multi_logloss: 0.174216\n",
            "[1713]\tvalid_0's multi_logloss: 0.174203\n",
            "[1714]\tvalid_0's multi_logloss: 0.17419\n",
            "[1715]\tvalid_0's multi_logloss: 0.174171\n",
            "[1716]\tvalid_0's multi_logloss: 0.174155\n",
            "[1717]\tvalid_0's multi_logloss: 0.174126\n",
            "[1718]\tvalid_0's multi_logloss: 0.174109\n",
            "[1719]\tvalid_0's multi_logloss: 0.174098\n",
            "[1720]\tvalid_0's multi_logloss: 0.174079\n",
            "[1721]\tvalid_0's multi_logloss: 0.174062\n",
            "[1722]\tvalid_0's multi_logloss: 0.174043\n",
            "[1723]\tvalid_0's multi_logloss: 0.174019\n",
            "[1724]\tvalid_0's multi_logloss: 0.174002\n",
            "[1725]\tvalid_0's multi_logloss: 0.173987\n",
            "[1726]\tvalid_0's multi_logloss: 0.173969\n",
            "[1727]\tvalid_0's multi_logloss: 0.173956\n",
            "[1728]\tvalid_0's multi_logloss: 0.173938\n",
            "[1729]\tvalid_0's multi_logloss: 0.173924\n",
            "[1730]\tvalid_0's multi_logloss: 0.173915\n",
            "[1731]\tvalid_0's multi_logloss: 0.173904\n",
            "[1732]\tvalid_0's multi_logloss: 0.17389\n",
            "[1733]\tvalid_0's multi_logloss: 0.173871\n",
            "[1734]\tvalid_0's multi_logloss: 0.173854\n",
            "[1735]\tvalid_0's multi_logloss: 0.173838\n",
            "[1736]\tvalid_0's multi_logloss: 0.173821\n",
            "[1737]\tvalid_0's multi_logloss: 0.173804\n",
            "[1738]\tvalid_0's multi_logloss: 0.173787\n",
            "[1739]\tvalid_0's multi_logloss: 0.173779\n",
            "[1740]\tvalid_0's multi_logloss: 0.173756\n",
            "[1741]\tvalid_0's multi_logloss: 0.17374\n",
            "[1742]\tvalid_0's multi_logloss: 0.17373\n",
            "[1743]\tvalid_0's multi_logloss: 0.173717\n",
            "[1744]\tvalid_0's multi_logloss: 0.17371\n",
            "[1745]\tvalid_0's multi_logloss: 0.17369\n",
            "[1746]\tvalid_0's multi_logloss: 0.173675\n",
            "[1747]\tvalid_0's multi_logloss: 0.173662\n",
            "[1748]\tvalid_0's multi_logloss: 0.173645\n",
            "[1749]\tvalid_0's multi_logloss: 0.173628\n",
            "[1750]\tvalid_0's multi_logloss: 0.173618\n",
            "[1751]\tvalid_0's multi_logloss: 0.173608\n",
            "[1752]\tvalid_0's multi_logloss: 0.173591\n",
            "[1753]\tvalid_0's multi_logloss: 0.173569\n",
            "[1754]\tvalid_0's multi_logloss: 0.173551\n",
            "[1755]\tvalid_0's multi_logloss: 0.173543\n",
            "[1756]\tvalid_0's multi_logloss: 0.173524\n",
            "[1757]\tvalid_0's multi_logloss: 0.173513\n",
            "[1758]\tvalid_0's multi_logloss: 0.173497\n",
            "[1759]\tvalid_0's multi_logloss: 0.173483\n",
            "[1760]\tvalid_0's multi_logloss: 0.173469\n",
            "[1761]\tvalid_0's multi_logloss: 0.173457\n",
            "[1762]\tvalid_0's multi_logloss: 0.173442\n",
            "[1763]\tvalid_0's multi_logloss: 0.173423\n",
            "[1764]\tvalid_0's multi_logloss: 0.173397\n",
            "[1765]\tvalid_0's multi_logloss: 0.173383\n",
            "[1766]\tvalid_0's multi_logloss: 0.17337\n",
            "[1767]\tvalid_0's multi_logloss: 0.17335\n",
            "[1768]\tvalid_0's multi_logloss: 0.173337\n",
            "[1769]\tvalid_0's multi_logloss: 0.17332\n",
            "[1770]\tvalid_0's multi_logloss: 0.173308\n",
            "[1771]\tvalid_0's multi_logloss: 0.173294\n",
            "[1772]\tvalid_0's multi_logloss: 0.173278\n",
            "[1773]\tvalid_0's multi_logloss: 0.173264\n",
            "[1774]\tvalid_0's multi_logloss: 0.173252\n",
            "[1775]\tvalid_0's multi_logloss: 0.173241\n",
            "[1776]\tvalid_0's multi_logloss: 0.173227\n",
            "[1777]\tvalid_0's multi_logloss: 0.173205\n",
            "[1778]\tvalid_0's multi_logloss: 0.173196\n",
            "[1779]\tvalid_0's multi_logloss: 0.173177\n",
            "[1780]\tvalid_0's multi_logloss: 0.173169\n",
            "[1781]\tvalid_0's multi_logloss: 0.173158\n",
            "[1782]\tvalid_0's multi_logloss: 0.173142\n",
            "[1783]\tvalid_0's multi_logloss: 0.173127\n",
            "[1784]\tvalid_0's multi_logloss: 0.173121\n",
            "[1785]\tvalid_0's multi_logloss: 0.173114\n",
            "[1786]\tvalid_0's multi_logloss: 0.173101\n",
            "[1787]\tvalid_0's multi_logloss: 0.173088\n",
            "[1788]\tvalid_0's multi_logloss: 0.173076\n",
            "[1789]\tvalid_0's multi_logloss: 0.173064\n",
            "[1790]\tvalid_0's multi_logloss: 0.173052\n",
            "[1791]\tvalid_0's multi_logloss: 0.173041\n",
            "[1792]\tvalid_0's multi_logloss: 0.173027\n",
            "[1793]\tvalid_0's multi_logloss: 0.173012\n",
            "[1794]\tvalid_0's multi_logloss: 0.172989\n",
            "[1795]\tvalid_0's multi_logloss: 0.172975\n",
            "[1796]\tvalid_0's multi_logloss: 0.172967\n",
            "[1797]\tvalid_0's multi_logloss: 0.172956\n",
            "[1798]\tvalid_0's multi_logloss: 0.172948\n",
            "[1799]\tvalid_0's multi_logloss: 0.172934\n",
            "[1800]\tvalid_0's multi_logloss: 0.172917\n",
            "[1801]\tvalid_0's multi_logloss: 0.172904\n",
            "[1802]\tvalid_0's multi_logloss: 0.17289\n",
            "[1803]\tvalid_0's multi_logloss: 0.172874\n",
            "[1804]\tvalid_0's multi_logloss: 0.172855\n",
            "[1805]\tvalid_0's multi_logloss: 0.172841\n",
            "[1806]\tvalid_0's multi_logloss: 0.172825\n",
            "[1807]\tvalid_0's multi_logloss: 0.172819\n",
            "[1808]\tvalid_0's multi_logloss: 0.172808\n",
            "[1809]\tvalid_0's multi_logloss: 0.172793\n",
            "[1810]\tvalid_0's multi_logloss: 0.17278\n",
            "[1811]\tvalid_0's multi_logloss: 0.172767\n",
            "[1812]\tvalid_0's multi_logloss: 0.172756\n",
            "[1813]\tvalid_0's multi_logloss: 0.172747\n",
            "[1814]\tvalid_0's multi_logloss: 0.17273\n",
            "[1815]\tvalid_0's multi_logloss: 0.17271\n",
            "[1816]\tvalid_0's multi_logloss: 0.172704\n",
            "[1817]\tvalid_0's multi_logloss: 0.172693\n",
            "[1818]\tvalid_0's multi_logloss: 0.172679\n",
            "[1819]\tvalid_0's multi_logloss: 0.172672\n",
            "[1820]\tvalid_0's multi_logloss: 0.172658\n",
            "[1821]\tvalid_0's multi_logloss: 0.172645\n",
            "[1822]\tvalid_0's multi_logloss: 0.172635\n",
            "[1823]\tvalid_0's multi_logloss: 0.172628\n",
            "[1824]\tvalid_0's multi_logloss: 0.172613\n",
            "[1825]\tvalid_0's multi_logloss: 0.172601\n",
            "[1826]\tvalid_0's multi_logloss: 0.172587\n",
            "[1827]\tvalid_0's multi_logloss: 0.172566\n",
            "[1828]\tvalid_0's multi_logloss: 0.17256\n",
            "[1829]\tvalid_0's multi_logloss: 0.172549\n",
            "[1830]\tvalid_0's multi_logloss: 0.172539\n",
            "[1831]\tvalid_0's multi_logloss: 0.172525\n",
            "[1832]\tvalid_0's multi_logloss: 0.172517\n",
            "[1833]\tvalid_0's multi_logloss: 0.172502\n",
            "[1834]\tvalid_0's multi_logloss: 0.172482\n",
            "[1835]\tvalid_0's multi_logloss: 0.172461\n",
            "[1836]\tvalid_0's multi_logloss: 0.172451\n",
            "[1837]\tvalid_0's multi_logloss: 0.172443\n",
            "[1838]\tvalid_0's multi_logloss: 0.17243\n",
            "[1839]\tvalid_0's multi_logloss: 0.172421\n",
            "[1840]\tvalid_0's multi_logloss: 0.172407\n",
            "[1841]\tvalid_0's multi_logloss: 0.172395\n",
            "[1842]\tvalid_0's multi_logloss: 0.172381\n",
            "[1843]\tvalid_0's multi_logloss: 0.172366\n",
            "[1844]\tvalid_0's multi_logloss: 0.172356\n",
            "[1845]\tvalid_0's multi_logloss: 0.172341\n",
            "[1846]\tvalid_0's multi_logloss: 0.172331\n",
            "[1847]\tvalid_0's multi_logloss: 0.172329\n",
            "[1848]\tvalid_0's multi_logloss: 0.172311\n",
            "[1849]\tvalid_0's multi_logloss: 0.172292\n",
            "[1850]\tvalid_0's multi_logloss: 0.172282\n",
            "[1851]\tvalid_0's multi_logloss: 0.17227\n",
            "[1852]\tvalid_0's multi_logloss: 0.172254\n",
            "[1853]\tvalid_0's multi_logloss: 0.172238\n",
            "[1854]\tvalid_0's multi_logloss: 0.172224\n",
            "[1855]\tvalid_0's multi_logloss: 0.172209\n",
            "[1856]\tvalid_0's multi_logloss: 0.172194\n",
            "[1857]\tvalid_0's multi_logloss: 0.172175\n",
            "[1858]\tvalid_0's multi_logloss: 0.172172\n",
            "[1859]\tvalid_0's multi_logloss: 0.172161\n",
            "[1860]\tvalid_0's multi_logloss: 0.172153\n",
            "[1861]\tvalid_0's multi_logloss: 0.172143\n",
            "[1862]\tvalid_0's multi_logloss: 0.172136\n",
            "[1863]\tvalid_0's multi_logloss: 0.172124\n",
            "[1864]\tvalid_0's multi_logloss: 0.172111\n",
            "[1865]\tvalid_0's multi_logloss: 0.172103\n",
            "[1866]\tvalid_0's multi_logloss: 0.172092\n",
            "[1867]\tvalid_0's multi_logloss: 0.172082\n",
            "[1868]\tvalid_0's multi_logloss: 0.17207\n",
            "[1869]\tvalid_0's multi_logloss: 0.172059\n",
            "[1870]\tvalid_0's multi_logloss: 0.172051\n",
            "[1871]\tvalid_0's multi_logloss: 0.17204\n",
            "[1872]\tvalid_0's multi_logloss: 0.172029\n",
            "[1873]\tvalid_0's multi_logloss: 0.172013\n",
            "[1874]\tvalid_0's multi_logloss: 0.172005\n",
            "[1875]\tvalid_0's multi_logloss: 0.171993\n",
            "[1876]\tvalid_0's multi_logloss: 0.171975\n",
            "[1877]\tvalid_0's multi_logloss: 0.171963\n",
            "[1878]\tvalid_0's multi_logloss: 0.171947\n",
            "[1879]\tvalid_0's multi_logloss: 0.171937\n",
            "[1880]\tvalid_0's multi_logloss: 0.171929\n",
            "[1881]\tvalid_0's multi_logloss: 0.171919\n",
            "[1882]\tvalid_0's multi_logloss: 0.171896\n",
            "[1883]\tvalid_0's multi_logloss: 0.171886\n",
            "[1884]\tvalid_0's multi_logloss: 0.171875\n",
            "[1885]\tvalid_0's multi_logloss: 0.171864\n",
            "[1886]\tvalid_0's multi_logloss: 0.171855\n",
            "[1887]\tvalid_0's multi_logloss: 0.171834\n",
            "[1888]\tvalid_0's multi_logloss: 0.171815\n",
            "[1889]\tvalid_0's multi_logloss: 0.171803\n",
            "[1890]\tvalid_0's multi_logloss: 0.171785\n",
            "[1891]\tvalid_0's multi_logloss: 0.171772\n",
            "[1892]\tvalid_0's multi_logloss: 0.171757\n",
            "[1893]\tvalid_0's multi_logloss: 0.171747\n",
            "[1894]\tvalid_0's multi_logloss: 0.171736\n",
            "[1895]\tvalid_0's multi_logloss: 0.17172\n",
            "[1896]\tvalid_0's multi_logloss: 0.171704\n",
            "[1897]\tvalid_0's multi_logloss: 0.171702\n",
            "[1898]\tvalid_0's multi_logloss: 0.171693\n",
            "[1899]\tvalid_0's multi_logloss: 0.171681\n",
            "[1900]\tvalid_0's multi_logloss: 0.171674\n",
            "[1901]\tvalid_0's multi_logloss: 0.171661\n",
            "[1902]\tvalid_0's multi_logloss: 0.171649\n",
            "[1903]\tvalid_0's multi_logloss: 0.171638\n",
            "[1904]\tvalid_0's multi_logloss: 0.171627\n",
            "[1905]\tvalid_0's multi_logloss: 0.171609\n",
            "[1906]\tvalid_0's multi_logloss: 0.171598\n",
            "[1907]\tvalid_0's multi_logloss: 0.171587\n",
            "[1908]\tvalid_0's multi_logloss: 0.171575\n",
            "[1909]\tvalid_0's multi_logloss: 0.171566\n",
            "[1910]\tvalid_0's multi_logloss: 0.171559\n",
            "[1911]\tvalid_0's multi_logloss: 0.171545\n",
            "[1912]\tvalid_0's multi_logloss: 0.171531\n",
            "[1913]\tvalid_0's multi_logloss: 0.171517\n",
            "[1914]\tvalid_0's multi_logloss: 0.171513\n",
            "[1915]\tvalid_0's multi_logloss: 0.171499\n",
            "[1916]\tvalid_0's multi_logloss: 0.171486\n",
            "[1917]\tvalid_0's multi_logloss: 0.171479\n",
            "[1918]\tvalid_0's multi_logloss: 0.171465\n",
            "[1919]\tvalid_0's multi_logloss: 0.171454\n",
            "[1920]\tvalid_0's multi_logloss: 0.171443\n",
            "[1921]\tvalid_0's multi_logloss: 0.171435\n",
            "[1922]\tvalid_0's multi_logloss: 0.171425\n",
            "[1923]\tvalid_0's multi_logloss: 0.171405\n",
            "[1924]\tvalid_0's multi_logloss: 0.171393\n",
            "[1925]\tvalid_0's multi_logloss: 0.171382\n",
            "[1926]\tvalid_0's multi_logloss: 0.171371\n",
            "[1927]\tvalid_0's multi_logloss: 0.171361\n",
            "[1928]\tvalid_0's multi_logloss: 0.171345\n",
            "[1929]\tvalid_0's multi_logloss: 0.171331\n",
            "[1930]\tvalid_0's multi_logloss: 0.171318\n",
            "[1931]\tvalid_0's multi_logloss: 0.171301\n",
            "[1932]\tvalid_0's multi_logloss: 0.171288\n",
            "[1933]\tvalid_0's multi_logloss: 0.171278\n",
            "[1934]\tvalid_0's multi_logloss: 0.17126\n",
            "[1935]\tvalid_0's multi_logloss: 0.17125\n",
            "[1936]\tvalid_0's multi_logloss: 0.171236\n",
            "[1937]\tvalid_0's multi_logloss: 0.171226\n",
            "[1938]\tvalid_0's multi_logloss: 0.17121\n",
            "[1939]\tvalid_0's multi_logloss: 0.171201\n",
            "[1940]\tvalid_0's multi_logloss: 0.171185\n",
            "[1941]\tvalid_0's multi_logloss: 0.171173\n",
            "[1942]\tvalid_0's multi_logloss: 0.171157\n",
            "[1943]\tvalid_0's multi_logloss: 0.171153\n",
            "[1944]\tvalid_0's multi_logloss: 0.171143\n",
            "[1945]\tvalid_0's multi_logloss: 0.171134\n",
            "[1946]\tvalid_0's multi_logloss: 0.17112\n",
            "[1947]\tvalid_0's multi_logloss: 0.171112\n",
            "[1948]\tvalid_0's multi_logloss: 0.171102\n",
            "[1949]\tvalid_0's multi_logloss: 0.171092\n",
            "[1950]\tvalid_0's multi_logloss: 0.171084\n",
            "[1951]\tvalid_0's multi_logloss: 0.171073\n",
            "[1952]\tvalid_0's multi_logloss: 0.171067\n",
            "[1953]\tvalid_0's multi_logloss: 0.17104\n",
            "[1954]\tvalid_0's multi_logloss: 0.171034\n",
            "[1955]\tvalid_0's multi_logloss: 0.171018\n",
            "[1956]\tvalid_0's multi_logloss: 0.171005\n",
            "[1957]\tvalid_0's multi_logloss: 0.170994\n",
            "[1958]\tvalid_0's multi_logloss: 0.170987\n",
            "[1959]\tvalid_0's multi_logloss: 0.170978\n",
            "[1960]\tvalid_0's multi_logloss: 0.170969\n",
            "[1961]\tvalid_0's multi_logloss: 0.170962\n",
            "[1962]\tvalid_0's multi_logloss: 0.170949\n",
            "[1963]\tvalid_0's multi_logloss: 0.170937\n",
            "[1964]\tvalid_0's multi_logloss: 0.170926\n",
            "[1965]\tvalid_0's multi_logloss: 0.170914\n",
            "[1966]\tvalid_0's multi_logloss: 0.170901\n",
            "[1967]\tvalid_0's multi_logloss: 0.17089\n",
            "[1968]\tvalid_0's multi_logloss: 0.170886\n",
            "[1969]\tvalid_0's multi_logloss: 0.170878\n",
            "[1970]\tvalid_0's multi_logloss: 0.170865\n",
            "[1971]\tvalid_0's multi_logloss: 0.170851\n",
            "[1972]\tvalid_0's multi_logloss: 0.170838\n",
            "[1973]\tvalid_0's multi_logloss: 0.170828\n",
            "[1974]\tvalid_0's multi_logloss: 0.17081\n",
            "[1975]\tvalid_0's multi_logloss: 0.170796\n",
            "[1976]\tvalid_0's multi_logloss: 0.170783\n",
            "[1977]\tvalid_0's multi_logloss: 0.170771\n",
            "[1978]\tvalid_0's multi_logloss: 0.170762\n",
            "[1979]\tvalid_0's multi_logloss: 0.170744\n",
            "[1980]\tvalid_0's multi_logloss: 0.170728\n",
            "[1981]\tvalid_0's multi_logloss: 0.170718\n",
            "[1982]\tvalid_0's multi_logloss: 0.170715\n",
            "[1983]\tvalid_0's multi_logloss: 0.170712\n",
            "[1984]\tvalid_0's multi_logloss: 0.170703\n",
            "[1985]\tvalid_0's multi_logloss: 0.170691\n",
            "[1986]\tvalid_0's multi_logloss: 0.170682\n",
            "[1987]\tvalid_0's multi_logloss: 0.170678\n",
            "[1988]\tvalid_0's multi_logloss: 0.170669\n",
            "[1989]\tvalid_0's multi_logloss: 0.170656\n",
            "[1990]\tvalid_0's multi_logloss: 0.170648\n",
            "[1991]\tvalid_0's multi_logloss: 0.170636\n",
            "[1992]\tvalid_0's multi_logloss: 0.170631\n",
            "[1993]\tvalid_0's multi_logloss: 0.170617\n",
            "[1994]\tvalid_0's multi_logloss: 0.170611\n",
            "[1995]\tvalid_0's multi_logloss: 0.170594\n",
            "[1996]\tvalid_0's multi_logloss: 0.170575\n",
            "[1997]\tvalid_0's multi_logloss: 0.170568\n",
            "[1998]\tvalid_0's multi_logloss: 0.170559\n",
            "[1999]\tvalid_0's multi_logloss: 0.170543\n",
            "[2000]\tvalid_0's multi_logloss: 0.170538\n",
            "[2001]\tvalid_0's multi_logloss: 0.170529\n",
            "[2002]\tvalid_0's multi_logloss: 0.170524\n",
            "[2003]\tvalid_0's multi_logloss: 0.170522\n",
            "[2004]\tvalid_0's multi_logloss: 0.170508\n",
            "[2005]\tvalid_0's multi_logloss: 0.170502\n",
            "[2006]\tvalid_0's multi_logloss: 0.17049\n",
            "[2007]\tvalid_0's multi_logloss: 0.170489\n",
            "[2008]\tvalid_0's multi_logloss: 0.17047\n",
            "[2009]\tvalid_0's multi_logloss: 0.170453\n",
            "[2010]\tvalid_0's multi_logloss: 0.17044\n",
            "[2011]\tvalid_0's multi_logloss: 0.170434\n",
            "[2012]\tvalid_0's multi_logloss: 0.170419\n",
            "[2013]\tvalid_0's multi_logloss: 0.17041\n",
            "[2014]\tvalid_0's multi_logloss: 0.170399\n",
            "[2015]\tvalid_0's multi_logloss: 0.170389\n",
            "[2016]\tvalid_0's multi_logloss: 0.170369\n",
            "[2017]\tvalid_0's multi_logloss: 0.170354\n",
            "[2018]\tvalid_0's multi_logloss: 0.170337\n",
            "[2019]\tvalid_0's multi_logloss: 0.170331\n",
            "[2020]\tvalid_0's multi_logloss: 0.170318\n",
            "[2021]\tvalid_0's multi_logloss: 0.170307\n",
            "[2022]\tvalid_0's multi_logloss: 0.170303\n",
            "[2023]\tvalid_0's multi_logloss: 0.170294\n",
            "[2024]\tvalid_0's multi_logloss: 0.170285\n",
            "[2025]\tvalid_0's multi_logloss: 0.170273\n",
            "[2026]\tvalid_0's multi_logloss: 0.170262\n",
            "[2027]\tvalid_0's multi_logloss: 0.170252\n",
            "[2028]\tvalid_0's multi_logloss: 0.170242\n",
            "[2029]\tvalid_0's multi_logloss: 0.170238\n",
            "[2030]\tvalid_0's multi_logloss: 0.170227\n",
            "[2031]\tvalid_0's multi_logloss: 0.17022\n",
            "[2032]\tvalid_0's multi_logloss: 0.170211\n",
            "[2033]\tvalid_0's multi_logloss: 0.170203\n",
            "[2034]\tvalid_0's multi_logloss: 0.170193\n",
            "[2035]\tvalid_0's multi_logloss: 0.170188\n",
            "[2036]\tvalid_0's multi_logloss: 0.170184\n",
            "[2037]\tvalid_0's multi_logloss: 0.170175\n",
            "[2038]\tvalid_0's multi_logloss: 0.170176\n",
            "[2039]\tvalid_0's multi_logloss: 0.170166\n",
            "[2040]\tvalid_0's multi_logloss: 0.170163\n",
            "[2041]\tvalid_0's multi_logloss: 0.170146\n",
            "[2042]\tvalid_0's multi_logloss: 0.170139\n",
            "[2043]\tvalid_0's multi_logloss: 0.170133\n",
            "[2044]\tvalid_0's multi_logloss: 0.170121\n",
            "[2045]\tvalid_0's multi_logloss: 0.170113\n",
            "[2046]\tvalid_0's multi_logloss: 0.170103\n",
            "[2047]\tvalid_0's multi_logloss: 0.170094\n",
            "[2048]\tvalid_0's multi_logloss: 0.170084\n",
            "[2049]\tvalid_0's multi_logloss: 0.170074\n",
            "[2050]\tvalid_0's multi_logloss: 0.170063\n",
            "[2051]\tvalid_0's multi_logloss: 0.170052\n",
            "[2052]\tvalid_0's multi_logloss: 0.17004\n",
            "[2053]\tvalid_0's multi_logloss: 0.170032\n",
            "[2054]\tvalid_0's multi_logloss: 0.170018\n",
            "[2055]\tvalid_0's multi_logloss: 0.170006\n",
            "[2056]\tvalid_0's multi_logloss: 0.169997\n",
            "[2057]\tvalid_0's multi_logloss: 0.169987\n",
            "[2058]\tvalid_0's multi_logloss: 0.169975\n",
            "[2059]\tvalid_0's multi_logloss: 0.169966\n",
            "[2060]\tvalid_0's multi_logloss: 0.169957\n",
            "[2061]\tvalid_0's multi_logloss: 0.16995\n",
            "[2062]\tvalid_0's multi_logloss: 0.169941\n",
            "[2063]\tvalid_0's multi_logloss: 0.169938\n",
            "[2064]\tvalid_0's multi_logloss: 0.169929\n",
            "[2065]\tvalid_0's multi_logloss: 0.169922\n",
            "[2066]\tvalid_0's multi_logloss: 0.16992\n",
            "[2067]\tvalid_0's multi_logloss: 0.169908\n",
            "[2068]\tvalid_0's multi_logloss: 0.169897\n",
            "[2069]\tvalid_0's multi_logloss: 0.169879\n",
            "[2070]\tvalid_0's multi_logloss: 0.169873\n",
            "[2071]\tvalid_0's multi_logloss: 0.16986\n",
            "[2072]\tvalid_0's multi_logloss: 0.169853\n",
            "[2073]\tvalid_0's multi_logloss: 0.169848\n",
            "[2074]\tvalid_0's multi_logloss: 0.169848\n",
            "[2075]\tvalid_0's multi_logloss: 0.169839\n",
            "[2076]\tvalid_0's multi_logloss: 0.169836\n",
            "[2077]\tvalid_0's multi_logloss: 0.169826\n",
            "[2078]\tvalid_0's multi_logloss: 0.16982\n",
            "[2079]\tvalid_0's multi_logloss: 0.169814\n",
            "[2080]\tvalid_0's multi_logloss: 0.169806\n",
            "[2081]\tvalid_0's multi_logloss: 0.169798\n",
            "[2082]\tvalid_0's multi_logloss: 0.169788\n",
            "[2083]\tvalid_0's multi_logloss: 0.169777\n",
            "[2084]\tvalid_0's multi_logloss: 0.169766\n",
            "[2085]\tvalid_0's multi_logloss: 0.169758\n",
            "[2086]\tvalid_0's multi_logloss: 0.169745\n",
            "[2087]\tvalid_0's multi_logloss: 0.169742\n",
            "[2088]\tvalid_0's multi_logloss: 0.169733\n",
            "[2089]\tvalid_0's multi_logloss: 0.169723\n",
            "[2090]\tvalid_0's multi_logloss: 0.169708\n",
            "[2091]\tvalid_0's multi_logloss: 0.169704\n",
            "[2092]\tvalid_0's multi_logloss: 0.169697\n",
            "[2093]\tvalid_0's multi_logloss: 0.169684\n",
            "[2094]\tvalid_0's multi_logloss: 0.16968\n",
            "[2095]\tvalid_0's multi_logloss: 0.169668\n",
            "[2096]\tvalid_0's multi_logloss: 0.169663\n",
            "[2097]\tvalid_0's multi_logloss: 0.169661\n",
            "[2098]\tvalid_0's multi_logloss: 0.169657\n",
            "[2099]\tvalid_0's multi_logloss: 0.169648\n",
            "[2100]\tvalid_0's multi_logloss: 0.169641\n",
            "[2101]\tvalid_0's multi_logloss: 0.169627\n",
            "[2102]\tvalid_0's multi_logloss: 0.169617\n",
            "[2103]\tvalid_0's multi_logloss: 0.169607\n",
            "[2104]\tvalid_0's multi_logloss: 0.1696\n",
            "[2105]\tvalid_0's multi_logloss: 0.169588\n",
            "[2106]\tvalid_0's multi_logloss: 0.16958\n",
            "[2107]\tvalid_0's multi_logloss: 0.169581\n",
            "[2108]\tvalid_0's multi_logloss: 0.169579\n",
            "[2109]\tvalid_0's multi_logloss: 0.169571\n",
            "[2110]\tvalid_0's multi_logloss: 0.169564\n",
            "[2111]\tvalid_0's multi_logloss: 0.169558\n",
            "[2112]\tvalid_0's multi_logloss: 0.169555\n",
            "[2113]\tvalid_0's multi_logloss: 0.16955\n",
            "[2114]\tvalid_0's multi_logloss: 0.169539\n",
            "[2115]\tvalid_0's multi_logloss: 0.169532\n",
            "[2116]\tvalid_0's multi_logloss: 0.16953\n",
            "[2117]\tvalid_0's multi_logloss: 0.169519\n",
            "[2118]\tvalid_0's multi_logloss: 0.169507\n",
            "[2119]\tvalid_0's multi_logloss: 0.169497\n",
            "[2120]\tvalid_0's multi_logloss: 0.169488\n",
            "[2121]\tvalid_0's multi_logloss: 0.169476\n",
            "[2122]\tvalid_0's multi_logloss: 0.169472\n",
            "[2123]\tvalid_0's multi_logloss: 0.169465\n",
            "[2124]\tvalid_0's multi_logloss: 0.169453\n",
            "[2125]\tvalid_0's multi_logloss: 0.169449\n",
            "[2126]\tvalid_0's multi_logloss: 0.169443\n",
            "[2127]\tvalid_0's multi_logloss: 0.169436\n",
            "[2128]\tvalid_0's multi_logloss: 0.169431\n",
            "[2129]\tvalid_0's multi_logloss: 0.169429\n",
            "[2130]\tvalid_0's multi_logloss: 0.169419\n",
            "[2131]\tvalid_0's multi_logloss: 0.169413\n",
            "[2132]\tvalid_0's multi_logloss: 0.16941\n",
            "[2133]\tvalid_0's multi_logloss: 0.169402\n",
            "[2134]\tvalid_0's multi_logloss: 0.169397\n",
            "[2135]\tvalid_0's multi_logloss: 0.169384\n",
            "[2136]\tvalid_0's multi_logloss: 0.169375\n",
            "[2137]\tvalid_0's multi_logloss: 0.169362\n",
            "[2138]\tvalid_0's multi_logloss: 0.169357\n",
            "[2139]\tvalid_0's multi_logloss: 0.169353\n",
            "[2140]\tvalid_0's multi_logloss: 0.169337\n",
            "[2141]\tvalid_0's multi_logloss: 0.169329\n",
            "[2142]\tvalid_0's multi_logloss: 0.169322\n",
            "[2143]\tvalid_0's multi_logloss: 0.169316\n",
            "[2144]\tvalid_0's multi_logloss: 0.169314\n",
            "[2145]\tvalid_0's multi_logloss: 0.169305\n",
            "[2146]\tvalid_0's multi_logloss: 0.169305\n",
            "[2147]\tvalid_0's multi_logloss: 0.169296\n",
            "[2148]\tvalid_0's multi_logloss: 0.169286\n",
            "[2149]\tvalid_0's multi_logloss: 0.169285\n",
            "[2150]\tvalid_0's multi_logloss: 0.169281\n",
            "[2151]\tvalid_0's multi_logloss: 0.169272\n",
            "[2152]\tvalid_0's multi_logloss: 0.169277\n",
            "[2153]\tvalid_0's multi_logloss: 0.169266\n",
            "[2154]\tvalid_0's multi_logloss: 0.169256\n",
            "[2155]\tvalid_0's multi_logloss: 0.169248\n",
            "[2156]\tvalid_0's multi_logloss: 0.169242\n",
            "[2157]\tvalid_0's multi_logloss: 0.169227\n",
            "[2158]\tvalid_0's multi_logloss: 0.16922\n",
            "[2159]\tvalid_0's multi_logloss: 0.169217\n",
            "[2160]\tvalid_0's multi_logloss: 0.169202\n",
            "[2161]\tvalid_0's multi_logloss: 0.169198\n",
            "[2162]\tvalid_0's multi_logloss: 0.16919\n",
            "[2163]\tvalid_0's multi_logloss: 0.169176\n",
            "[2164]\tvalid_0's multi_logloss: 0.169173\n",
            "[2165]\tvalid_0's multi_logloss: 0.169164\n",
            "[2166]\tvalid_0's multi_logloss: 0.169156\n",
            "[2167]\tvalid_0's multi_logloss: 0.169149\n",
            "[2168]\tvalid_0's multi_logloss: 0.169141\n",
            "[2169]\tvalid_0's multi_logloss: 0.169137\n",
            "[2170]\tvalid_0's multi_logloss: 0.169127\n",
            "[2171]\tvalid_0's multi_logloss: 0.169113\n",
            "[2172]\tvalid_0's multi_logloss: 0.169104\n",
            "[2173]\tvalid_0's multi_logloss: 0.169106\n",
            "[2174]\tvalid_0's multi_logloss: 0.169097\n",
            "[2175]\tvalid_0's multi_logloss: 0.169091\n",
            "[2176]\tvalid_0's multi_logloss: 0.169088\n",
            "[2177]\tvalid_0's multi_logloss: 0.169083\n",
            "[2178]\tvalid_0's multi_logloss: 0.169079\n",
            "[2179]\tvalid_0's multi_logloss: 0.169067\n",
            "[2180]\tvalid_0's multi_logloss: 0.169061\n",
            "[2181]\tvalid_0's multi_logloss: 0.169055\n",
            "[2182]\tvalid_0's multi_logloss: 0.169048\n",
            "[2183]\tvalid_0's multi_logloss: 0.169034\n",
            "[2184]\tvalid_0's multi_logloss: 0.16903\n",
            "[2185]\tvalid_0's multi_logloss: 0.16902\n",
            "[2186]\tvalid_0's multi_logloss: 0.169014\n",
            "[2187]\tvalid_0's multi_logloss: 0.169002\n",
            "[2188]\tvalid_0's multi_logloss: 0.168994\n",
            "[2189]\tvalid_0's multi_logloss: 0.168993\n",
            "[2190]\tvalid_0's multi_logloss: 0.168983\n",
            "[2191]\tvalid_0's multi_logloss: 0.168978\n",
            "[2192]\tvalid_0's multi_logloss: 0.168974\n",
            "[2193]\tvalid_0's multi_logloss: 0.168971\n",
            "[2194]\tvalid_0's multi_logloss: 0.168964\n",
            "[2195]\tvalid_0's multi_logloss: 0.168958\n",
            "[2196]\tvalid_0's multi_logloss: 0.16895\n",
            "[2197]\tvalid_0's multi_logloss: 0.168944\n",
            "[2198]\tvalid_0's multi_logloss: 0.168943\n",
            "[2199]\tvalid_0's multi_logloss: 0.168934\n",
            "[2200]\tvalid_0's multi_logloss: 0.168926\n",
            "[2201]\tvalid_0's multi_logloss: 0.168919\n",
            "[2202]\tvalid_0's multi_logloss: 0.168908\n",
            "[2203]\tvalid_0's multi_logloss: 0.1689\n",
            "[2204]\tvalid_0's multi_logloss: 0.168893\n",
            "[2205]\tvalid_0's multi_logloss: 0.168886\n",
            "[2206]\tvalid_0's multi_logloss: 0.16887\n",
            "[2207]\tvalid_0's multi_logloss: 0.168858\n",
            "[2208]\tvalid_0's multi_logloss: 0.168854\n",
            "[2209]\tvalid_0's multi_logloss: 0.168847\n",
            "[2210]\tvalid_0's multi_logloss: 0.168835\n",
            "[2211]\tvalid_0's multi_logloss: 0.168824\n",
            "[2212]\tvalid_0's multi_logloss: 0.168817\n",
            "[2213]\tvalid_0's multi_logloss: 0.168815\n",
            "[2214]\tvalid_0's multi_logloss: 0.168807\n",
            "[2215]\tvalid_0's multi_logloss: 0.168801\n",
            "[2216]\tvalid_0's multi_logloss: 0.168793\n",
            "[2217]\tvalid_0's multi_logloss: 0.168785\n",
            "[2218]\tvalid_0's multi_logloss: 0.168774\n",
            "[2219]\tvalid_0's multi_logloss: 0.168763\n",
            "[2220]\tvalid_0's multi_logloss: 0.168759\n",
            "[2221]\tvalid_0's multi_logloss: 0.168755\n",
            "[2222]\tvalid_0's multi_logloss: 0.168745\n",
            "[2223]\tvalid_0's multi_logloss: 0.168733\n",
            "[2224]\tvalid_0's multi_logloss: 0.168727\n",
            "[2225]\tvalid_0's multi_logloss: 0.168719\n",
            "[2226]\tvalid_0's multi_logloss: 0.168715\n",
            "[2227]\tvalid_0's multi_logloss: 0.168713\n",
            "[2228]\tvalid_0's multi_logloss: 0.168705\n",
            "[2229]\tvalid_0's multi_logloss: 0.1687\n",
            "[2230]\tvalid_0's multi_logloss: 0.168696\n",
            "[2231]\tvalid_0's multi_logloss: 0.168691\n",
            "[2232]\tvalid_0's multi_logloss: 0.168676\n",
            "[2233]\tvalid_0's multi_logloss: 0.168667\n",
            "[2234]\tvalid_0's multi_logloss: 0.168665\n",
            "[2235]\tvalid_0's multi_logloss: 0.168656\n",
            "[2236]\tvalid_0's multi_logloss: 0.168649\n",
            "[2237]\tvalid_0's multi_logloss: 0.168644\n",
            "[2238]\tvalid_0's multi_logloss: 0.168639\n",
            "[2239]\tvalid_0's multi_logloss: 0.16863\n",
            "[2240]\tvalid_0's multi_logloss: 0.168615\n",
            "[2241]\tvalid_0's multi_logloss: 0.16861\n",
            "[2242]\tvalid_0's multi_logloss: 0.168607\n",
            "[2243]\tvalid_0's multi_logloss: 0.168595\n",
            "[2244]\tvalid_0's multi_logloss: 0.168592\n",
            "[2245]\tvalid_0's multi_logloss: 0.168583\n",
            "[2246]\tvalid_0's multi_logloss: 0.168576\n",
            "[2247]\tvalid_0's multi_logloss: 0.168567\n",
            "[2248]\tvalid_0's multi_logloss: 0.16856\n",
            "[2249]\tvalid_0's multi_logloss: 0.168554\n",
            "[2250]\tvalid_0's multi_logloss: 0.168554\n",
            "[2251]\tvalid_0's multi_logloss: 0.168552\n",
            "[2252]\tvalid_0's multi_logloss: 0.168546\n",
            "[2253]\tvalid_0's multi_logloss: 0.16854\n",
            "[2254]\tvalid_0's multi_logloss: 0.168531\n",
            "[2255]\tvalid_0's multi_logloss: 0.168527\n",
            "[2256]\tvalid_0's multi_logloss: 0.168518\n",
            "[2257]\tvalid_0's multi_logloss: 0.168506\n",
            "[2258]\tvalid_0's multi_logloss: 0.168497\n",
            "[2259]\tvalid_0's multi_logloss: 0.168493\n",
            "[2260]\tvalid_0's multi_logloss: 0.168484\n",
            "[2261]\tvalid_0's multi_logloss: 0.168485\n",
            "[2262]\tvalid_0's multi_logloss: 0.168479\n",
            "[2263]\tvalid_0's multi_logloss: 0.168478\n",
            "[2264]\tvalid_0's multi_logloss: 0.168475\n",
            "[2265]\tvalid_0's multi_logloss: 0.168476\n",
            "[2266]\tvalid_0's multi_logloss: 0.168473\n",
            "[2267]\tvalid_0's multi_logloss: 0.168458\n",
            "[2268]\tvalid_0's multi_logloss: 0.168452\n",
            "[2269]\tvalid_0's multi_logloss: 0.168446\n",
            "[2270]\tvalid_0's multi_logloss: 0.168447\n",
            "[2271]\tvalid_0's multi_logloss: 0.168442\n",
            "[2272]\tvalid_0's multi_logloss: 0.168443\n",
            "[2273]\tvalid_0's multi_logloss: 0.168442\n",
            "[2274]\tvalid_0's multi_logloss: 0.168436\n",
            "[2275]\tvalid_0's multi_logloss: 0.168435\n",
            "[2276]\tvalid_0's multi_logloss: 0.16842\n",
            "[2277]\tvalid_0's multi_logloss: 0.168413\n",
            "[2278]\tvalid_0's multi_logloss: 0.168402\n",
            "[2279]\tvalid_0's multi_logloss: 0.168397\n",
            "[2280]\tvalid_0's multi_logloss: 0.168387\n",
            "[2281]\tvalid_0's multi_logloss: 0.168384\n",
            "[2282]\tvalid_0's multi_logloss: 0.168372\n",
            "[2283]\tvalid_0's multi_logloss: 0.168372\n",
            "[2284]\tvalid_0's multi_logloss: 0.168365\n",
            "[2285]\tvalid_0's multi_logloss: 0.168359\n",
            "[2286]\tvalid_0's multi_logloss: 0.168356\n",
            "[2287]\tvalid_0's multi_logloss: 0.168349\n",
            "[2288]\tvalid_0's multi_logloss: 0.168342\n",
            "[2289]\tvalid_0's multi_logloss: 0.168339\n",
            "[2290]\tvalid_0's multi_logloss: 0.168333\n",
            "[2291]\tvalid_0's multi_logloss: 0.168335\n",
            "[2292]\tvalid_0's multi_logloss: 0.168327\n",
            "[2293]\tvalid_0's multi_logloss: 0.168324\n",
            "[2294]\tvalid_0's multi_logloss: 0.168318\n",
            "[2295]\tvalid_0's multi_logloss: 0.168319\n",
            "[2296]\tvalid_0's multi_logloss: 0.168313\n",
            "[2297]\tvalid_0's multi_logloss: 0.16831\n",
            "[2298]\tvalid_0's multi_logloss: 0.168306\n",
            "[2299]\tvalid_0's multi_logloss: 0.1683\n",
            "[2300]\tvalid_0's multi_logloss: 0.168292\n",
            "[2301]\tvalid_0's multi_logloss: 0.168288\n",
            "[2302]\tvalid_0's multi_logloss: 0.168282\n",
            "[2303]\tvalid_0's multi_logloss: 0.168276\n",
            "[2304]\tvalid_0's multi_logloss: 0.168263\n",
            "[2305]\tvalid_0's multi_logloss: 0.168255\n",
            "[2306]\tvalid_0's multi_logloss: 0.168248\n",
            "[2307]\tvalid_0's multi_logloss: 0.168238\n",
            "[2308]\tvalid_0's multi_logloss: 0.168228\n",
            "[2309]\tvalid_0's multi_logloss: 0.168224\n",
            "[2310]\tvalid_0's multi_logloss: 0.168219\n",
            "[2311]\tvalid_0's multi_logloss: 0.16822\n",
            "[2312]\tvalid_0's multi_logloss: 0.168224\n",
            "[2313]\tvalid_0's multi_logloss: 0.168216\n",
            "[2314]\tvalid_0's multi_logloss: 0.168211\n",
            "[2315]\tvalid_0's multi_logloss: 0.168209\n",
            "[2316]\tvalid_0's multi_logloss: 0.168204\n",
            "[2317]\tvalid_0's multi_logloss: 0.168193\n",
            "[2318]\tvalid_0's multi_logloss: 0.168183\n",
            "[2319]\tvalid_0's multi_logloss: 0.168178\n",
            "[2320]\tvalid_0's multi_logloss: 0.168165\n",
            "[2321]\tvalid_0's multi_logloss: 0.168157\n",
            "[2322]\tvalid_0's multi_logloss: 0.168153\n",
            "[2323]\tvalid_0's multi_logloss: 0.168155\n",
            "[2324]\tvalid_0's multi_logloss: 0.168149\n",
            "[2325]\tvalid_0's multi_logloss: 0.168151\n",
            "[2326]\tvalid_0's multi_logloss: 0.168143\n",
            "[2327]\tvalid_0's multi_logloss: 0.168131\n",
            "[2328]\tvalid_0's multi_logloss: 0.16813\n",
            "[2329]\tvalid_0's multi_logloss: 0.168127\n",
            "[2330]\tvalid_0's multi_logloss: 0.168126\n",
            "[2331]\tvalid_0's multi_logloss: 0.168122\n",
            "[2332]\tvalid_0's multi_logloss: 0.168107\n",
            "[2333]\tvalid_0's multi_logloss: 0.1681\n",
            "[2334]\tvalid_0's multi_logloss: 0.168098\n",
            "[2335]\tvalid_0's multi_logloss: 0.168093\n",
            "[2336]\tvalid_0's multi_logloss: 0.168096\n",
            "[2337]\tvalid_0's multi_logloss: 0.168091\n",
            "[2338]\tvalid_0's multi_logloss: 0.168088\n",
            "[2339]\tvalid_0's multi_logloss: 0.168089\n",
            "[2340]\tvalid_0's multi_logloss: 0.168082\n",
            "[2341]\tvalid_0's multi_logloss: 0.168073\n",
            "[2342]\tvalid_0's multi_logloss: 0.168068\n",
            "[2343]\tvalid_0's multi_logloss: 0.168058\n",
            "[2344]\tvalid_0's multi_logloss: 0.168053\n",
            "[2345]\tvalid_0's multi_logloss: 0.168049\n",
            "[2346]\tvalid_0's multi_logloss: 0.168049\n",
            "[2347]\tvalid_0's multi_logloss: 0.168049\n",
            "[2348]\tvalid_0's multi_logloss: 0.168042\n",
            "[2349]\tvalid_0's multi_logloss: 0.168038\n",
            "[2350]\tvalid_0's multi_logloss: 0.168034\n",
            "[2351]\tvalid_0's multi_logloss: 0.168028\n",
            "[2352]\tvalid_0's multi_logloss: 0.168021\n",
            "[2353]\tvalid_0's multi_logloss: 0.168017\n",
            "[2354]\tvalid_0's multi_logloss: 0.168018\n",
            "[2355]\tvalid_0's multi_logloss: 0.168012\n",
            "[2356]\tvalid_0's multi_logloss: 0.168001\n",
            "[2357]\tvalid_0's multi_logloss: 0.167995\n",
            "[2358]\tvalid_0's multi_logloss: 0.167988\n",
            "[2359]\tvalid_0's multi_logloss: 0.167984\n",
            "[2360]\tvalid_0's multi_logloss: 0.167979\n",
            "[2361]\tvalid_0's multi_logloss: 0.16798\n",
            "[2362]\tvalid_0's multi_logloss: 0.167973\n",
            "[2363]\tvalid_0's multi_logloss: 0.167962\n",
            "[2364]\tvalid_0's multi_logloss: 0.167951\n",
            "[2365]\tvalid_0's multi_logloss: 0.16795\n",
            "[2366]\tvalid_0's multi_logloss: 0.167948\n",
            "[2367]\tvalid_0's multi_logloss: 0.167944\n",
            "[2368]\tvalid_0's multi_logloss: 0.167938\n",
            "[2369]\tvalid_0's multi_logloss: 0.16793\n",
            "[2370]\tvalid_0's multi_logloss: 0.167922\n",
            "[2371]\tvalid_0's multi_logloss: 0.167913\n",
            "[2372]\tvalid_0's multi_logloss: 0.167905\n",
            "[2373]\tvalid_0's multi_logloss: 0.167895\n",
            "[2374]\tvalid_0's multi_logloss: 0.167889\n",
            "[2375]\tvalid_0's multi_logloss: 0.16788\n",
            "[2376]\tvalid_0's multi_logloss: 0.167872\n",
            "[2377]\tvalid_0's multi_logloss: 0.167869\n",
            "[2378]\tvalid_0's multi_logloss: 0.167869\n",
            "[2379]\tvalid_0's multi_logloss: 0.167861\n",
            "[2380]\tvalid_0's multi_logloss: 0.167855\n",
            "[2381]\tvalid_0's multi_logloss: 0.167853\n",
            "[2382]\tvalid_0's multi_logloss: 0.167841\n",
            "[2383]\tvalid_0's multi_logloss: 0.167838\n",
            "[2384]\tvalid_0's multi_logloss: 0.16784\n",
            "[2385]\tvalid_0's multi_logloss: 0.167833\n",
            "[2386]\tvalid_0's multi_logloss: 0.167832\n",
            "[2387]\tvalid_0's multi_logloss: 0.167826\n",
            "[2388]\tvalid_0's multi_logloss: 0.167827\n",
            "[2389]\tvalid_0's multi_logloss: 0.167821\n",
            "[2390]\tvalid_0's multi_logloss: 0.167818\n",
            "[2391]\tvalid_0's multi_logloss: 0.167806\n",
            "[2392]\tvalid_0's multi_logloss: 0.167799\n",
            "[2393]\tvalid_0's multi_logloss: 0.16779\n",
            "[2394]\tvalid_0's multi_logloss: 0.167785\n",
            "[2395]\tvalid_0's multi_logloss: 0.167777\n",
            "[2396]\tvalid_0's multi_logloss: 0.167773\n",
            "[2397]\tvalid_0's multi_logloss: 0.16777\n",
            "[2398]\tvalid_0's multi_logloss: 0.167763\n",
            "[2399]\tvalid_0's multi_logloss: 0.167762\n",
            "[2400]\tvalid_0's multi_logloss: 0.167757\n",
            "[2401]\tvalid_0's multi_logloss: 0.167754\n",
            "[2402]\tvalid_0's multi_logloss: 0.167753\n",
            "[2403]\tvalid_0's multi_logloss: 0.167758\n",
            "[2404]\tvalid_0's multi_logloss: 0.167753\n",
            "[2405]\tvalid_0's multi_logloss: 0.167747\n",
            "[2406]\tvalid_0's multi_logloss: 0.167742\n",
            "[2407]\tvalid_0's multi_logloss: 0.167732\n",
            "[2408]\tvalid_0's multi_logloss: 0.16773\n",
            "[2409]\tvalid_0's multi_logloss: 0.167721\n",
            "[2410]\tvalid_0's multi_logloss: 0.167716\n",
            "[2411]\tvalid_0's multi_logloss: 0.167714\n",
            "[2412]\tvalid_0's multi_logloss: 0.167715\n",
            "[2413]\tvalid_0's multi_logloss: 0.16771\n",
            "[2414]\tvalid_0's multi_logloss: 0.1677\n",
            "[2415]\tvalid_0's multi_logloss: 0.1677\n",
            "[2416]\tvalid_0's multi_logloss: 0.167699\n",
            "[2417]\tvalid_0's multi_logloss: 0.167689\n",
            "[2418]\tvalid_0's multi_logloss: 0.167683\n",
            "[2419]\tvalid_0's multi_logloss: 0.167672\n",
            "[2420]\tvalid_0's multi_logloss: 0.167666\n",
            "[2421]\tvalid_0's multi_logloss: 0.167656\n",
            "[2422]\tvalid_0's multi_logloss: 0.167652\n",
            "[2423]\tvalid_0's multi_logloss: 0.167644\n",
            "[2424]\tvalid_0's multi_logloss: 0.167639\n",
            "[2425]\tvalid_0's multi_logloss: 0.167629\n",
            "[2426]\tvalid_0's multi_logloss: 0.167629\n",
            "[2427]\tvalid_0's multi_logloss: 0.167619\n",
            "[2428]\tvalid_0's multi_logloss: 0.167618\n",
            "[2429]\tvalid_0's multi_logloss: 0.167612\n",
            "[2430]\tvalid_0's multi_logloss: 0.167604\n",
            "[2431]\tvalid_0's multi_logloss: 0.167595\n",
            "[2432]\tvalid_0's multi_logloss: 0.167594\n",
            "[2433]\tvalid_0's multi_logloss: 0.167591\n",
            "[2434]\tvalid_0's multi_logloss: 0.167586\n",
            "[2435]\tvalid_0's multi_logloss: 0.167574\n",
            "[2436]\tvalid_0's multi_logloss: 0.167571\n",
            "[2437]\tvalid_0's multi_logloss: 0.167564\n",
            "[2438]\tvalid_0's multi_logloss: 0.167565\n",
            "[2439]\tvalid_0's multi_logloss: 0.167564\n",
            "[2440]\tvalid_0's multi_logloss: 0.167564\n",
            "[2441]\tvalid_0's multi_logloss: 0.167564\n",
            "[2442]\tvalid_0's multi_logloss: 0.167561\n",
            "[2443]\tvalid_0's multi_logloss: 0.167555\n",
            "[2444]\tvalid_0's multi_logloss: 0.167557\n",
            "[2445]\tvalid_0's multi_logloss: 0.167555\n",
            "[2446]\tvalid_0's multi_logloss: 0.167549\n",
            "[2447]\tvalid_0's multi_logloss: 0.167539\n",
            "[2448]\tvalid_0's multi_logloss: 0.167538\n",
            "[2449]\tvalid_0's multi_logloss: 0.167537\n",
            "[2450]\tvalid_0's multi_logloss: 0.16753\n",
            "[2451]\tvalid_0's multi_logloss: 0.167524\n",
            "[2452]\tvalid_0's multi_logloss: 0.167523\n",
            "[2453]\tvalid_0's multi_logloss: 0.167511\n",
            "[2454]\tvalid_0's multi_logloss: 0.167509\n",
            "[2455]\tvalid_0's multi_logloss: 0.167503\n",
            "[2456]\tvalid_0's multi_logloss: 0.167497\n",
            "[2457]\tvalid_0's multi_logloss: 0.167489\n",
            "[2458]\tvalid_0's multi_logloss: 0.167487\n",
            "[2459]\tvalid_0's multi_logloss: 0.167482\n",
            "[2460]\tvalid_0's multi_logloss: 0.167486\n",
            "[2461]\tvalid_0's multi_logloss: 0.167487\n",
            "[2462]\tvalid_0's multi_logloss: 0.167491\n",
            "[2463]\tvalid_0's multi_logloss: 0.167492\n",
            "[2464]\tvalid_0's multi_logloss: 0.167487\n",
            "[2465]\tvalid_0's multi_logloss: 0.167482\n",
            "[2466]\tvalid_0's multi_logloss: 0.167479\n",
            "[2467]\tvalid_0's multi_logloss: 0.16747\n",
            "[2468]\tvalid_0's multi_logloss: 0.167461\n",
            "[2469]\tvalid_0's multi_logloss: 0.16746\n",
            "[2470]\tvalid_0's multi_logloss: 0.167454\n",
            "[2471]\tvalid_0's multi_logloss: 0.16746\n",
            "[2472]\tvalid_0's multi_logloss: 0.167459\n",
            "[2473]\tvalid_0's multi_logloss: 0.16745\n",
            "[2474]\tvalid_0's multi_logloss: 0.167445\n",
            "[2475]\tvalid_0's multi_logloss: 0.167448\n",
            "[2476]\tvalid_0's multi_logloss: 0.167446\n",
            "[2477]\tvalid_0's multi_logloss: 0.167445\n",
            "[2478]\tvalid_0's multi_logloss: 0.167441\n",
            "[2479]\tvalid_0's multi_logloss: 0.16744\n",
            "[2480]\tvalid_0's multi_logloss: 0.16744\n",
            "[2481]\tvalid_0's multi_logloss: 0.167438\n",
            "[2482]\tvalid_0's multi_logloss: 0.167432\n",
            "[2483]\tvalid_0's multi_logloss: 0.167428\n",
            "[2484]\tvalid_0's multi_logloss: 0.167432\n",
            "[2485]\tvalid_0's multi_logloss: 0.167428\n",
            "[2486]\tvalid_0's multi_logloss: 0.167422\n",
            "[2487]\tvalid_0's multi_logloss: 0.167415\n",
            "[2488]\tvalid_0's multi_logloss: 0.167416\n",
            "[2489]\tvalid_0's multi_logloss: 0.167408\n",
            "[2490]\tvalid_0's multi_logloss: 0.167403\n",
            "[2491]\tvalid_0's multi_logloss: 0.167399\n",
            "[2492]\tvalid_0's multi_logloss: 0.167402\n",
            "[2493]\tvalid_0's multi_logloss: 0.1674\n",
            "[2494]\tvalid_0's multi_logloss: 0.167394\n",
            "[2495]\tvalid_0's multi_logloss: 0.167386\n",
            "[2496]\tvalid_0's multi_logloss: 0.167385\n",
            "[2497]\tvalid_0's multi_logloss: 0.167383\n",
            "[2498]\tvalid_0's multi_logloss: 0.167383\n",
            "[2499]\tvalid_0's multi_logloss: 0.167371\n",
            "[2500]\tvalid_0's multi_logloss: 0.167373\n",
            "[2501]\tvalid_0's multi_logloss: 0.16737\n",
            "[2502]\tvalid_0's multi_logloss: 0.167369\n",
            "[2503]\tvalid_0's multi_logloss: 0.167365\n",
            "[2504]\tvalid_0's multi_logloss: 0.167355\n",
            "[2505]\tvalid_0's multi_logloss: 0.167346\n",
            "[2506]\tvalid_0's multi_logloss: 0.167343\n",
            "[2507]\tvalid_0's multi_logloss: 0.167342\n",
            "[2508]\tvalid_0's multi_logloss: 0.167343\n",
            "[2509]\tvalid_0's multi_logloss: 0.167339\n",
            "[2510]\tvalid_0's multi_logloss: 0.167334\n",
            "[2511]\tvalid_0's multi_logloss: 0.167328\n",
            "[2512]\tvalid_0's multi_logloss: 0.167333\n",
            "[2513]\tvalid_0's multi_logloss: 0.167332\n",
            "[2514]\tvalid_0's multi_logloss: 0.167329\n",
            "[2515]\tvalid_0's multi_logloss: 0.167329\n",
            "[2516]\tvalid_0's multi_logloss: 0.167329\n",
            "[2517]\tvalid_0's multi_logloss: 0.167325\n",
            "[2518]\tvalid_0's multi_logloss: 0.167329\n",
            "[2519]\tvalid_0's multi_logloss: 0.167321\n",
            "[2520]\tvalid_0's multi_logloss: 0.167315\n",
            "[2521]\tvalid_0's multi_logloss: 0.167316\n",
            "[2522]\tvalid_0's multi_logloss: 0.167314\n",
            "[2523]\tvalid_0's multi_logloss: 0.167308\n",
            "[2524]\tvalid_0's multi_logloss: 0.167298\n",
            "[2525]\tvalid_0's multi_logloss: 0.167293\n",
            "[2526]\tvalid_0's multi_logloss: 0.167293\n",
            "[2527]\tvalid_0's multi_logloss: 0.167292\n",
            "[2528]\tvalid_0's multi_logloss: 0.167291\n",
            "[2529]\tvalid_0's multi_logloss: 0.167291\n",
            "[2530]\tvalid_0's multi_logloss: 0.167285\n",
            "[2531]\tvalid_0's multi_logloss: 0.167282\n",
            "[2532]\tvalid_0's multi_logloss: 0.167278\n",
            "[2533]\tvalid_0's multi_logloss: 0.167275\n",
            "[2534]\tvalid_0's multi_logloss: 0.167274\n",
            "[2535]\tvalid_0's multi_logloss: 0.167274\n",
            "[2536]\tvalid_0's multi_logloss: 0.167268\n",
            "[2537]\tvalid_0's multi_logloss: 0.167262\n",
            "[2538]\tvalid_0's multi_logloss: 0.167258\n",
            "[2539]\tvalid_0's multi_logloss: 0.167256\n",
            "[2540]\tvalid_0's multi_logloss: 0.167252\n",
            "[2541]\tvalid_0's multi_logloss: 0.167249\n",
            "[2542]\tvalid_0's multi_logloss: 0.167244\n",
            "[2543]\tvalid_0's multi_logloss: 0.167242\n",
            "[2544]\tvalid_0's multi_logloss: 0.16724\n",
            "[2545]\tvalid_0's multi_logloss: 0.167238\n",
            "[2546]\tvalid_0's multi_logloss: 0.167232\n",
            "[2547]\tvalid_0's multi_logloss: 0.167229\n",
            "[2548]\tvalid_0's multi_logloss: 0.167226\n",
            "[2549]\tvalid_0's multi_logloss: 0.167222\n",
            "[2550]\tvalid_0's multi_logloss: 0.167217\n",
            "[2551]\tvalid_0's multi_logloss: 0.167212\n",
            "[2552]\tvalid_0's multi_logloss: 0.167211\n",
            "[2553]\tvalid_0's multi_logloss: 0.167217\n",
            "[2554]\tvalid_0's multi_logloss: 0.167218\n",
            "[2555]\tvalid_0's multi_logloss: 0.167212\n",
            "[2556]\tvalid_0's multi_logloss: 0.167201\n",
            "[2557]\tvalid_0's multi_logloss: 0.167198\n",
            "[2558]\tvalid_0's multi_logloss: 0.167192\n",
            "[2559]\tvalid_0's multi_logloss: 0.167184\n",
            "[2560]\tvalid_0's multi_logloss: 0.167184\n",
            "[2561]\tvalid_0's multi_logloss: 0.167184\n",
            "[2562]\tvalid_0's multi_logloss: 0.167184\n",
            "[2563]\tvalid_0's multi_logloss: 0.167179\n",
            "[2564]\tvalid_0's multi_logloss: 0.16718\n",
            "[2565]\tvalid_0's multi_logloss: 0.167175\n",
            "[2566]\tvalid_0's multi_logloss: 0.167168\n",
            "[2567]\tvalid_0's multi_logloss: 0.16716\n",
            "[2568]\tvalid_0's multi_logloss: 0.16716\n",
            "[2569]\tvalid_0's multi_logloss: 0.167154\n",
            "[2570]\tvalid_0's multi_logloss: 0.167152\n",
            "[2571]\tvalid_0's multi_logloss: 0.167153\n",
            "[2572]\tvalid_0's multi_logloss: 0.167144\n",
            "[2573]\tvalid_0's multi_logloss: 0.167134\n",
            "[2574]\tvalid_0's multi_logloss: 0.167136\n",
            "[2575]\tvalid_0's multi_logloss: 0.167125\n",
            "[2576]\tvalid_0's multi_logloss: 0.167116\n",
            "[2577]\tvalid_0's multi_logloss: 0.167112\n",
            "[2578]\tvalid_0's multi_logloss: 0.167102\n",
            "[2579]\tvalid_0's multi_logloss: 0.167098\n",
            "[2580]\tvalid_0's multi_logloss: 0.1671\n",
            "[2581]\tvalid_0's multi_logloss: 0.167094\n",
            "[2582]\tvalid_0's multi_logloss: 0.16709\n",
            "[2583]\tvalid_0's multi_logloss: 0.167087\n",
            "[2584]\tvalid_0's multi_logloss: 0.167086\n",
            "[2585]\tvalid_0's multi_logloss: 0.167082\n",
            "[2586]\tvalid_0's multi_logloss: 0.167076\n",
            "[2587]\tvalid_0's multi_logloss: 0.16707\n",
            "[2588]\tvalid_0's multi_logloss: 0.167069\n",
            "[2589]\tvalid_0's multi_logloss: 0.167068\n",
            "[2590]\tvalid_0's multi_logloss: 0.167062\n",
            "[2591]\tvalid_0's multi_logloss: 0.167056\n",
            "[2592]\tvalid_0's multi_logloss: 0.167054\n",
            "[2593]\tvalid_0's multi_logloss: 0.167048\n",
            "[2594]\tvalid_0's multi_logloss: 0.167042\n",
            "[2595]\tvalid_0's multi_logloss: 0.167038\n",
            "[2596]\tvalid_0's multi_logloss: 0.167035\n",
            "[2597]\tvalid_0's multi_logloss: 0.167029\n",
            "[2598]\tvalid_0's multi_logloss: 0.167026\n",
            "[2599]\tvalid_0's multi_logloss: 0.167024\n",
            "[2600]\tvalid_0's multi_logloss: 0.167019\n",
            "[2601]\tvalid_0's multi_logloss: 0.167017\n",
            "[2602]\tvalid_0's multi_logloss: 0.167017\n",
            "[2603]\tvalid_0's multi_logloss: 0.167019\n",
            "[2604]\tvalid_0's multi_logloss: 0.167017\n",
            "[2605]\tvalid_0's multi_logloss: 0.167022\n",
            "[2606]\tvalid_0's multi_logloss: 0.167014\n",
            "[2607]\tvalid_0's multi_logloss: 0.167011\n",
            "[2608]\tvalid_0's multi_logloss: 0.167007\n",
            "[2609]\tvalid_0's multi_logloss: 0.167008\n",
            "[2610]\tvalid_0's multi_logloss: 0.167008\n",
            "[2611]\tvalid_0's multi_logloss: 0.167008\n",
            "[2612]\tvalid_0's multi_logloss: 0.167002\n",
            "[2613]\tvalid_0's multi_logloss: 0.166991\n",
            "[2614]\tvalid_0's multi_logloss: 0.166998\n",
            "[2615]\tvalid_0's multi_logloss: 0.167001\n",
            "[2616]\tvalid_0's multi_logloss: 0.166997\n",
            "[2617]\tvalid_0's multi_logloss: 0.166993\n",
            "[2618]\tvalid_0's multi_logloss: 0.166989\n",
            "[2619]\tvalid_0's multi_logloss: 0.166988\n",
            "[2620]\tvalid_0's multi_logloss: 0.166988\n",
            "[2621]\tvalid_0's multi_logloss: 0.166984\n",
            "[2622]\tvalid_0's multi_logloss: 0.166984\n",
            "[2623]\tvalid_0's multi_logloss: 0.166984\n",
            "[2624]\tvalid_0's multi_logloss: 0.16699\n",
            "[2625]\tvalid_0's multi_logloss: 0.166985\n",
            "[2626]\tvalid_0's multi_logloss: 0.16698\n",
            "[2627]\tvalid_0's multi_logloss: 0.166977\n",
            "[2628]\tvalid_0's multi_logloss: 0.166977\n",
            "[2629]\tvalid_0's multi_logloss: 0.166971\n",
            "[2630]\tvalid_0's multi_logloss: 0.166971\n",
            "[2631]\tvalid_0's multi_logloss: 0.166969\n",
            "[2632]\tvalid_0's multi_logloss: 0.16697\n",
            "[2633]\tvalid_0's multi_logloss: 0.166969\n",
            "[2634]\tvalid_0's multi_logloss: 0.16696\n",
            "[2635]\tvalid_0's multi_logloss: 0.166958\n",
            "[2636]\tvalid_0's multi_logloss: 0.166954\n",
            "[2637]\tvalid_0's multi_logloss: 0.166952\n",
            "[2638]\tvalid_0's multi_logloss: 0.166951\n",
            "[2639]\tvalid_0's multi_logloss: 0.166957\n",
            "[2640]\tvalid_0's multi_logloss: 0.166956\n",
            "[2641]\tvalid_0's multi_logloss: 0.166954\n",
            "[2642]\tvalid_0's multi_logloss: 0.166956\n",
            "[2643]\tvalid_0's multi_logloss: 0.166949\n",
            "[2644]\tvalid_0's multi_logloss: 0.166949\n",
            "[2645]\tvalid_0's multi_logloss: 0.166949\n",
            "[2646]\tvalid_0's multi_logloss: 0.166949\n",
            "[2647]\tvalid_0's multi_logloss: 0.166942\n",
            "[2648]\tvalid_0's multi_logloss: 0.166937\n",
            "[2649]\tvalid_0's multi_logloss: 0.166931\n",
            "[2650]\tvalid_0's multi_logloss: 0.16692\n",
            "[2651]\tvalid_0's multi_logloss: 0.166919\n",
            "[2652]\tvalid_0's multi_logloss: 0.166917\n",
            "[2653]\tvalid_0's multi_logloss: 0.166914\n",
            "[2654]\tvalid_0's multi_logloss: 0.16691\n",
            "[2655]\tvalid_0's multi_logloss: 0.16692\n",
            "[2656]\tvalid_0's multi_logloss: 0.166913\n",
            "[2657]\tvalid_0's multi_logloss: 0.166911\n",
            "[2658]\tvalid_0's multi_logloss: 0.16691\n",
            "[2659]\tvalid_0's multi_logloss: 0.16691\n",
            "[2660]\tvalid_0's multi_logloss: 0.166902\n",
            "[2661]\tvalid_0's multi_logloss: 0.166899\n",
            "[2662]\tvalid_0's multi_logloss: 0.166895\n",
            "[2663]\tvalid_0's multi_logloss: 0.166889\n",
            "[2664]\tvalid_0's multi_logloss: 0.166886\n",
            "[2665]\tvalid_0's multi_logloss: 0.166881\n",
            "[2666]\tvalid_0's multi_logloss: 0.166882\n",
            "[2667]\tvalid_0's multi_logloss: 0.16688\n",
            "[2668]\tvalid_0's multi_logloss: 0.166869\n",
            "[2669]\tvalid_0's multi_logloss: 0.166862\n",
            "[2670]\tvalid_0's multi_logloss: 0.166861\n",
            "[2671]\tvalid_0's multi_logloss: 0.166857\n",
            "[2672]\tvalid_0's multi_logloss: 0.166852\n",
            "[2673]\tvalid_0's multi_logloss: 0.166851\n",
            "[2674]\tvalid_0's multi_logloss: 0.166849\n",
            "[2675]\tvalid_0's multi_logloss: 0.166847\n",
            "[2676]\tvalid_0's multi_logloss: 0.16685\n",
            "[2677]\tvalid_0's multi_logloss: 0.166849\n",
            "[2678]\tvalid_0's multi_logloss: 0.16685\n",
            "[2679]\tvalid_0's multi_logloss: 0.166852\n",
            "[2680]\tvalid_0's multi_logloss: 0.166849\n",
            "[2681]\tvalid_0's multi_logloss: 0.166842\n",
            "[2682]\tvalid_0's multi_logloss: 0.166842\n",
            "[2683]\tvalid_0's multi_logloss: 0.166838\n",
            "[2684]\tvalid_0's multi_logloss: 0.166841\n",
            "[2685]\tvalid_0's multi_logloss: 0.166844\n",
            "[2686]\tvalid_0's multi_logloss: 0.166841\n",
            "[2687]\tvalid_0's multi_logloss: 0.166848\n",
            "[2688]\tvalid_0's multi_logloss: 0.166846\n",
            "[2689]\tvalid_0's multi_logloss: 0.166848\n",
            "[2690]\tvalid_0's multi_logloss: 0.166841\n",
            "[2691]\tvalid_0's multi_logloss: 0.16684\n",
            "[2692]\tvalid_0's multi_logloss: 0.166836\n",
            "[2693]\tvalid_0's multi_logloss: 0.166832\n",
            "[2694]\tvalid_0's multi_logloss: 0.166827\n",
            "[2695]\tvalid_0's multi_logloss: 0.16683\n",
            "[2696]\tvalid_0's multi_logloss: 0.166831\n",
            "[2697]\tvalid_0's multi_logloss: 0.166833\n",
            "[2698]\tvalid_0's multi_logloss: 0.166834\n",
            "[2699]\tvalid_0's multi_logloss: 0.166839\n",
            "[2700]\tvalid_0's multi_logloss: 0.166839\n",
            "[2701]\tvalid_0's multi_logloss: 0.16684\n",
            "[2702]\tvalid_0's multi_logloss: 0.166837\n",
            "[2703]\tvalid_0's multi_logloss: 0.166836\n",
            "[2704]\tvalid_0's multi_logloss: 0.166831\n",
            "[2705]\tvalid_0's multi_logloss: 0.166834\n",
            "[2706]\tvalid_0's multi_logloss: 0.166834\n",
            "[2707]\tvalid_0's multi_logloss: 0.16683\n",
            "[2708]\tvalid_0's multi_logloss: 0.16683\n",
            "[2709]\tvalid_0's multi_logloss: 0.166823\n",
            "[2710]\tvalid_0's multi_logloss: 0.166821\n",
            "[2711]\tvalid_0's multi_logloss: 0.166822\n",
            "[2712]\tvalid_0's multi_logloss: 0.166822\n",
            "[2713]\tvalid_0's multi_logloss: 0.166814\n",
            "[2714]\tvalid_0's multi_logloss: 0.166809\n",
            "[2715]\tvalid_0's multi_logloss: 0.166808\n",
            "[2716]\tvalid_0's multi_logloss: 0.166814\n",
            "[2717]\tvalid_0's multi_logloss: 0.166814\n",
            "[2718]\tvalid_0's multi_logloss: 0.166812\n",
            "[2719]\tvalid_0's multi_logloss: 0.166808\n",
            "[2720]\tvalid_0's multi_logloss: 0.166806\n",
            "[2721]\tvalid_0's multi_logloss: 0.166804\n",
            "[2722]\tvalid_0's multi_logloss: 0.166804\n",
            "[2723]\tvalid_0's multi_logloss: 0.166802\n",
            "[2724]\tvalid_0's multi_logloss: 0.166803\n",
            "[2725]\tvalid_0's multi_logloss: 0.1668\n",
            "[2726]\tvalid_0's multi_logloss: 0.166796\n",
            "[2727]\tvalid_0's multi_logloss: 0.166795\n",
            "[2728]\tvalid_0's multi_logloss: 0.166796\n",
            "[2729]\tvalid_0's multi_logloss: 0.166793\n",
            "[2730]\tvalid_0's multi_logloss: 0.166794\n",
            "[2731]\tvalid_0's multi_logloss: 0.166791\n",
            "[2732]\tvalid_0's multi_logloss: 0.166793\n",
            "[2733]\tvalid_0's multi_logloss: 0.166791\n",
            "[2734]\tvalid_0's multi_logloss: 0.166788\n",
            "[2735]\tvalid_0's multi_logloss: 0.16679\n",
            "[2736]\tvalid_0's multi_logloss: 0.166782\n",
            "[2737]\tvalid_0's multi_logloss: 0.166786\n",
            "[2738]\tvalid_0's multi_logloss: 0.166783\n",
            "[2739]\tvalid_0's multi_logloss: 0.166786\n",
            "[2740]\tvalid_0's multi_logloss: 0.166791\n",
            "[2741]\tvalid_0's multi_logloss: 0.166786\n",
            "[2742]\tvalid_0's multi_logloss: 0.16678\n",
            "[2743]\tvalid_0's multi_logloss: 0.166777\n",
            "[2744]\tvalid_0's multi_logloss: 0.166771\n",
            "[2745]\tvalid_0's multi_logloss: 0.166769\n",
            "[2746]\tvalid_0's multi_logloss: 0.166766\n",
            "[2747]\tvalid_0's multi_logloss: 0.166764\n",
            "[2748]\tvalid_0's multi_logloss: 0.16676\n",
            "[2749]\tvalid_0's multi_logloss: 0.166764\n",
            "[2750]\tvalid_0's multi_logloss: 0.16676\n",
            "[2751]\tvalid_0's multi_logloss: 0.166753\n",
            "[2752]\tvalid_0's multi_logloss: 0.166754\n",
            "[2753]\tvalid_0's multi_logloss: 0.166749\n",
            "[2754]\tvalid_0's multi_logloss: 0.166743\n",
            "[2755]\tvalid_0's multi_logloss: 0.166747\n",
            "[2756]\tvalid_0's multi_logloss: 0.166747\n",
            "[2757]\tvalid_0's multi_logloss: 0.166741\n",
            "[2758]\tvalid_0's multi_logloss: 0.166746\n",
            "[2759]\tvalid_0's multi_logloss: 0.166745\n",
            "[2760]\tvalid_0's multi_logloss: 0.16675\n",
            "[2761]\tvalid_0's multi_logloss: 0.166746\n",
            "[2762]\tvalid_0's multi_logloss: 0.166748\n",
            "[2763]\tvalid_0's multi_logloss: 0.166745\n",
            "[2764]\tvalid_0's multi_logloss: 0.16674\n",
            "[2765]\tvalid_0's multi_logloss: 0.16674\n",
            "[2766]\tvalid_0's multi_logloss: 0.166743\n",
            "[2767]\tvalid_0's multi_logloss: 0.166748\n",
            "[2768]\tvalid_0's multi_logloss: 0.16675\n",
            "[2769]\tvalid_0's multi_logloss: 0.166746\n",
            "[2770]\tvalid_0's multi_logloss: 0.166745\n",
            "[2771]\tvalid_0's multi_logloss: 0.166746\n",
            "[2772]\tvalid_0's multi_logloss: 0.166747\n",
            "[2773]\tvalid_0's multi_logloss: 0.166754\n",
            "[2774]\tvalid_0's multi_logloss: 0.166763\n",
            "[2775]\tvalid_0's multi_logloss: 0.166761\n",
            "[2776]\tvalid_0's multi_logloss: 0.166755\n",
            "[2777]\tvalid_0's multi_logloss: 0.166755\n",
            "[2778]\tvalid_0's multi_logloss: 0.166752\n",
            "[2779]\tvalid_0's multi_logloss: 0.166753\n",
            "[2780]\tvalid_0's multi_logloss: 0.166752\n",
            "[2781]\tvalid_0's multi_logloss: 0.166746\n",
            "[2782]\tvalid_0's multi_logloss: 0.166742\n",
            "[2783]\tvalid_0's multi_logloss: 0.166731\n",
            "[2784]\tvalid_0's multi_logloss: 0.166732\n",
            "[2785]\tvalid_0's multi_logloss: 0.166731\n",
            "[2786]\tvalid_0's multi_logloss: 0.166734\n",
            "[2787]\tvalid_0's multi_logloss: 0.166733\n",
            "[2788]\tvalid_0's multi_logloss: 0.166733\n",
            "[2789]\tvalid_0's multi_logloss: 0.166728\n",
            "[2790]\tvalid_0's multi_logloss: 0.166731\n",
            "[2791]\tvalid_0's multi_logloss: 0.166727\n",
            "[2792]\tvalid_0's multi_logloss: 0.16672\n",
            "[2793]\tvalid_0's multi_logloss: 0.166722\n",
            "[2794]\tvalid_0's multi_logloss: 0.166716\n",
            "[2795]\tvalid_0's multi_logloss: 0.166719\n",
            "[2796]\tvalid_0's multi_logloss: 0.166719\n",
            "[2797]\tvalid_0's multi_logloss: 0.166721\n",
            "[2798]\tvalid_0's multi_logloss: 0.166722\n",
            "[2799]\tvalid_0's multi_logloss: 0.166719\n",
            "[2800]\tvalid_0's multi_logloss: 0.166716\n",
            "[2801]\tvalid_0's multi_logloss: 0.166723\n",
            "[2802]\tvalid_0's multi_logloss: 0.166725\n",
            "[2803]\tvalid_0's multi_logloss: 0.166731\n",
            "[2804]\tvalid_0's multi_logloss: 0.166736\n",
            "[2805]\tvalid_0's multi_logloss: 0.166734\n",
            "[2806]\tvalid_0's multi_logloss: 0.16673\n",
            "[2807]\tvalid_0's multi_logloss: 0.166728\n",
            "[2808]\tvalid_0's multi_logloss: 0.166732\n",
            "[2809]\tvalid_0's multi_logloss: 0.166728\n",
            "[2810]\tvalid_0's multi_logloss: 0.16673\n",
            "[2811]\tvalid_0's multi_logloss: 0.166728\n",
            "[2812]\tvalid_0's multi_logloss: 0.166729\n",
            "[2813]\tvalid_0's multi_logloss: 0.166726\n",
            "[2814]\tvalid_0's multi_logloss: 0.166724\n",
            "[2815]\tvalid_0's multi_logloss: 0.16672\n",
            "[2816]\tvalid_0's multi_logloss: 0.16672\n",
            "[2817]\tvalid_0's multi_logloss: 0.166719\n",
            "[2818]\tvalid_0's multi_logloss: 0.166709\n",
            "[2819]\tvalid_0's multi_logloss: 0.166712\n",
            "[2820]\tvalid_0's multi_logloss: 0.166706\n",
            "[2821]\tvalid_0's multi_logloss: 0.166698\n",
            "[2822]\tvalid_0's multi_logloss: 0.166697\n",
            "[2823]\tvalid_0's multi_logloss: 0.166697\n",
            "[2824]\tvalid_0's multi_logloss: 0.166692\n",
            "[2825]\tvalid_0's multi_logloss: 0.166691\n",
            "[2826]\tvalid_0's multi_logloss: 0.166692\n",
            "[2827]\tvalid_0's multi_logloss: 0.166686\n",
            "[2828]\tvalid_0's multi_logloss: 0.166679\n",
            "[2829]\tvalid_0's multi_logloss: 0.166676\n",
            "[2830]\tvalid_0's multi_logloss: 0.166674\n",
            "[2831]\tvalid_0's multi_logloss: 0.166682\n",
            "[2832]\tvalid_0's multi_logloss: 0.166679\n",
            "[2833]\tvalid_0's multi_logloss: 0.166678\n",
            "[2834]\tvalid_0's multi_logloss: 0.166682\n",
            "[2835]\tvalid_0's multi_logloss: 0.166687\n",
            "[2836]\tvalid_0's multi_logloss: 0.166692\n",
            "[2837]\tvalid_0's multi_logloss: 0.166697\n",
            "[2838]\tvalid_0's multi_logloss: 0.1667\n",
            "[2839]\tvalid_0's multi_logloss: 0.1667\n",
            "[2840]\tvalid_0's multi_logloss: 0.166705\n",
            "[2841]\tvalid_0's multi_logloss: 0.166704\n",
            "[2842]\tvalid_0's multi_logloss: 0.166702\n",
            "[2843]\tvalid_0's multi_logloss: 0.166699\n",
            "[2844]\tvalid_0's multi_logloss: 0.166704\n",
            "[2845]\tvalid_0's multi_logloss: 0.166703\n",
            "[2846]\tvalid_0's multi_logloss: 0.166699\n",
            "[2847]\tvalid_0's multi_logloss: 0.166703\n",
            "[2848]\tvalid_0's multi_logloss: 0.166706\n",
            "[2849]\tvalid_0's multi_logloss: 0.166704\n",
            "[2850]\tvalid_0's multi_logloss: 0.166697\n",
            "[2851]\tvalid_0's multi_logloss: 0.166694\n",
            "[2852]\tvalid_0's multi_logloss: 0.166693\n",
            "[2853]\tvalid_0's multi_logloss: 0.166689\n",
            "[2854]\tvalid_0's multi_logloss: 0.166694\n",
            "[2855]\tvalid_0's multi_logloss: 0.166703\n",
            "[2856]\tvalid_0's multi_logloss: 0.166706\n",
            "[2857]\tvalid_0's multi_logloss: 0.166708\n",
            "[2858]\tvalid_0's multi_logloss: 0.166705\n",
            "[2859]\tvalid_0's multi_logloss: 0.1667\n",
            "[2860]\tvalid_0's multi_logloss: 0.1667\n",
            "[2861]\tvalid_0's multi_logloss: 0.166701\n",
            "[2862]\tvalid_0's multi_logloss: 0.166695\n",
            "[2863]\tvalid_0's multi_logloss: 0.166694\n",
            "[2864]\tvalid_0's multi_logloss: 0.166693\n",
            "[2865]\tvalid_0's multi_logloss: 0.166689\n",
            "[2866]\tvalid_0's multi_logloss: 0.166689\n",
            "[2867]\tvalid_0's multi_logloss: 0.166686\n",
            "[2868]\tvalid_0's multi_logloss: 0.166681\n",
            "[2869]\tvalid_0's multi_logloss: 0.166681\n",
            "[2870]\tvalid_0's multi_logloss: 0.166679\n",
            "[2871]\tvalid_0's multi_logloss: 0.166681\n",
            "[2872]\tvalid_0's multi_logloss: 0.16668\n",
            "[2873]\tvalid_0's multi_logloss: 0.166676\n",
            "[2874]\tvalid_0's multi_logloss: 0.166676\n",
            "[2875]\tvalid_0's multi_logloss: 0.166678\n",
            "[2876]\tvalid_0's multi_logloss: 0.166679\n",
            "[2877]\tvalid_0's multi_logloss: 0.166676\n",
            "[2878]\tvalid_0's multi_logloss: 0.166681\n",
            "[2879]\tvalid_0's multi_logloss: 0.166686\n",
            "[2880]\tvalid_0's multi_logloss: 0.166691\n",
            "[2881]\tvalid_0's multi_logloss: 0.16669\n",
            "[2882]\tvalid_0's multi_logloss: 0.166697\n",
            "[2883]\tvalid_0's multi_logloss: 0.166696\n",
            "[2884]\tvalid_0's multi_logloss: 0.166694\n",
            "[2885]\tvalid_0's multi_logloss: 0.166692\n",
            "[2886]\tvalid_0's multi_logloss: 0.166693\n",
            "[2887]\tvalid_0's multi_logloss: 0.166693\n",
            "[2888]\tvalid_0's multi_logloss: 0.166694\n",
            "[2889]\tvalid_0's multi_logloss: 0.166698\n",
            "[2890]\tvalid_0's multi_logloss: 0.166701\n",
            "[2891]\tvalid_0's multi_logloss: 0.166697\n",
            "[2892]\tvalid_0's multi_logloss: 0.166702\n",
            "[2893]\tvalid_0's multi_logloss: 0.166709\n",
            "[2894]\tvalid_0's multi_logloss: 0.166705\n",
            "[2895]\tvalid_0's multi_logloss: 0.166703\n",
            "[2896]\tvalid_0's multi_logloss: 0.1667\n",
            "[2897]\tvalid_0's multi_logloss: 0.166706\n",
            "[2898]\tvalid_0's multi_logloss: 0.166706\n",
            "[2899]\tvalid_0's multi_logloss: 0.166708\n",
            "[2900]\tvalid_0's multi_logloss: 0.166706\n",
            "[2901]\tvalid_0's multi_logloss: 0.166703\n",
            "[2902]\tvalid_0's multi_logloss: 0.166703\n",
            "[2903]\tvalid_0's multi_logloss: 0.166702\n",
            "[2904]\tvalid_0's multi_logloss: 0.166701\n",
            "[2905]\tvalid_0's multi_logloss: 0.166706\n",
            "[2906]\tvalid_0's multi_logloss: 0.166713\n",
            "[2907]\tvalid_0's multi_logloss: 0.166714\n",
            "[2908]\tvalid_0's multi_logloss: 0.166717\n",
            "[2909]\tvalid_0's multi_logloss: 0.166725\n",
            "[2910]\tvalid_0's multi_logloss: 0.166731\n",
            "[2911]\tvalid_0's multi_logloss: 0.166737\n",
            "[2912]\tvalid_0's multi_logloss: 0.166738\n",
            "[2913]\tvalid_0's multi_logloss: 0.166739\n",
            "[2914]\tvalid_0's multi_logloss: 0.16674\n",
            "[2915]\tvalid_0's multi_logloss: 0.166742\n",
            "[2916]\tvalid_0's multi_logloss: 0.166741\n",
            "[2917]\tvalid_0's multi_logloss: 0.166734\n",
            "[2918]\tvalid_0's multi_logloss: 0.166738\n",
            "[2919]\tvalid_0's multi_logloss: 0.16674\n",
            "[2920]\tvalid_0's multi_logloss: 0.166749\n",
            "[2921]\tvalid_0's multi_logloss: 0.166749\n",
            "[2922]\tvalid_0's multi_logloss: 0.166753\n",
            "[2923]\tvalid_0's multi_logloss: 0.166745\n",
            "[2924]\tvalid_0's multi_logloss: 0.16675\n",
            "[2925]\tvalid_0's multi_logloss: 0.166744\n",
            "[2926]\tvalid_0's multi_logloss: 0.166743\n",
            "[2927]\tvalid_0's multi_logloss: 0.166743\n",
            "[2928]\tvalid_0's multi_logloss: 0.166738\n",
            "[2929]\tvalid_0's multi_logloss: 0.166736\n",
            "[2930]\tvalid_0's multi_logloss: 0.166742\n",
            "Early stopping, best iteration is:\n",
            "[2830]\tvalid_0's multi_logloss: 0.166674\n",
            "Saving model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7f921fada860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GkQzCp889n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "de758a24-fb68-4e7c-f9b5-60bb21e12905"
      },
      "source": [
        "# train_preds = gbm.predict(df_train[columns])\n",
        "# predictions = []\n",
        "# for x in train_preds:\n",
        "#     predictions.append(np.argmax(x))\n",
        "# print('train', metrics.f1_score(y_train, predictions, average='macro'))\n",
        "\n",
        "# test_preds = gbm.predict(df_test[columns])\n",
        "# predictions = []\n",
        "# for x in test_preds:\n",
        "#     predictions.append(np.argmax(x))\n",
        "# print('test', metrics.f1_score(y_test, predictions, average='macro'))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7383378668271513\n",
            "test 0.5966941731442842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65c2RmTmTPjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "d05decd5-a841-462e-f02a-2d08783b9af5"
      },
      "source": [
        "# baseline 3\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow_lemmas\n",
        "encoder_pos = OneHotEncoder()\n",
        "lemma_columns = [\n",
        "    f'{prefix}lemma'\n",
        "    for prefix in ['prev-prev-', 'prev-', '', 'next-', 'next-next-']\n",
        "]\n",
        "\n",
        "columns = [\n",
        "    f'{prefix}{feature}'\n",
        "    for prefix in ['prev-prev-', 'prev-', '', 'next-', 'next-next-']\n",
        "    for feature in ['pos', 'uppercase']\n",
        "]\n",
        "encoder_pos.fit(df[columns])\n",
        "\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train[lemma_column])\n",
        "    for lemma_column in lemma_columns\n",
        "] + [encoder_pos.transform(df_train[columns])])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test[lemma_column])\n",
        "    for lemma_column in lemma_columns\n",
        "] + [encoder_pos.transform(df_test[columns])])\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    random_state=SEED, max_features=None, verbose=1, criterion='entropy',\n",
        "    min_samples_leaf=1, min_samples_split=2, n_estimators=10, n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 11.5min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 0.9901597349666811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test 0.837889956055061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhY1ElCNC8ES",
        "colab_type": "text"
      },
      "source": [
        "0.8378 > 0.8122"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jCvv4xqHTAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fd0f1c5-f154-4139-f685-324b4ddf4421"
      },
      "source": [
        "# # LGBM\n",
        "# import lightgbm as lgb\n",
        "# import scipy.sparse as sp\n",
        "\n",
        "# embeding = w2v_cbow\n",
        "# encoder_pos = OneHotEncoder()\n",
        "# columns = ['pos', 'next-pos', 'next-next-pos', 'prev-pos', 'prev-prev-pos']\n",
        "\n",
        "# X_train = sp.hstack([\n",
        "#     embeding.transform(df_train.word),\n",
        "#     embeding.transform(df_train['next-word']),\n",
        "#     embeding.transform(df_train['next-next-word']),\n",
        "#     embeding.transform(df_train['prev-word']),\n",
        "#     embeding.transform(df_train['prev-prev-word']),\n",
        "#     encoder_pos.fit_transform(df_train[columns])\n",
        "# ])\n",
        "# X_test = sp.hstack([\n",
        "#     embeding.transform(df_test.word),\n",
        "#     embeding.transform(df_test['next-word']),\n",
        "#     embeding.transform(df_test['next-next-word']),\n",
        "#     embeding.transform(df_test['prev-word']),\n",
        "#     embeding.transform(df_test['prev-prev-word']),\n",
        "#     encoder_pos.transform(df_test[columns])\n",
        "# ])\n",
        "\n",
        "# lgb_train = lgb.Dataset(X_train, y_train)\n",
        "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "# params = {\n",
        "#     'boosting_type': 'gbdt',\n",
        "#     'objective': 'multiclass',\n",
        "#     'num_class': len(np.unique(y)),\n",
        "#     'metric': 'multi_logloss',\n",
        "#     'num_leaves': 127,\n",
        "#     'learning_rate': 0.01,\n",
        "#     'feature_fraction': 0.7,\n",
        "#     'bagging_fraction': 0.6,\n",
        "#     'bagging_freq': 1,\n",
        "#     'verbose': 50,\n",
        "#     'seed': SEED\n",
        "# }\n",
        "\n",
        "# print('Starting training...')\n",
        "# # train\n",
        "# gbm = lgb.train(\n",
        "#     params,\n",
        "#     lgb_train,\n",
        "#     num_boost_round=100,\n",
        "#     valid_sets=lgb_eval,\n",
        "#     early_stopping_rounds=100\n",
        "# )\n",
        "\n",
        "# print('Saving model...')\n",
        "# # save model to file\n",
        "# gbm.save_model('model.txt')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "[1]\tvalid_0's multi_logloss: 0.716336\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.693827\n",
            "[3]\tvalid_0's multi_logloss: 0.673643\n",
            "[4]\tvalid_0's multi_logloss: 0.656817\n",
            "[5]\tvalid_0's multi_logloss: 0.641113\n",
            "[6]\tvalid_0's multi_logloss: 0.62601\n",
            "[7]\tvalid_0's multi_logloss: 0.613716\n",
            "[8]\tvalid_0's multi_logloss: 0.601476\n",
            "[9]\tvalid_0's multi_logloss: 0.589819\n",
            "[10]\tvalid_0's multi_logloss: 0.57886\n",
            "[11]\tvalid_0's multi_logloss: 0.568466\n",
            "[12]\tvalid_0's multi_logloss: 0.558747\n",
            "[13]\tvalid_0's multi_logloss: 0.549919\n",
            "[14]\tvalid_0's multi_logloss: 0.540853\n",
            "[15]\tvalid_0's multi_logloss: 0.532099\n",
            "[16]\tvalid_0's multi_logloss: 0.524481\n",
            "[17]\tvalid_0's multi_logloss: 0.516384\n",
            "[18]\tvalid_0's multi_logloss: 0.508678\n",
            "[19]\tvalid_0's multi_logloss: 0.501272\n",
            "[20]\tvalid_0's multi_logloss: 0.494033\n",
            "[21]\tvalid_0's multi_logloss: 0.487396\n",
            "[22]\tvalid_0's multi_logloss: 0.481031\n",
            "[23]\tvalid_0's multi_logloss: 0.474665\n",
            "[24]\tvalid_0's multi_logloss: 0.468512\n",
            "[25]\tvalid_0's multi_logloss: 0.462546\n",
            "[26]\tvalid_0's multi_logloss: 0.457299\n",
            "[27]\tvalid_0's multi_logloss: 0.451649\n",
            "[28]\tvalid_0's multi_logloss: 0.446442\n",
            "[29]\tvalid_0's multi_logloss: 0.441615\n",
            "[30]\tvalid_0's multi_logloss: 0.436513\n",
            "[31]\tvalid_0's multi_logloss: 0.431848\n",
            "[32]\tvalid_0's multi_logloss: 0.427262\n",
            "[33]\tvalid_0's multi_logloss: 0.422405\n",
            "[34]\tvalid_0's multi_logloss: 0.417877\n",
            "[35]\tvalid_0's multi_logloss: 0.413697\n",
            "[36]\tvalid_0's multi_logloss: 0.409211\n",
            "[37]\tvalid_0's multi_logloss: 0.405144\n",
            "[38]\tvalid_0's multi_logloss: 0.40075\n",
            "[39]\tvalid_0's multi_logloss: 0.39649\n",
            "[40]\tvalid_0's multi_logloss: 0.392762\n",
            "[41]\tvalid_0's multi_logloss: 0.388733\n",
            "[42]\tvalid_0's multi_logloss: 0.384884\n",
            "[43]\tvalid_0's multi_logloss: 0.381022\n",
            "[44]\tvalid_0's multi_logloss: 0.377193\n",
            "[45]\tvalid_0's multi_logloss: 0.373478\n",
            "[46]\tvalid_0's multi_logloss: 0.369765\n",
            "[47]\tvalid_0's multi_logloss: 0.366175\n",
            "[48]\tvalid_0's multi_logloss: 0.362756\n",
            "[49]\tvalid_0's multi_logloss: 0.359315\n",
            "[50]\tvalid_0's multi_logloss: 0.355825\n",
            "[51]\tvalid_0's multi_logloss: 0.352467\n",
            "[52]\tvalid_0's multi_logloss: 0.349314\n",
            "[53]\tvalid_0's multi_logloss: 0.346302\n",
            "[54]\tvalid_0's multi_logloss: 0.343088\n",
            "[55]\tvalid_0's multi_logloss: 0.339946\n",
            "[56]\tvalid_0's multi_logloss: 0.336867\n",
            "[57]\tvalid_0's multi_logloss: 0.333819\n",
            "[58]\tvalid_0's multi_logloss: 0.330902\n",
            "[59]\tvalid_0's multi_logloss: 0.32812\n",
            "[60]\tvalid_0's multi_logloss: 0.325283\n",
            "[61]\tvalid_0's multi_logloss: 0.322679\n",
            "[62]\tvalid_0's multi_logloss: 0.320063\n",
            "[63]\tvalid_0's multi_logloss: 0.317347\n",
            "[64]\tvalid_0's multi_logloss: 0.314666\n",
            "[65]\tvalid_0's multi_logloss: 0.312084\n",
            "[66]\tvalid_0's multi_logloss: 0.309479\n",
            "[67]\tvalid_0's multi_logloss: 0.30717\n",
            "[68]\tvalid_0's multi_logloss: 0.30457\n",
            "[69]\tvalid_0's multi_logloss: 0.302064\n",
            "[70]\tvalid_0's multi_logloss: 0.299535\n",
            "[71]\tvalid_0's multi_logloss: 0.297114\n",
            "[72]\tvalid_0's multi_logloss: 0.294847\n",
            "[73]\tvalid_0's multi_logloss: 0.292435\n",
            "[74]\tvalid_0's multi_logloss: 0.290102\n",
            "[75]\tvalid_0's multi_logloss: 0.28776\n",
            "[76]\tvalid_0's multi_logloss: 0.285493\n",
            "[77]\tvalid_0's multi_logloss: 0.283455\n",
            "[78]\tvalid_0's multi_logloss: 0.281201\n",
            "[79]\tvalid_0's multi_logloss: 0.27898\n",
            "[80]\tvalid_0's multi_logloss: 0.276811\n",
            "[81]\tvalid_0's multi_logloss: 0.274719\n",
            "[82]\tvalid_0's multi_logloss: 0.272705\n",
            "[83]\tvalid_0's multi_logloss: 0.270592\n",
            "[84]\tvalid_0's multi_logloss: 0.268536\n",
            "[85]\tvalid_0's multi_logloss: 0.266531\n",
            "[86]\tvalid_0's multi_logloss: 0.264557\n",
            "[87]\tvalid_0's multi_logloss: 0.262751\n",
            "[88]\tvalid_0's multi_logloss: 0.260802\n",
            "[89]\tvalid_0's multi_logloss: 0.258923\n",
            "[90]\tvalid_0's multi_logloss: 0.257087\n",
            "[91]\tvalid_0's multi_logloss: 0.255253\n",
            "[92]\tvalid_0's multi_logloss: 0.253429\n",
            "[93]\tvalid_0's multi_logloss: 0.251732\n",
            "[94]\tvalid_0's multi_logloss: 0.250019\n",
            "[95]\tvalid_0's multi_logloss: 0.248214\n",
            "[96]\tvalid_0's multi_logloss: 0.246489\n",
            "[97]\tvalid_0's multi_logloss: 0.244882\n",
            "[98]\tvalid_0's multi_logloss: 0.243157\n",
            "[99]\tvalid_0's multi_logloss: 0.241462\n",
            "[100]\tvalid_0's multi_logloss: 0.2398\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's multi_logloss: 0.2398\n",
            "Saving model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7f921dd07e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkYhqliHK7v5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7ee16381-d0a5-47e4-d6e6-98d89f156bec"
      },
      "source": [
        "# train_preds = gbm.predict(X_train)\n",
        "# predictions = []\n",
        "# for x in train_preds:\n",
        "#     predictions.append(np.argmax(x))\n",
        "# print('train', metrics.f1_score(y_train, predictions, average='macro'))\n",
        "\n",
        "# test_preds = gbm.predict(X_test)\n",
        "# predictions = []\n",
        "# for x in test_preds:\n",
        "#     predictions.append(np.argmax(x))\n",
        "# print('test', metrics.f1_score(y_test, predictions, average='macro'))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7680029478652147\n",
            "test 0.39954632571069604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgQOFJ0gDGAq",
        "colab_type": "text"
      },
      "source": [
        "[1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?\n",
        "\n",
        "F1 score представляет из себя более общую и \"репрезентативную\" метрику, чем просто полнота или точность, поскольку высокое значение одного не гарантирует высокое значение другого. F1-score же учитывает обе метрики, причём в равной мере (т.к. β = 1), поэтому если значение F1-score высокое, как у нас, то это говорит о том, что классификатор ведёт себя хорошо как по той, так и по другой метрике (но никто не говорит, что одинаково). Необходимо усреднение, поскольку у нас многоклассовая, а не бинарная классификация. Как видно из частотностей выше, классы неравномерно распределены и в тестовой выборке сохраняется такое распределение (см. stratify=y), поэтому в случае микро-усреднения высокое качество будет даже у константного алгоритма с самым частотным классом (т.к. в этом случае рассматривается F1-метрика в общем, а не для каждого класса по отдельности), в отличие от макро-усреднения, где усредняется значение F1-метрики по всем классам в отдельности, что гораздо важнее в нашей задаче, поскольку мы хотим не только предсказывать отсутствие NER, но и предсказывать его наличие в редких случаях, поэтому эта метрика гораздо лучше отражает корректность алгоритма. Weighted average нам тоже не очень подходит, т.к. мы хотим предсказывать наличие NER ничуть не меньше, чем отсутствие оного. Macro accuracy, macro precision, macro recall в принципе тоже можно использовать, но они обладают тем недостатком, что отражают работу классификатора не в полной мере. Также можно использовать log-loss для небинарного случая, поскольку в этом случае также логарифм считается для каждого класса отдельно."
      ]
    }
  ]
}