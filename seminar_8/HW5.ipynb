{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGhiKPm-oM2O",
        "colab_type": "code",
        "outputId": "459078e8-01ee-4afe-b255-cba6dcc9c873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from google.colab import files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCWAu1V-g8NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0VWGG2OUqrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet = string.ascii_lowercase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GryLHUKNko-M",
        "colab_type": "code",
        "outputId": "eb689408-f23d-48ca-825c-c4ef1fd6742d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c1d8cde-4c39-4bd1-80cd-c2398ab46d34\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3c1d8cde-4c39-4bd1-80cd-c2398ab46d34\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"happypuffin7\",\"key\":\"510774de9e6f1d45f5c1decaf6107cb4\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q23hjvl6k2Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvsnYtm1mtWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjfFZPY1naqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc7SHfyZn84Z",
        "colab_type": "code",
        "outputId": "f083fd24-7f0b-4f34-8888-ba096ee6f890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle datasets download -d utathya/imdb-review-dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading imdb-review-dataset.zip to /content\n",
            " 65% 33.0M/50.5M [00:00<00:00, 42.1MB/s]\n",
            "100% 50.5M/50.5M [00:00<00:00, 65.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhiU1UU4nIju",
        "colab_type": "code",
        "outputId": "b4765d5d-9bc6-4d76-c0fb-5788546d4571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip imdb-review-dataset.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imdb-review-dataset.zip\n",
            "  inflating: imdb_master.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ix8AG9yoEMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv', encoding='latin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy64ZGgwoZPg",
        "colab_type": "code",
        "outputId": "3ba56099-cf88-4159-95cb-8c8b5300cec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0_2.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10000_4.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10001_1.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10002_3.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10003_3.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  type  ... label         file\n",
              "0           0  test  ...   neg      0_2.txt\n",
              "1           1  test  ...   neg  10000_4.txt\n",
              "2           2  test  ...   neg  10001_1.txt\n",
              "3           3  test  ...   neg  10002_3.txt\n",
              "4           4  test  ...   neg  10003_3.txt\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM5onZnBUz70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "symbols_to_be_removed = set(' '.join(list(df[df['type'] != 'test'].review)).lower()) - (set(alphabet) | {' ', '\\n', '\\t'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxOBOJpHVkbz",
        "colab_type": "code",
        "outputId": "0e8fd165-4ecf-4fc8-d2fc-52c6dc481808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join(symbols_to_be_removed)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¿á\\x181³7[]&å¾$©ð*®\\\\°\\x08%-ë?¡µ5¥/«²2{§6>æ)±\\'¬;¢8ªº¯·è0|~ï!\"¦+´\\xad¤¶@9ã}¼â\\x10¨_½»#(`:¸£ä,=3\\xa0.^<4¹'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVMc19jlUkhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    for ch in symbols_to_be_removed:\n",
        "        if ch in text:\n",
        "            text = text.replace(ch, '')\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBVOi10ZVq81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# нормализауем текст, чтобы повысить качество: помогло повысить accuracy с 87.75% до 88.84%\n",
        "df['preprocessed_review'] = df['review'].apply(preprocess_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V88rnc7Rp8MG",
        "colab_type": "code",
        "outputId": "be898640-975f-4904-81ee-345f1b666b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['type'].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['test', 'train'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIk-bFYw6ia",
        "colab_type": "code",
        "outputId": "ccfac901-b13c-45f9-cea1-011891c98fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "df[df['type'] == 'train']['label'].unique(), df[df['type'] == 'test']['label'].unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['neg', 'pos', 'unsup'], dtype=object),\n",
              " array(['neg', 'pos'], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcOVlmY2pSVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unsup = df[df['label'] == 'unsup'][['preprocessed_review', 'label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabvCuKmpSQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[df['type'] == 'train'][['preprocessed_review', 'label']]\n",
        "df_test = df[df['type'] == 'test'][['preprocessed_review', 'label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BWkO9uC2BLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[(df['label'] == 'neg') | (df['label'] == 'pos')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_9bqdDl9-Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_and_unsup = df[df['type'] == 'train'][['preprocessed_review', 'label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SovvYZHqCF6",
        "colab_type": "code",
        "outputId": "13d3fd13-a507-4443-8d3b-9931df8b6775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.shape, df_test.shape, df_unsup.shape, df_train_and_unsup.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 2), (25000, 2), (50000, 2), (75000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSkvABnRqCCr",
        "colab_type": "code",
        "outputId": "8f8a97d9-4936-4ae9-9d4b-c42a7ba8a704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preprocessed_review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25000</th>\n",
              "      <td>story of a man who ha unnatural feeling for a ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25001</th>\n",
              "      <td>airport start a a brand new luxury plane is lo...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25002</th>\n",
              "      <td>this film lacked something i couldnt put my fi...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25003</th>\n",
              "      <td>sorry everyone i know this is supposed to be a...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25004</th>\n",
              "      <td>when i wa little my parent took me along to th...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     preprocessed_review label\n",
              "25000  story of a man who ha unnatural feeling for a ...   neg\n",
              "25001  airport start a a brand new luxury plane is lo...   neg\n",
              "25002  this film lacked something i couldnt put my fi...   neg\n",
              "25003  sorry everyone i know this is supposed to be a...   neg\n",
              "25004  when i wa little my parent took me along to th...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTiCL2SAv8B9",
        "colab_type": "text"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3FkiJQ-xcY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('neg', 'pos')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWsPqXH9jHb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetFromDataFrame(data.Dataset):\n",
        "    \"\"\"\n",
        "    A class to convert pandas DataFrame to torchtext Dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, path, text_field, label_field, col, gt, dfs, **kwargs):\n",
        "        fields = [(\"text\", text_field), (\"label\", label_field)]\n",
        "        examples = []\n",
        "        shape_ = dfs[path].values[:,1].shape[0]\n",
        "        for i in tqdm(range(shape_), total=shape_, desc=f\"Example:\"):\n",
        "            text = dfs[path][col].iloc[i]\n",
        "            label = dfs[path][gt].iloc[i]\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.text)\n",
        "    \n",
        "    # @classmethod\n",
        "    # def splits(cls, text_field, label_field, col, label, train, validation=None, test=None, **kwargs):\n",
        "    #     dfs = {'train': train}\n",
        "    #     if validation is not None:\n",
        "    #         dfs['validation'] = validation\n",
        "    #         has_validation = 'validation'\n",
        "    #     else:\n",
        "    #         has_validation = None\n",
        "    #     if test is not None:\n",
        "    #         dfs['test'] = test\n",
        "    #         has_test = 'test'\n",
        "    #     else:\n",
        "    #         has_test = None\n",
        "    #     return super().splits('',\n",
        "    #         text_field=text_field, label_field=label_field, col=col, gt=label, \n",
        "    #                           train='train', validation=has_validation, test=has_test,  dfs=dfs, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdoArtym2e-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy', batch_first=True, lower=True)\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jeL3rIsjHkY",
        "colab_type": "code",
        "outputId": "0ad2c6f8-6832-4705-b0c6-3b2a4db71817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dfs = {0: df_train, 1: df_test, 2: df_train_and_unsup}\n",
        "train_dataset = DatasetFromDataFrame(0, TEXT, LABEL, 'preprocessed_review', 'label', dfs)\n",
        "test_dataset = DatasetFromDataFrame(1, TEXT, LABEL, 'preprocessed_review', 'label', dfs)\n",
        "train_and_unsup_dataset = DatasetFromDataFrame(2, TEXT, LABEL, 'preprocessed_review', 'label', dfs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example:: 100%|██████████| 25000/25000 [00:34<00:00, 734.87it/s]\n",
            "Example:: 100%|██████████| 25000/25000 [00:33<00:00, 746.50it/s]\n",
            "Example:: 100%|██████████| 75000/75000 [01:43<00:00, 722.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiOkOp0rqF4H",
        "colab": {}
      },
      "source": [
        "# Я пробовал с valid_dataset и за 5 эпох модель ещё не успевает переобучиться, поэтому чтобы сохранить максимум информации\n",
        "# для обучающей выборки я решил обойтись без валидационной выборки. Но вообще можно разбить выборку вот так (и раскомментить выше):\n",
        "# train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(SEED), split_ratio=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgQsHltfm06y",
        "colab_type": "code",
        "outputId": "fcecf972-bc61-4dc6-eb49-48b75de9d4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Как видно, обучающая выборка небольшая, поэтому решили обойтись без валидационной выборки\n",
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XhCy0htq6LZ",
        "colab_type": "text"
      },
      "source": [
        "Я пробовал использовать \"glove.6B.100d\" эмбеддинги, но максимальное качество accuracy только 88.84%, поэтому самостоятельно предобучаем word2vec эмбеддинги и вставляем их в build_vocab от torchtext-а.\n",
        "\n",
        "Именно здесь я при обучении использую unsupervised data ([2 points] for using unsupervised data). По поводу использования unsupervised data были также следующие идеи: поскольку наша модель достигает на тесте > 85%, то можно предиктить с помощью нашей модели на unsupervised data и отбирать случаи, когда модель особенно уверена в своих предсказаниях, и добавлять их в train_dataset, но поскольку качество 90% уже удалось достичь просто с помощью преобученных эмбеддингов, то я не стал это реализовывать.\n",
        "\n",
        "Эмбеддинги я обучаю на всей train-выборке (т.е. не только на unsupervised data, но и на supervised data в train-е)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfOfQ-eSSuyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [sent.split() for sent in list(df_train_and_unsup.preprocessed_review)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnDhsQ1_sVlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## constants\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "# константа определяется дефолтными min_count и другими параметрами в классе Word2Vec в gensim-е\n",
        "MAX_VOCAB = 49347\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKzJ6tG-SJtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(sentences, size=EMBEDDING_DIM)\n",
        "weights = torch.FloatTensor(w2v_model.wv.vectors)\n",
        "w2v_model.wv.save_word2vec_format('w2v_embeddings_100')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0gwGfN6BE-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# чтобы tqdm нормально себя вёл\n",
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WM3cJd9m038",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "32517004-f31c-4455-a8d9-0f629b45d7d5"
      },
      "source": [
        "vectors = Vectors(name='w2v_embeddings_100', cache='./')\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_and_unsup_dataset,\n",
        "    vectors=vectors,  # \"glove.6B.100d\"\n",
        "    max_size=MAX_VOCAB,\n",
        "    unk_init=torch.Tensor.normal_\n",
        ")\n",
        "\n",
        "LABEL.build_vocab(train_dataset)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/49349 [00:00<?, ?it/s]Skipping token b'49349' with 1-dimensional vector [b'100']; likely a header\n",
            " 99%|█████████▉| 48907/49349 [00:01<00:00, 29023.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-MuxnOdnBsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, train_and_unsup_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset, train_and_unsup_dataset, test_dataset), batch_size=BATCH_SIZE, device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z6q95BYrTHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, vocab_size, pad_idx, num_filters, filter_sizes):\n",
        "        super().__init__()\n",
        "\n",
        "        # embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, EMBEDDING_DIM, padding_idx=pad_idx)\n",
        "\n",
        "        # list of convolutions\n",
        "        self.convolutions = nn.ModuleList(\n",
        "            [\n",
        "                nn.Conv2d(\n",
        "                    in_channels=1,  # because we have texts, not images\n",
        "                    out_channels=num_filters,\n",
        "                    kernel_size=(filter_size, EMBEDDING_DIM)\n",
        "                )\n",
        "                for filter_size in filter_sizes\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # fully connected layer\n",
        "        self.linear = nn.Linear(len(filter_sizes) * num_filters, 1)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # get embeddings\n",
        "        embeddings = self.embedding(text)\n",
        "\n",
        "        # add dummy channel (second) dimension\n",
        "        embeddings = embeddings.unsqueeze(1)\n",
        "\n",
        "        # apply convolutions (using relu activation function after convolution)\n",
        "        convolved = [F.relu(convolution(embeddings)).squeeze(3) for convolution in self.convolutions]\n",
        "\n",
        "        # apply max pooling\n",
        "        pooled = [F.max_pool1d(convolved_, convolved_.shape[2]).squeeze(2) for convolved_ in convolved]\n",
        "\n",
        "        # concatenate\n",
        "        cat = torch.cat(pooled, dim=1)\n",
        "\n",
        "        # apply fully connected layer\n",
        "        result = self.linear(cat)\n",
        "\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39NWMGrKnBxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(TEXT.vocab)\n",
        "NUM_FILTERS = 100\n",
        "FILTER_SIZES = [2, 3, 4]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model_100 = NeuralNet(VOCAB_SIZE, PAD_IDX, NUM_FILTERS, FILTER_SIZES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-mXyjoFtIyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_100.embedding.weight.data.copy_(pretrained_embeddings);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgS13c2ltldK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model_100.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model_100.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e60f5b66-7590-4371-dd47-44ee9cbeeddf",
        "id": "pijhsdVNtu3Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Length of Text Vocabulary: \" + str(len(TEXT.vocab)))\n",
        "print(\"Vector size of Text Vocabulary: \", TEXT.vocab.vectors.size())\n",
        "print(\"Label Length: \" + str(len(LABEL.vocab)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Text Vocabulary: 49349\n",
            "Vector size of Text Vocabulary:  torch.Size([49349, 100])\n",
            "Label Length: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-qwtC02v64O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_100.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a66bz4Z6t649",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_preds, y_true):\n",
        "    y_preds = torch.round(torch.sigmoid(y_preds))\n",
        "    preds = (y_preds == y_true).float()\n",
        "    return preds.sum() / len(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2jMoKTMwaNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        y_preds = model(batch.text).squeeze(1)\n",
        "        loss = criterion(y_preds, batch.label)\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += accuracy(y_preds, batch.label).item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh60LagQuAr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            y_preds = model(batch.text).squeeze(1)\n",
        "            loss = criterion(y_preds, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += accuracy(y_preds, batch.label).item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpXOR7aquFfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_evaluate_model(model, num_epochs=5):\n",
        "    best_valid_loss = float('inf')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # train model\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "        print(f'Epoch: {epoch + 1}')\n",
        "        print(f'train loss: {train_loss:.3f}, train acc: {train_acc*100:.2f}%')\n",
        "\n",
        "    # evaluate model\n",
        "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "    print(f'test loss: {test_loss:.3f}, test acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIADSM4lgc9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "af03ecc1-0dd8-4578-dfb2-b9b90307f67b"
      },
      "source": [
        "train_and_evaluate_model(model_100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "train loss: 0.425, train acc: 80.05%\n",
            "Epoch: 2\n",
            "train loss: 0.265, train acc: 89.08%\n",
            "Epoch: 3\n",
            "train loss: 0.203, train acc: 92.31%\n",
            "Epoch: 4\n",
            "train loss: 0.155, train acc: 94.53%\n",
            "Epoch: 5\n",
            "train loss: 0.116, train acc: 96.35%\n",
            "test loss: 0.248, test acc: 90.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPJ9W1G0jn1Z",
        "colab_type": "text"
      },
      "source": [
        "Как видно, модель не сильно переобучается, хотя на большем количестве данных и на большем количестве эпох качество, очевидно, было бы лучше. Но лучше be on the safe side и не переобучать модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1TmwFVrcyit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You have to provide data for trials with different hyperparameter values.\n",
        "# Вообще говоря мы уже достигли качества 90%, но поскольку нужно предоставить подбор гиперпараметра,\n",
        "# давайте попробуем увеличить размерность embedding-а (300 вместо 100) и увеличим количество фильтров\n",
        "# и количество размеров фильтров:\n",
        "NUM_FILTERS = 300\n",
        "FILTER_SIZES = [2, 3, 4, 5, 6]\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjdyU6a1ehoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(sentences, size=EMBEDDING_DIM)\n",
        "weights = torch.FloatTensor(w2v_model.wv.vectors)\n",
        "w2v_model.wv.save_word2vec_format('w2v_embeddings_300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Cri9tPeElm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d5fec211-a37c-42bf-cead-dd393c6dd204"
      },
      "source": [
        "vectors = Vectors(name='w2v_embeddings_300', cache='./')\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_and_unsup_dataset,\n",
        "    vectors=vectors,  # \"glove.6B.100d\"\n",
        "    max_size=MAX_VOCAB,\n",
        "    unk_init=torch.Tensor.normal_\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/49349 [00:00<?, ?it/s]Skipping token b'49349' with 1-dimensional vector [b'300']; likely a header\n",
            " 98%|█████████▊| 48277/49349 [00:04<00:00, 11626.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lcr1ufne0fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_300 = NeuralNet(VOCAB_SIZE, PAD_IDX, NUM_FILTERS, FILTER_SIZES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBXhwIuifAMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_300.embedding.weight.data.copy_(pretrained_embeddings);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMfbdqfIfEbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model_300.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model_300.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldnfhqEHguYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_300.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-6RYYh2fKQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e723ff1a-323c-4c26-d74a-8e59ab038a35"
      },
      "source": [
        "train_and_evaluate_model(model_300)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "train loss: 0.414, train acc: 81.89%\n",
            "Epoch: 2\n",
            "train loss: 0.207, train acc: 91.87%\n",
            "Epoch: 3\n",
            "train loss: 0.106, train acc: 96.68%\n",
            "Epoch: 4\n",
            "train loss: 0.035, train acc: 99.49%\n",
            "Epoch: 5\n",
            "train loss: 0.010, train acc: 99.99%\n",
            "test loss: 0.266, test acc: 90.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRFIOjdMl--E",
        "colab_type": "text"
      },
      "source": [
        "Здесь уже модель по сути выучила всё, что было в train-корпусе. Поэтому дальнейшего повышения качества нужно добиваться не столько изменением архитектуры (поскольку при такой архитектуре за 5 эпох уже всё выучено и дальше будет только переобучение), сколько, видимо, более точными embedding-ами и добавлением unsupervised-данных в train-выборку (отбор тех, на которых модель с 90% accuracy уверена, т.е. нужно выбрать порог)."
      ]
    }
  ]
}